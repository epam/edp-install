{"config":{"lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"EPAM Delivery \u00b6 EPAM Delivery platform (EDP) is out of the box integrated ecosystem for software development connected to a local development environment. EPAM Delivery Platform, which is also called \"The Rocket\" , is a platform that allows shortening the time that is passed before an active development can be started from several months to several hours. EDP consists of the following: The platform based on managed infrastructure and container orchestration; Security covering authentication, authorization, and SSO for platform services; Development and testing toolset; Well-established engineering process and EPAM practices (EngX) reflected in CICD pipelines, and delivery analytics; Local development with debug capabilities. Note To get accurate information about the EDP architecture, please refer to the EDP Architecture page.","title":"Overview"},{"location":"#epam-delivery","text":"EPAM Delivery platform (EDP) is out of the box integrated ecosystem for software development connected to a local development environment. EPAM Delivery Platform, which is also called \"The Rocket\" , is a platform that allows shortening the time that is passed before an active development can be started from several months to several hours. EDP consists of the following: The platform based on managed infrastructure and container orchestration; Security covering authentication, authorization, and SSO for platform services; Development and testing toolset; Well-established engineering process and EPAM practices (EngX) reflected in CICD pipelines, and delivery analytics; Local development with debug capabilities. Note To get accurate information about the EDP architecture, please refer to the EDP Architecture page.","title":"EPAM Delivery"},{"location":"getting_started/","text":"","title":"Getting started"},{"location":"glossary/","text":"Glossary \u00b6 Get familiar with the definitions and context for the most useful EDP terms presented below.","title":"Glossary"},{"location":"glossary/#glossary","text":"Get familiar with the definitions and context for the most useful EDP terms presented below.","title":"Glossary"},{"location":"developer-guide/","text":"Overview \u00b6 This guide is for developers who want to extend EDP functionality","title":"Overview"},{"location":"developer-guide/#overview","text":"This guide is for developers who want to extend EDP functionality","title":"Overview"},{"location":"developer-guide/local-development/","text":"Local Development \u00b6 Requirements \u00b6 GoLang version higher than 1.13; Note The GOPATH and GOROOT environment variables should be added in PATH. PostgreSQL client version higher than 9.5; Configured access to the VCS, for details, refer to the Gerrit Setup for Developer page; GoLand Intellij IDEA or another IDE. Start Operator \u00b6 In order to run the operator, follow the steps below: Clone repository; Open folder in GoLand Intellij IDEA, click the button and select the Go Build option: In Configuration tab, fill in the following: 3.1. In the Field field, indicate the path to the main.go file; 3.2. In the Working directory field, indicate the path to the operator; 3.3. In the Environment field, specify the platform name (OpenShift/Kubernetes); Create the PostgreSQL database, schema, and a user for the EDP Admin Console operator: Create database with a user: CREATE DATABASE edp-db WITH ENCODING 'UTF8'; CREATE USER postgres WITH PASSWORD 'password'; GRANT ALL PRIVILEGES ON DATABASE 'edp-db' to postgres; Create a schema: CREATE SCHEMA [ IF NOT EXISTS ] ' develop ' ; EDP Admin Console operator supports two modes for running: local and prod. For local deploy, modify edp-admin-console/conf/app.conf and set the following parameters: runmode = local [ local ] dbEnabled = true pgHost = localhost pgPort = 5432 pgDatabase = edp - db pgUser = postgres pgPassword = password edpName = develop Run go build main.go (Shift+F10); After the successful setup, follow the http://localhost:8080 URL address to check the result: Exceptional Cases \u00b6 After starting the Go build process, the following error will appear: go : finding github . com /openshift/ api v3 . 9.0 go : finding github . com /openshift/ client - go v3 . 9.0 go : errors parsing go . mod : C :\\ Users \\<< username >>\\ Desktop \\ EDP \\ edp - admin - console \\ go . mod : 36 : require github . com /openshift/ api : version \"v3.9.0\" invalid : unknown revision v3 . 9.0 Compilation finished with exit code 1 To resolve the issue, update the go dependency by applying the Golang command: go get github . com / openshift / api @v3 .9.0","title":"Local Development"},{"location":"developer-guide/local-development/#local-development","text":"","title":"Local Development"},{"location":"developer-guide/local-development/#requirements","text":"GoLang version higher than 1.13; Note The GOPATH and GOROOT environment variables should be added in PATH. PostgreSQL client version higher than 9.5; Configured access to the VCS, for details, refer to the Gerrit Setup for Developer page; GoLand Intellij IDEA or another IDE.","title":"Requirements"},{"location":"developer-guide/local-development/#start-operator","text":"In order to run the operator, follow the steps below: Clone repository; Open folder in GoLand Intellij IDEA, click the button and select the Go Build option: In Configuration tab, fill in the following: 3.1. In the Field field, indicate the path to the main.go file; 3.2. In the Working directory field, indicate the path to the operator; 3.3. In the Environment field, specify the platform name (OpenShift/Kubernetes); Create the PostgreSQL database, schema, and a user for the EDP Admin Console operator: Create database with a user: CREATE DATABASE edp-db WITH ENCODING 'UTF8'; CREATE USER postgres WITH PASSWORD 'password'; GRANT ALL PRIVILEGES ON DATABASE 'edp-db' to postgres; Create a schema: CREATE SCHEMA [ IF NOT EXISTS ] ' develop ' ; EDP Admin Console operator supports two modes for running: local and prod. For local deploy, modify edp-admin-console/conf/app.conf and set the following parameters: runmode = local [ local ] dbEnabled = true pgHost = localhost pgPort = 5432 pgDatabase = edp - db pgUser = postgres pgPassword = password edpName = develop Run go build main.go (Shift+F10); After the successful setup, follow the http://localhost:8080 URL address to check the result:","title":"Start Operator"},{"location":"developer-guide/local-development/#exceptional-cases","text":"After starting the Go build process, the following error will appear: go : finding github . com /openshift/ api v3 . 9.0 go : finding github . com /openshift/ client - go v3 . 9.0 go : errors parsing go . mod : C :\\ Users \\<< username >>\\ Desktop \\ EDP \\ edp - admin - console \\ go . mod : 36 : require github . com /openshift/ api : version \"v3.9.0\" invalid : unknown revision v3 . 9.0 Compilation finished with exit code 1 To resolve the issue, update the go dependency by applying the Golang command: go get github . com / openshift / api @v3 .9.0","title":"Exceptional Cases"},{"location":"developer-guide/rest-api/","text":"EDP API \u00b6 Create Codebase Entity \u00b6 EDP allows you to create three codebase types: Application, Autotest and Library. There are also several strategy types for each codebase: Create, Clone and Import. Depending on the selected codebase type and the respective strategy, you should specify a different set of fields in a request. Note The Route, Database and VCS are optional fields. In accordance with the necessary deploy set, you have to add the necessary fields into request._ Request \u00b6 POST /api/v1/edp/codebase Application (Create) \u00b6 { \"name\": \"app01\", \"type\": \"application\", \"strategy\": \"create\", \"lang\": \"java\", \"framework\": \"springboot\", \"buildTool\": \"maven\", \"multiModule\": false, \"route\": { \"site\": \"api\", \"path\": \"/\" }, \"database\": { \"kind\": \"postgresql\", \"version\": \"postgres:9.6\", \"capacity\": \"1Gi\", \"storage\": \"efs\" }, \"description\": \"Description\", \"gitServer\": \"gerrit\", \"jenkinsSlave\": \"maven\", \"jobProvisioning\": \"default\", \"deploymentScript\": \"openshift-template\" } Application (Clone) \u00b6 { \" name \" : \" app01 \" , \" type \" : \" application \" , \" strategy \" : \" clone \" , \" lang \" : \" java \" , \" framework \" : \" springboot \" , \" buildTool \" : \" maven \" , \" multiModule \" : false , \" repository \" : { \" url \" : \" http(s)://git.sample.com/sample.git \" , // login and password are required only if repo is private \" login \" : \" login \" , \" password \" : \" password \" }, \" description \" : \" Description \" , \" gitServer \" : \" gerrit \" , \" jenkinsSlave \" : \" maven \" , \" jobProvisioning \" : \" default \" , \" deploymentScript \" : \" openshift-template \" } Application (Import) \u00b6 { \"type\": \"application\", \"strategy\": \"import\", \"lang\": \"java\", \"framework\": \"springboot\", \"buildTool\": \"maven\", \"multiModule\": false, \"description\": \"Description\", \"gitServer\": \"git-epam\", \"gitUrlPath\": \"/relative/path/to/repo\", \"jenkinsSlave\": \"maven\", \"jobProvisioning\": \"default\", \"deploymentScript\": \"openshift-template\" } Autotests (Clone) \u00b6 { \" name \" : \" aut01 \" , \" type \" : \" autotests \" , \" strategy \" : \" clone \" , \" lang \" : \" java \" , \" framework \" : \" springboot \" , \" buildTool \" : \" maven \" , \" testReportFramework \" : \" allure \" , \" repository \" : { \" url \" : \" http(s)://git.sample.com/sample.git \" , // login and password are required only if repo is private \" login \" : \" login \" , \" password \" : \" password \" }, \" description \" : \" Description \" , \" jenkinsSlave \" : \" maven \" , \" jobProvisioning \" : \" default \" } Autotests (Import) \u00b6 { \"type\": \"autotests\", \"strategy\": \"import\", \"lang\": \"java\", \"framework\": \"springboot\", \"buildTool\": \"maven\", \"testReportFramework\": \"allure\", \"description\": \"Description\", \"gitServer\": \"git-epam\", \"gitRelativePath\": \"/relative/path/to/repo\", \"jenkinsSlave\": \"maven\", \"jobProvisioning\": \"default\" } Library (Create) \u00b6 { \"name\": \"lib01\", \"type\": \"library\", \"strategy\": \"create\", \"lang\": \"java\", \"buildTool\": \"maven\", \"multiModule\": false, \"jenkinsSlave\": \"maven\", \"jobProvisioning\": \"default\", } Library (Clone) \u00b6 { \" name \" : \" lib01 \" , \" type \" : \" library \" , \" strategy \" : \" clone \" , \" lang \" : \" java \" , \" buildTool \" : \" maven \" , \" multiModule \" : false , \" repository \" : { \" url \" : \" http(s)://git.sample.com/sample.git \" , // login and password are required only if repo is private \" login \" : \" login \" , \" password \" : \" password \" }, \" vcs \" : null , \" jenkinsSlave \" : \" maven \" , \" jobProvisioning \" : \" default \" , } Library (Import) \u00b6 { \"type\": \"library\", \"strategy\": \"import\", \"lang\": \"java\", \"buildTool\": \"maven\", \"multiModule\": false, \"gitServer\": \"git-epam\", \"gitUrlPath\": \"/relative/path/to/repo\", \"jenkinsSlave\": \"maven\", \"jobProvisioning\": \"default\", } Response \u00b6 Status 200 OK Get Codebase by Name \u00b6 Request \u00b6 GET /api/v1/edp/codebase/{codebaseName} example: localhost/api/v1/edp/codebase/app01 Response \u00b6 Status 200 OK { \"id\" : 1 , \"name\" : \"app01\" , \"language\" : \"java\" , \"build_tool\" : \"maven\" , \"framework\" : \"springboot\" , \"strategy\" : \"create\" , \"git_url\" : \"\" , \"route_site\" : \"api\" , \"route_path\" : \"/\" , \"type\" : \"application\" , \"status\" : \"active\" , \"testReportFramework\" : \"\" , \"description\" : \"Description\" , \"codebase_branch\" : [ { \"id\" : 1 , \"branchName\" : \"master\" , \"from_commit\" : \"\" , \"status\" : \"active\" , \"branchLink\" : \"\" , \"jenkinsLink\" : \"\" , \"appName\" : \"\" , \"codebaseDockerStream\" : null } ], \"gitServer\" : \"gerrit\" , \"gitProjectPath\" : null , \"jenkinsSlave\" : \"maven\" , \"jobProvisioning\" : \"default\" , \"deploymentScript\" : \"openshift-template\" } Get All Codebases \u00b6 Request \u00b6 GET /api/v1/edp/codebase?type={codebaseType} example: localhost/api/v1/edp/codebase?type=application Response \u00b6 Status 200 OK [ { \"id\" : 1 , \"name\" : \"app01\" , \"language\" : \"java\" , \"build_tool\" : \"maven\" , \"framework\" : \"springboot\" , \"strategy\" : \"create\" , \"git_url\" : \"\" , \"route_site\" : \"api\" , \"route_path\" : \"/\" , \"type\" : \"application\" , \"status\" : \"active\" , \"testReportFramework\" : \"\" , \"description\" : \"Description\" , \"codebase_branch\" : [ { \"id\" : 1 , \"branchName\" : \"master\" , \"from_commit\" : \"\" , \"status\" : \"active\" , \"branchLink\" : \"\" , \"jenkinsLink\" : \"\" , \"appName\" : \"\" , \"codebaseDockerStream\" : [ { \"id\" : 1 , \"ocImageStreamName\" : \"app01-master\" , \"imageLink\" : \"\" , \"jenkinsLink\" : \"\" } ] } ], \"gitServer\" : \"gerrit\" , \"gitProjectPath\" : null , \"jenkinsSlave\" : \"maven\" , \"jobProvisioning\" : \"\" , \"deploymentScript\" : \"openshift-template\" }, { \"id\" : 2 , \"name\" : \"app02\" , \"language\" : \"java\" , \"build_tool\" : \"maven\" , \"framework\" : \"springboot\" , \"strategy\" : \"create\" , \"git_url\" : \"\" , \"route_site\" : \"app\" , \"route_path\" : \"/\" , \"type\" : \"application\" , \"status\" : \"failed\" , \"testReportFramework\" : \"\" , \"description\" : \"\" , \"codebase_branch\" : [ { \"id\" : 2 , \"branchName\" : \"master\" , \"from_commit\" : \"\" , \"status\" : \"inactive\" , \"branchLink\" : \"\" , \"jenkinsLink\" : \"\" , \"appName\" : \"\" , \"codebaseDockerStream\" : [ { \"id\" : 2 , \"ocImageStreamName\" : \"app02-master\" , \"imageLink\" : \"\" , \"jenkinsLink\" : \"\" } ] } ], \"gitServer\" : \"gerrit\" , \"gitProjectPath\" : null , \"jenkinsSlave\" : \"maven\" , \"jobProvisioning\" : \"\" , \"deploymentScript\" : \"openshift-template\" } ] Create CD Pipeline Entity \u00b6 Request \u00b6 POST /api/v1/edp/cd-pipeline { \"name\":\"pipe1\", \"applications\":[ { \"appName\":\"app01\", \"inputDockerStream\":\"app01-master\" } ], \"stages\":[ { \"name\":\"sit\", \"description\":\"description-sit\", \"qualityGateType\":\"manual\", \"stepName\":\"approve\", \"triggerType\":\"manual\", \"order\":0, \"qualityGates\": [ { \"qualityGateType\":\"manual\", \"stepName\":\"step-one-one\", \"autotestName\": null, \"branchName\": null }, { \"qualityGateType\":\"manual\", \"stepName\":\"step-two-two\", \"autotestName\": null, \"branchName\": null } ] } ] } Response \u00b6 Status 200 OK Get CD Pipeline Entity by Name \u00b6 Request \u00b6 GET /api/v1/edp/cd-pipeline/{cdPipelineName} example: localhost/api/v1/edp/cd-pipeline/pipe1 Response \u00b6 Status 200 OK { \"id\": 1, \"name\": \"pipe1\", \"status\": \"active\", \"jenkinsLink\": \"\", \"codebaseBranches\": [ { \"id\": 1, \"branchName\": \"master\", \"from_commit\": \"\", \"status\": \"active\", \"branchLink\": \"\", \"jenkinsLink\": \"\", \"appName\": \"java-springboot-helloworld\", \"codebaseDockerStream\": [ { \"id\": 1, \"ocImageStreamName\": \"java-springboot-helloworld-master\", \"imageLink\": \"\", \"jenkinsLink\": \"\" } ] } ], \"stages\": [ { \"id\": 1, \"name\": \"sit\", \"description\": \"sit\", \"triggerType\": \"manual\", \"order\": 0, \"platformProjectLink\": \"\", \"platformProjectName\": env-am-test-deploy-sit\", \"qualityGates\": [ { \"id\": 1, \"qualityGateType\": \"manual\", \"stepName\": \"manual\", \"cdStageId\": 1, \"autotest\": null, \"codebaseBranch\": null } ], \"source\": { \"type\": \"library\", \"library\": { \"name\": \"lib01\", \"branch\": \"master\" } } } ], \"services\": [], \"applicationsToPromote\": [ \"java-springboot-helloworld\" ] } Get CD Stage Entity by Pipeline and Stage Names \u00b6 Request \u00b6 GET /api/v1/edp/cd-pipeline/{cdPipelineName}/stage/{stageName} example: `localhost/api/v1/edp/cd-pipeline/pipe1/stage/sit Response \u00b6 { \"name\": \"sit\", \"cdPipeline\": \"pipe1\", \"description\": \"sit\", \"triggerType\": \"manual\", \"order\": \"0\", \"applications\": [ { \"name\": \"java-springboot-helloworld\", \"branchName\": \"master\", \"inputIs\": \"java-springboot-helloworld-master\", \"outputIs\": \"am-test-deploy-sit-java-springboot-helloworld-verified\" } ], \"qualityGates\": [ { \"id\": 1, \"qualityGateType\": \"manual\", \"stepName\": \"manual\", \"cdStageId\": 1, \"autotest\": null, \"codebaseBranch\": null } ] } Update CD Pipeline Entity \u00b6 Request \u00b6 PUT /api/v1/edp/cd-pipeline/{cdPipelineName}/update example: localhost/api/v1/edp/cd-pipeline/pipe1/update Change Set of Applications \u00b6 { \"applications\":[ { \"appName\":\"app01\", \"inputDockerStream\":\"app01-master\" }, { \"appName\":\"app02\", \"inputDockerStream\":\"app02\" } ] } Response \u00b6 204 No Cont ent Change Set of Stages \u00b6 { \"stages\": [ { \"name\": \"sit\", \"description\": \"sit\", \"triggerType\": \"manual\", \"order\": 0, \"platformProjectLink\": \"\", \"platformProjectName\": env-deploy-sit\", \"qualityGates\": [ { \"id\": 1, \"qualityGateType\": \"manual\", \"stepName\": \"manual\", \"cdStageId\": 1, \"autotest\": null, \"codebaseBranch\": null } ], \"source\": { \"type\": \"library\", \"library\": { \"name\": \"lib01\", \"branch\": \"master\" } } } ] } Response \u00b6 204 No Cont ent","title":"EDP API"},{"location":"developer-guide/rest-api/#edp-api","text":"","title":"EDP API"},{"location":"developer-guide/rest-api/#create-codebase-entity","text":"EDP allows you to create three codebase types: Application, Autotest and Library. There are also several strategy types for each codebase: Create, Clone and Import. Depending on the selected codebase type and the respective strategy, you should specify a different set of fields in a request. Note The Route, Database and VCS are optional fields. In accordance with the necessary deploy set, you have to add the necessary fields into request._","title":"Create Codebase Entity"},{"location":"developer-guide/rest-api/#request","text":"POST /api/v1/edp/codebase","title":"Request"},{"location":"developer-guide/rest-api/#application-create","text":"{ \"name\": \"app01\", \"type\": \"application\", \"strategy\": \"create\", \"lang\": \"java\", \"framework\": \"springboot\", \"buildTool\": \"maven\", \"multiModule\": false, \"route\": { \"site\": \"api\", \"path\": \"/\" }, \"database\": { \"kind\": \"postgresql\", \"version\": \"postgres:9.6\", \"capacity\": \"1Gi\", \"storage\": \"efs\" }, \"description\": \"Description\", \"gitServer\": \"gerrit\", \"jenkinsSlave\": \"maven\", \"jobProvisioning\": \"default\", \"deploymentScript\": \"openshift-template\" }","title":"Application (Create)"},{"location":"developer-guide/rest-api/#application-clone","text":"{ \" name \" : \" app01 \" , \" type \" : \" application \" , \" strategy \" : \" clone \" , \" lang \" : \" java \" , \" framework \" : \" springboot \" , \" buildTool \" : \" maven \" , \" multiModule \" : false , \" repository \" : { \" url \" : \" http(s)://git.sample.com/sample.git \" , // login and password are required only if repo is private \" login \" : \" login \" , \" password \" : \" password \" }, \" description \" : \" Description \" , \" gitServer \" : \" gerrit \" , \" jenkinsSlave \" : \" maven \" , \" jobProvisioning \" : \" default \" , \" deploymentScript \" : \" openshift-template \" }","title":"Application (Clone)"},{"location":"developer-guide/rest-api/#application-import","text":"{ \"type\": \"application\", \"strategy\": \"import\", \"lang\": \"java\", \"framework\": \"springboot\", \"buildTool\": \"maven\", \"multiModule\": false, \"description\": \"Description\", \"gitServer\": \"git-epam\", \"gitUrlPath\": \"/relative/path/to/repo\", \"jenkinsSlave\": \"maven\", \"jobProvisioning\": \"default\", \"deploymentScript\": \"openshift-template\" }","title":"Application (Import)"},{"location":"developer-guide/rest-api/#autotests-clone","text":"{ \" name \" : \" aut01 \" , \" type \" : \" autotests \" , \" strategy \" : \" clone \" , \" lang \" : \" java \" , \" framework \" : \" springboot \" , \" buildTool \" : \" maven \" , \" testReportFramework \" : \" allure \" , \" repository \" : { \" url \" : \" http(s)://git.sample.com/sample.git \" , // login and password are required only if repo is private \" login \" : \" login \" , \" password \" : \" password \" }, \" description \" : \" Description \" , \" jenkinsSlave \" : \" maven \" , \" jobProvisioning \" : \" default \" }","title":"Autotests (Clone)"},{"location":"developer-guide/rest-api/#autotests-import","text":"{ \"type\": \"autotests\", \"strategy\": \"import\", \"lang\": \"java\", \"framework\": \"springboot\", \"buildTool\": \"maven\", \"testReportFramework\": \"allure\", \"description\": \"Description\", \"gitServer\": \"git-epam\", \"gitRelativePath\": \"/relative/path/to/repo\", \"jenkinsSlave\": \"maven\", \"jobProvisioning\": \"default\" }","title":"Autotests (Import)"},{"location":"developer-guide/rest-api/#library-create","text":"{ \"name\": \"lib01\", \"type\": \"library\", \"strategy\": \"create\", \"lang\": \"java\", \"buildTool\": \"maven\", \"multiModule\": false, \"jenkinsSlave\": \"maven\", \"jobProvisioning\": \"default\", }","title":"Library (Create)"},{"location":"developer-guide/rest-api/#library-clone","text":"{ \" name \" : \" lib01 \" , \" type \" : \" library \" , \" strategy \" : \" clone \" , \" lang \" : \" java \" , \" buildTool \" : \" maven \" , \" multiModule \" : false , \" repository \" : { \" url \" : \" http(s)://git.sample.com/sample.git \" , // login and password are required only if repo is private \" login \" : \" login \" , \" password \" : \" password \" }, \" vcs \" : null , \" jenkinsSlave \" : \" maven \" , \" jobProvisioning \" : \" default \" , }","title":"Library (Clone)"},{"location":"developer-guide/rest-api/#library-import","text":"{ \"type\": \"library\", \"strategy\": \"import\", \"lang\": \"java\", \"buildTool\": \"maven\", \"multiModule\": false, \"gitServer\": \"git-epam\", \"gitUrlPath\": \"/relative/path/to/repo\", \"jenkinsSlave\": \"maven\", \"jobProvisioning\": \"default\", }","title":"Library (Import)"},{"location":"developer-guide/rest-api/#response","text":"Status 200 OK","title":"Response"},{"location":"developer-guide/rest-api/#get-codebase-by-name","text":"","title":"Get Codebase by Name"},{"location":"developer-guide/rest-api/#request_1","text":"GET /api/v1/edp/codebase/{codebaseName} example: localhost/api/v1/edp/codebase/app01","title":"Request"},{"location":"developer-guide/rest-api/#response_1","text":"Status 200 OK { \"id\" : 1 , \"name\" : \"app01\" , \"language\" : \"java\" , \"build_tool\" : \"maven\" , \"framework\" : \"springboot\" , \"strategy\" : \"create\" , \"git_url\" : \"\" , \"route_site\" : \"api\" , \"route_path\" : \"/\" , \"type\" : \"application\" , \"status\" : \"active\" , \"testReportFramework\" : \"\" , \"description\" : \"Description\" , \"codebase_branch\" : [ { \"id\" : 1 , \"branchName\" : \"master\" , \"from_commit\" : \"\" , \"status\" : \"active\" , \"branchLink\" : \"\" , \"jenkinsLink\" : \"\" , \"appName\" : \"\" , \"codebaseDockerStream\" : null } ], \"gitServer\" : \"gerrit\" , \"gitProjectPath\" : null , \"jenkinsSlave\" : \"maven\" , \"jobProvisioning\" : \"default\" , \"deploymentScript\" : \"openshift-template\" }","title":"Response"},{"location":"developer-guide/rest-api/#get-all-codebases","text":"","title":"Get All Codebases"},{"location":"developer-guide/rest-api/#request_2","text":"GET /api/v1/edp/codebase?type={codebaseType} example: localhost/api/v1/edp/codebase?type=application","title":"Request"},{"location":"developer-guide/rest-api/#response_2","text":"Status 200 OK [ { \"id\" : 1 , \"name\" : \"app01\" , \"language\" : \"java\" , \"build_tool\" : \"maven\" , \"framework\" : \"springboot\" , \"strategy\" : \"create\" , \"git_url\" : \"\" , \"route_site\" : \"api\" , \"route_path\" : \"/\" , \"type\" : \"application\" , \"status\" : \"active\" , \"testReportFramework\" : \"\" , \"description\" : \"Description\" , \"codebase_branch\" : [ { \"id\" : 1 , \"branchName\" : \"master\" , \"from_commit\" : \"\" , \"status\" : \"active\" , \"branchLink\" : \"\" , \"jenkinsLink\" : \"\" , \"appName\" : \"\" , \"codebaseDockerStream\" : [ { \"id\" : 1 , \"ocImageStreamName\" : \"app01-master\" , \"imageLink\" : \"\" , \"jenkinsLink\" : \"\" } ] } ], \"gitServer\" : \"gerrit\" , \"gitProjectPath\" : null , \"jenkinsSlave\" : \"maven\" , \"jobProvisioning\" : \"\" , \"deploymentScript\" : \"openshift-template\" }, { \"id\" : 2 , \"name\" : \"app02\" , \"language\" : \"java\" , \"build_tool\" : \"maven\" , \"framework\" : \"springboot\" , \"strategy\" : \"create\" , \"git_url\" : \"\" , \"route_site\" : \"app\" , \"route_path\" : \"/\" , \"type\" : \"application\" , \"status\" : \"failed\" , \"testReportFramework\" : \"\" , \"description\" : \"\" , \"codebase_branch\" : [ { \"id\" : 2 , \"branchName\" : \"master\" , \"from_commit\" : \"\" , \"status\" : \"inactive\" , \"branchLink\" : \"\" , \"jenkinsLink\" : \"\" , \"appName\" : \"\" , \"codebaseDockerStream\" : [ { \"id\" : 2 , \"ocImageStreamName\" : \"app02-master\" , \"imageLink\" : \"\" , \"jenkinsLink\" : \"\" } ] } ], \"gitServer\" : \"gerrit\" , \"gitProjectPath\" : null , \"jenkinsSlave\" : \"maven\" , \"jobProvisioning\" : \"\" , \"deploymentScript\" : \"openshift-template\" } ]","title":"Response"},{"location":"developer-guide/rest-api/#create-cd-pipeline-entity","text":"","title":"Create CD Pipeline Entity"},{"location":"developer-guide/rest-api/#request_3","text":"POST /api/v1/edp/cd-pipeline { \"name\":\"pipe1\", \"applications\":[ { \"appName\":\"app01\", \"inputDockerStream\":\"app01-master\" } ], \"stages\":[ { \"name\":\"sit\", \"description\":\"description-sit\", \"qualityGateType\":\"manual\", \"stepName\":\"approve\", \"triggerType\":\"manual\", \"order\":0, \"qualityGates\": [ { \"qualityGateType\":\"manual\", \"stepName\":\"step-one-one\", \"autotestName\": null, \"branchName\": null }, { \"qualityGateType\":\"manual\", \"stepName\":\"step-two-two\", \"autotestName\": null, \"branchName\": null } ] } ] }","title":"Request"},{"location":"developer-guide/rest-api/#response_3","text":"Status 200 OK","title":"Response"},{"location":"developer-guide/rest-api/#get-cd-pipeline-entity-by-name","text":"","title":"Get CD Pipeline Entity by Name"},{"location":"developer-guide/rest-api/#request_4","text":"GET /api/v1/edp/cd-pipeline/{cdPipelineName} example: localhost/api/v1/edp/cd-pipeline/pipe1","title":"Request"},{"location":"developer-guide/rest-api/#response_4","text":"Status 200 OK { \"id\": 1, \"name\": \"pipe1\", \"status\": \"active\", \"jenkinsLink\": \"\", \"codebaseBranches\": [ { \"id\": 1, \"branchName\": \"master\", \"from_commit\": \"\", \"status\": \"active\", \"branchLink\": \"\", \"jenkinsLink\": \"\", \"appName\": \"java-springboot-helloworld\", \"codebaseDockerStream\": [ { \"id\": 1, \"ocImageStreamName\": \"java-springboot-helloworld-master\", \"imageLink\": \"\", \"jenkinsLink\": \"\" } ] } ], \"stages\": [ { \"id\": 1, \"name\": \"sit\", \"description\": \"sit\", \"triggerType\": \"manual\", \"order\": 0, \"platformProjectLink\": \"\", \"platformProjectName\": env-am-test-deploy-sit\", \"qualityGates\": [ { \"id\": 1, \"qualityGateType\": \"manual\", \"stepName\": \"manual\", \"cdStageId\": 1, \"autotest\": null, \"codebaseBranch\": null } ], \"source\": { \"type\": \"library\", \"library\": { \"name\": \"lib01\", \"branch\": \"master\" } } } ], \"services\": [], \"applicationsToPromote\": [ \"java-springboot-helloworld\" ] }","title":"Response"},{"location":"developer-guide/rest-api/#get-cd-stage-entity-by-pipeline-and-stage-names","text":"","title":"Get CD Stage Entity by Pipeline and Stage Names"},{"location":"developer-guide/rest-api/#request_5","text":"GET /api/v1/edp/cd-pipeline/{cdPipelineName}/stage/{stageName} example: `localhost/api/v1/edp/cd-pipeline/pipe1/stage/sit","title":"Request"},{"location":"developer-guide/rest-api/#response_5","text":"{ \"name\": \"sit\", \"cdPipeline\": \"pipe1\", \"description\": \"sit\", \"triggerType\": \"manual\", \"order\": \"0\", \"applications\": [ { \"name\": \"java-springboot-helloworld\", \"branchName\": \"master\", \"inputIs\": \"java-springboot-helloworld-master\", \"outputIs\": \"am-test-deploy-sit-java-springboot-helloworld-verified\" } ], \"qualityGates\": [ { \"id\": 1, \"qualityGateType\": \"manual\", \"stepName\": \"manual\", \"cdStageId\": 1, \"autotest\": null, \"codebaseBranch\": null } ] }","title":"Response"},{"location":"developer-guide/rest-api/#update-cd-pipeline-entity","text":"","title":"Update CD Pipeline Entity"},{"location":"developer-guide/rest-api/#request_6","text":"PUT /api/v1/edp/cd-pipeline/{cdPipelineName}/update example: localhost/api/v1/edp/cd-pipeline/pipe1/update","title":"Request"},{"location":"developer-guide/rest-api/#change-set-of-applications","text":"{ \"applications\":[ { \"appName\":\"app01\", \"inputDockerStream\":\"app01-master\" }, { \"appName\":\"app02\", \"inputDockerStream\":\"app02\" } ] }","title":"Change Set of Applications"},{"location":"developer-guide/rest-api/#response_6","text":"204 No Cont ent","title":"Response"},{"location":"developer-guide/rest-api/#change-set-of-stages","text":"{ \"stages\": [ { \"name\": \"sit\", \"description\": \"sit\", \"triggerType\": \"manual\", \"order\": 0, \"platformProjectLink\": \"\", \"platformProjectName\": env-deploy-sit\", \"qualityGates\": [ { \"id\": 1, \"qualityGateType\": \"manual\", \"stepName\": \"manual\", \"cdStageId\": 1, \"autotest\": null, \"codebaseBranch\": null } ], \"source\": { \"type\": \"library\", \"library\": { \"name\": \"lib01\", \"branch\": \"master\" } } } ] }","title":"Change Set of Stages"},{"location":"developer-guide/rest-api/#response_7","text":"204 No Cont ent","title":"Response"},{"location":"operator-guide/","text":"Overview \u00b6 This guide is for DevOps who installs/configure/customize EDP and also support platform","title":"Overview"},{"location":"operator-guide/#overview","text":"This guide is for DevOps who installs/configure/customize EDP and also support platform","title":"Overview"},{"location":"operator-guide/add-other-code-language/","text":"Add Other Code Language \u00b6 There is an ability to extend the default code languages when creating a codebase with the clone strategy. Warning The create strategy does not allow to customize the default code language set. In order to customize the Build Tool list, perform the following: Navigate to OpenShift, and edit the edp-admin-console deployment by adding the necessary code language into the BUILD TOOLS field. Note Use the comma sign to separate the code languages in order to make them available, e.g. maven, gradle. Add the Jenkins slave by following the Add Jenkins Slave instruction. As a result, the newly added Jenkins slave will be available in the Select Jenkins Slave dropdown list of the Advanced Settings block during the codebase creation: Extend or modify the Jenkins provisioner by following the Add Job Provisioner instruction. If it is necessary to create Code Review and Build pipelines, add corresponding entries (e.g. stages[Build-application-docker], [Code-review-application-docker]). See the example below: ... stages [ ' Code - review - application - docker ' ] = ' [ { \"name\" : \"gerrit-checkout\" } ' + \"${commitValidateStage}\" + ' ,{ \"name\" : \"sonar\" } ] ' stages [ ' Build - application - docker ' ] = ' [ { \"name\" : \"checkout\" },{ \"name\" : \"get-version\" },{ \"name\" : \"sonar\" }, ' + ' { \"name\" : \"build-image-kaniko\" } ' + \"${createJFVStage}\" + ' ,{ \"name\" : \"git-tag\" } ] ' ... Note Application is one of the available options. Another option might be to add a library. Please refer to the Add Library page for details._ Related Articles \u00b6 Add Jenkins Slave Add Job Provisioner Add Library","title":"Add Other Code Language"},{"location":"operator-guide/add-other-code-language/#add-other-code-language","text":"There is an ability to extend the default code languages when creating a codebase with the clone strategy. Warning The create strategy does not allow to customize the default code language set. In order to customize the Build Tool list, perform the following: Navigate to OpenShift, and edit the edp-admin-console deployment by adding the necessary code language into the BUILD TOOLS field. Note Use the comma sign to separate the code languages in order to make them available, e.g. maven, gradle. Add the Jenkins slave by following the Add Jenkins Slave instruction. As a result, the newly added Jenkins slave will be available in the Select Jenkins Slave dropdown list of the Advanced Settings block during the codebase creation: Extend or modify the Jenkins provisioner by following the Add Job Provisioner instruction. If it is necessary to create Code Review and Build pipelines, add corresponding entries (e.g. stages[Build-application-docker], [Code-review-application-docker]). See the example below: ... stages [ ' Code - review - application - docker ' ] = ' [ { \"name\" : \"gerrit-checkout\" } ' + \"${commitValidateStage}\" + ' ,{ \"name\" : \"sonar\" } ] ' stages [ ' Build - application - docker ' ] = ' [ { \"name\" : \"checkout\" },{ \"name\" : \"get-version\" },{ \"name\" : \"sonar\" }, ' + ' { \"name\" : \"build-image-kaniko\" } ' + \"${createJFVStage}\" + ' ,{ \"name\" : \"git-tag\" } ] ' ... Note Application is one of the available options. Another option might be to add a library. Please refer to the Add Library page for details._","title":"Add Other Code Language"},{"location":"operator-guide/add-other-code-language/#related-articles","text":"Add Jenkins Slave Add Job Provisioner Add Library","title":"Related Articles"},{"location":"operator-guide/aws-irsa/","text":"Associate IAM Roles With Service Accounts \u00b6 This page contains accurate information on how to associate an IAM role with the service account in EPAM Delivery Platform. Get acquainted with the AWS Official Documentation on the subject before proceeding. To successfully associate the IAM role with the service account, follow the steps below: Create an IAM role that will further be associated with the service account. This role must have the following trust policy: IAM Role { \"Version\": \"2012-10-17\", \"Statement\": [ { \"Effect\": \"Allow\", \"Principal\": { \"Federated\": \"arn:aws:iam::<AWS_ACCOUNT_ID>:oidc-provider/<OIDC_PROVIDER>\" }, \"Action\": \"sts:AssumeRoleWithWebIdentity\", \"Condition\": { \"StringEquals\": { \"<OIDC_PROVIDER>:sub\": \"system:serviceaccount:<SERVICE_ACCOUNT_NAMESPACE>:<SERVICE_ACCOUNT_NAME>\" } } } ] } Deploy the amazon-eks-pod-identity-webhook as described below: 2.1. Provide the stable version of the Docker image in the deploy/deployment-base.yaml file. 2.2. Provide ${CA_BUNDLE} in the deploy/mutatingwebhook.yaml file: secret_name=$(kubectl -n default get sa default -o jsonpath='{.secrets[0].name}') \\ CA_BUNDLE=$(kubectl -n default get secret/$secret_name -o jsonpath='{.data.ca\\.crt}' | tr -d '\\n') 2.3. Deploy the Webhook: kubectl apply -f deploy/ 2.4. Approve the csr : csr_name=$(kubectl get csr -o jsonpath='{.items[?(@.spec.username==\"system:serviceaccount:default:pod-identity-webhook\")].metadata.name}') kubectl certificate approve $csr_name Annotate the created service account with the IAM role: Service Account apiVersion: v1 kind: ServiceAccount metadata: name: <SERVICE_ACCOUNT_NAME> namespace: <NAMESPACE> annotations: eks.amazonaws.com/role-arn: \"arn:aws:iam::<AWS_ACCOUNT_ID>:role/<IAM_ROLE_NAME>\" All newly launched pods with this service account will be modified and then use the associated IAM role. Find below the pod specification template: Pod Template apiVersion: v1 kind: Pod metadata: name: <POD_NAME> namespace: <POD_NAMESPACE> spec: serviceAccountName: <SERVICE_ACCOUNT_NAME> securityContext: fsGroup: 65534 containers: - name: terraform image: epamedp/edp-jenkins-terraform-agent:2.0.2 command: ['sh', '-c', 'echo \"Hello, Kubernetes!\" && sleep 3600'] Related Articles \u00b6 Use Terraform Library in EDP","title":"Enable IRSA (AWS)"},{"location":"operator-guide/aws-irsa/#associate-iam-roles-with-service-accounts","text":"This page contains accurate information on how to associate an IAM role with the service account in EPAM Delivery Platform. Get acquainted with the AWS Official Documentation on the subject before proceeding. To successfully associate the IAM role with the service account, follow the steps below: Create an IAM role that will further be associated with the service account. This role must have the following trust policy: IAM Role { \"Version\": \"2012-10-17\", \"Statement\": [ { \"Effect\": \"Allow\", \"Principal\": { \"Federated\": \"arn:aws:iam::<AWS_ACCOUNT_ID>:oidc-provider/<OIDC_PROVIDER>\" }, \"Action\": \"sts:AssumeRoleWithWebIdentity\", \"Condition\": { \"StringEquals\": { \"<OIDC_PROVIDER>:sub\": \"system:serviceaccount:<SERVICE_ACCOUNT_NAMESPACE>:<SERVICE_ACCOUNT_NAME>\" } } } ] } Deploy the amazon-eks-pod-identity-webhook as described below: 2.1. Provide the stable version of the Docker image in the deploy/deployment-base.yaml file. 2.2. Provide ${CA_BUNDLE} in the deploy/mutatingwebhook.yaml file: secret_name=$(kubectl -n default get sa default -o jsonpath='{.secrets[0].name}') \\ CA_BUNDLE=$(kubectl -n default get secret/$secret_name -o jsonpath='{.data.ca\\.crt}' | tr -d '\\n') 2.3. Deploy the Webhook: kubectl apply -f deploy/ 2.4. Approve the csr : csr_name=$(kubectl get csr -o jsonpath='{.items[?(@.spec.username==\"system:serviceaccount:default:pod-identity-webhook\")].metadata.name}') kubectl certificate approve $csr_name Annotate the created service account with the IAM role: Service Account apiVersion: v1 kind: ServiceAccount metadata: name: <SERVICE_ACCOUNT_NAME> namespace: <NAMESPACE> annotations: eks.amazonaws.com/role-arn: \"arn:aws:iam::<AWS_ACCOUNT_ID>:role/<IAM_ROLE_NAME>\" All newly launched pods with this service account will be modified and then use the associated IAM role. Find below the pod specification template: Pod Template apiVersion: v1 kind: Pod metadata: name: <POD_NAME> namespace: <POD_NAMESPACE> spec: serviceAccountName: <SERVICE_ACCOUNT_NAME> securityContext: fsGroup: 65534 containers: - name: terraform image: epamedp/edp-jenkins-terraform-agent:2.0.2 command: ['sh', '-c', 'echo \"Hello, Kubernetes!\" && sleep 3600']","title":"Associate IAM Roles With Service Accounts"},{"location":"operator-guide/aws-irsa/#related-articles","text":"Use Terraform Library in EDP","title":"Related Articles"},{"location":"operator-guide/github-integration/","text":"GitHub Integration \u00b6 Discover the steps below to apply the GitHub integration correctly: Create access token for GitHub: Click the profile account and navigate to Settings; Go to Developer Settings; Select Personal access token and generate a new one with the following parameters Warning Make sure to copy your new personal access token right at this moment because there will not be any ability to see it again. Navigate to Jenkins -> Manage Jenkins -> Manage plugins , and click the Available tab and install the following plugins: GitHub and GitHub Pull Request Builder . Note If the necessary plugins are not available in the list, check out the Installed tab and verify whether they are presented. Navigate to Jenkins -> Credentials -> System -> Global credentials -> Add credentials , and create new credentials with the Secret text kind. In the Secret field, provide your GitHub API token, fill in the ID field with the github-access-token value: Generate and add a new SSH key to the GitHub account. To get more detailed information, please inspect the official GitHub documentation page. Note Use the same SSH key that was added to the GitServer definition. Add a private part of the SSH key to Jenkins by navigating to Jenkins -> Credentials -> System -> Global credentials -> Add credentials ; and create new credentials with the SSH username with private key kind: Navigate to Jenkins -> Manage Jenkins -> Configure system -> GitHub part, and configure the GitHub server: Configure the GitHub Pull Request Builder plugin: Note The Secret field is optional, for details, please refer to the official GitHub pull request builder plugin documentation . Create a new Job Provision by navigating to the Jenkins main page and opening the job-provisions folder: Click New Item; Type the name; Select the Freestyle project option and click OK; Select the This project is parameterized check box and add a few input parameters: NAME; TYPE; BUILD_TOOL; BRANCH; GIT_SERVER_CR_NAME; GIT_SERVER_CR_VERSION; GIT_CREDENTIALS_ID; REPOSITORY_PATH; JIRA_INTEGRATION_ENABLED; Check the Execute concurrent builds if necessary option; Check the Restrict where this project can be run option; Fill in the Label Expression field by typing the master branch name. In the Build section, perform the following: Select DSL Script ; Select the Use the provided DSL script check box: 9.Insert the following code: import groovy.json.* import jenkins.model.Jenkins import javaposse.jobdsl.plugin.* import com.cloudbees.hudson.plugins.folder.* Jenkins jenkins = Jenkins . instance def stages = [ : ] def jiraIntegrationEnabled = Boolean . parseBoolean ( \"${JIRA_INTEGRATION_ENABLED}\" as String ) def commitValidateStage = jiraIntegrationEnabled ? ' ,{ \"name\" : \"commit-validate\" } ' : '' def createJIMStage = jiraIntegrationEnabled ? ' ,{ \"name\" : \"create-jira-issue-metadata\" } ' : '' def platformType = \"${PLATFORM_TYPE}\" def buildStage = platformType == \"kubernetes\" ? ' ,{ \"name\" : \"build-image-kaniko\" }, ' : ' ,{ \"name\" : \"build-image-from-dockerfile\" }, ' def buildTool = \"${BUILD_TOOL}\" def goBuildStage = buildTool . toString () == \"go\" ? ' ,{ \"name\" : \"build\" } ' : ' ,{ \"name\" : \"compile\" } ' stages [ ' Code - review - application ' ] = ' [ { \"name\" : \"checkout\" } ' + \"${commitValidateStage}\" + goBuildStage + ' ,{ \"name\" : \"tests\" },{ \"name\" : \"sonar\" } ] ' stages [ ' Code - review - library ' ] = ' [ { \"name\" : \"checkout\" } ' + \"${commitValidateStage}\" + ' ,{ \"name\" : \"compile\" },{ \"name\" : \"tests\" }, ' + ' { \"name\" : \"sonar\" } ] ' stages [ ' Code - review - autotests ' ] = ' [ { \"name\" : \"checkout\" } ' + \"${commitValidateStage}\" + ' ,{ \"name\" : \"tests\" },{ \"name\" : \"sonar\" } ] ' stages [ ' Build - library - maven ' ] = ' [ { \"name\" : \"checkout\" },{ \"name\" : \"get-version\" },{ \"name\" : \"compile\" }, ' + ' { \"name\" : \"tests\" },{ \"name\" : \"sonar\" },{ \"name\" : \"build\" },{ \"name\" : \"push\" },{ \"name\" : \"git-tag\" } ] ' stages [ ' Build - library - npm ' ] = stages [ ' Build - library - maven ' ] stages [ ' Build - library - gradle ' ] = stages [ ' Build - library - maven ' ] stages [ ' Build - library - dotnet ' ] = ' [ { \"name\" : \"checkout\" },{ \"name\" : \"get-version\" },{ \"name\" : \"compile\" }, ' + ' { \"name\" : \"tests\" },{ \"name\" : \"sonar\" },{ \"name\" : \"push\" } ' + \"${createJIMStage}\" + ' ,{ \"name\" : \"git-tag\" } ] ' stages [ ' Build - application - maven ' ] = ' [ { \"name\" : \"checkout\" },{ \"name\" : \"get-version\" },{ \"name\" : \"compile\" }, ' + ' { \"name\" : \"tests\" },{ \"name\" : \"sonar\" },{ \"name\" : \"build\" } ' + \"${buildStage}\" + ' { \"name\" : \"push\" } ' + \"${createJIMStage}\" + ' ,{ \"name\" : \"git-tag\" } ] ' stages [ ' Build - application - npm ' ] = stages [ ' Build - application - maven ' ] stages [ ' Build - application - gradle ' ] = stages [ ' Build - application - maven ' ] stages [ ' Build - application - dotnet ' ] = ' [ { \"name\" : \"checkout\" },{ \"name\" : \"get-version\" },{ \"name\" : \"compile\" }, ' + ' { \"name\" : \"tests\" },{ \"name\" : \"sonar\" } ' + \"${buildStage}\" + ' { \"name\" : \"push\" } ' + \"${createJIMStage}\" + ' ,{ \"name\" : \"git-tag\" } ] ' stages [ ' Build - application - go ' ] = ' [ { \"name\" : \"checkout\" },{ \"name\" : \"get-version\" },{ \"name\" : \"tests\" },{ \"name\" : \"sonar\" }, ' + ' { \"name\" : \"build\" } ' + \"${buildStage}\" + \"${createJIMStage}\" + ' ,{ \"name\" : \"git-tag\" } ] ' stages [ ' Build - application - python ' ] = ' [ { \"name\" : \"checkout\" },{ \"name\" : \"get-version\" },{ \"name\" : \"compile\" },{ \"name\" : \"tests\" },{ \"name\" : \"sonar\" } ' + \"${buildStage}\" + ' { \"name\" : \"push\" } ' + \"${createJIMStage}\" + ' ,{ \"name\" : \"git-tag\" } ] ' stages [ ' Create - release ' ] = ' [ { \"name\" : \"checkout\" },{ \"name\" : \"create-branch\" },{ \"name\" : \"trigger-job\" } ] ' def buildToolsOutOfTheBox = [ \"maven\" , \"npm\" , \"gradle\" , \"dotnet\" , \"none\" , \"go\" , \"python\" ] def defaultStages = ' [ { \"name\" : \"checkout\" } ' + \"${createJIMStage}\" + ']' def codebaseName = \"${NAME}\" def gitServerCrName = \"${GIT_SERVER_CR_NAME}\" def gitServerCrVersion = \"${GIT_SERVER_CR_VERSION}\" def gitCredentialsId = \"${GIT_CREDENTIALS_ID ? GIT_CREDENTIALS_ID : 'gerrit-ciuser-sshkey'}\" def repositoryPath = \"${REPOSITORY_PATH.replaceAll(~/:\\d+\\\\//,\" / \")}\" def githubRepository = \"https://${repositoryPath.split(\" @ \")[1]}\" def codebaseFolder = jenkins . getItem ( codebaseName ) if ( codebaseFolder == null ) { folder ( codebaseName ) } createListView ( codebaseName , \"Releases\" ) createReleasePipeline ( \"Create-release-${codebaseName}\" , codebaseName , stages [ \"Create-release\" ] , \"create-release.groovy\" , repositoryPath , gitCredentialsId , gitServerCrName , gitServerCrVersion , jiraIntegrationEnabled , platformType ) if ( buildTool . toString (). equalsIgnoreCase ( ' none ' )) { return true } if ( BRANCH ) { def branch = \"${BRANCH}\" def formattedBranch = \"${branch.toUpperCase().replaceAll(/\\\\//, \" - \")}\" createListView ( codebaseName , formattedBranch ) def type = \"${TYPE}\" def supBuildTool = buildToolsOutOfTheBox . contains ( buildTool . toString ()) def crKey = \"Code-review-${type}\" . toString () createCodeReviewPipeline ( \"Code-review-${codebaseName}\" , codebaseName , stages . get ( crKey , defaultStages ), \"code-review.groovy\" , repositoryPath , gitCredentialsId , branch , gitServerCrName , gitServerCrVersion , githubRepository ) registerWebHook ( repositoryPath ) def buildKey = \"Build-${type}-${buildTool.toLowerCase()}\" . toString () if ( type . equalsIgnoreCase ( ' application ' ) || type . equalsIgnoreCase ( ' library ' )) { def jobExists = false if ( \"${formattedBranch}-Build-${codebaseName}\" . toString () in Jenkins . instance . getAllItems (). collect { it . name }) jobExists = true createBuildPipeline ( \"Build-${codebaseName}\" , codebaseName , stages . get ( buildKey , defaultStages ), \"build.groovy\" , repositoryPath , gitCredentialsId , branch , gitServerCrName , gitServerCrVersion , githubRepository ) registerWebHook ( repositoryPath , ' build ' ) if ( ! jobExists ) queue ( \"${codebaseName}/${formattedBranch}-Build-${codebaseName}\" ) } } def createCodeReviewPipeline ( pipelineName , codebaseName , codebaseStages , pipelineScript , repository , credId , watchBranch = \"master\" , gitServerCrName , gitServerCrVersion , githubRepository ) { pipelineJob ( \"${codebaseName}/${watchBranch.toUpperCase().replaceAll(/\\\\//, \" - \")}-${pipelineName}\" ) { logRotator { numToKeep ( 10 ) daysToKeep ( 7 ) } definition { cpsScm { scm { git { remote { url ( repository ) credentials ( credId ) refspec ( \"+refs/pull/*:refs/remotes/origin/pr/*\" ) } branches ( \"\\${ghprbActualCommit}\" ) scriptPath ( \"${pipelineScript}\" ) } } parameters { stringParam ( \"GIT_SERVER_CR_NAME\" , \"${gitServerCrName}\" , \"Name of Git Server CR to generate link to Git server\" ) stringParam ( \"GIT_SERVER_CR_VERSION\" , \"${gitServerCrVersion}\" , \"Version of GitServer CR Resource\" ) stringParam ( \"STAGES\" , \"${codebaseStages}\" , \"Consequence of stages in JSON format to be run during execution\" ) stringParam ( \"GERRIT_PROJECT_NAME\" , \"${codebaseName}\" , \"Gerrit project name(Codebase name) to be build\" ) stringParam ( \"BRANCH\" , \"${watchBranch}\" , \"Branch to build artifact from\" ) } } } triggers { githubPullRequest { cron ( '' ) onlyTriggerPhrase ( false ) useGitHubHooks ( true ) permitAll ( true ) autoCloseFailedPullRequests ( false ) displayBuildErrorsOnDownstreamBuilds ( false ) whiteListTargetBranches ( [ watchBranch . toString () ] ) extensions { commitStatus { context ( ' Jenkins Code - Review ' ) triggeredStatus ( ' Build is Triggered ' ) startedStatus ( ' Build is Started ' ) addTestResults ( true ) completedStatus ( ' SUCCESS ' , ' Verified ' ) completedStatus ( ' FAILURE ' , ' Failed ' ) completedStatus ( ' PENDING ' , ' Penging ' ) completedStatus ( ' ERROR ' , ' Error ' ) } } } } properties { githubProjectProperty { projectUrlStr ( \"${githubRepository}\" ) } } } } def createBuildPipeline ( pipelineName , codebaseName , codebaseStages , pipelineScript , repository , credId , watchBranch = \"master\" , gitServerCrName , gitServerCrVersion , githubRepository ) { pipelineJob ( \"${codebaseName}/${watchBranch.toUpperCase().replaceAll(/\\\\//, \" - \")}-${pipelineName}\" ) { logRotator { numToKeep ( 10 ) daysToKeep ( 7 ) } definition { cpsScm { scm { git { remote { url ( repository ) credentials ( credId ) } branches ( \"${watchBranch}\" ) scriptPath ( \"${pipelineScript}\" ) } } parameters { stringParam ( \"GIT_SERVER_CR_NAME\" , \"${gitServerCrName}\" , \"Name of Git Server CR to generate link to Git server\" ) stringParam ( \"GIT_SERVER_CR_VERSION\" , \"${gitServerCrVersion}\" , \"Version of GitServer CR Resource\" ) stringParam ( \"STAGES\" , \"${codebaseStages}\" , \"Consequence of stages in JSON format to be run during execution\" ) stringParam ( \"GERRIT_PROJECT_NAME\" , \"${codebaseName}\" , \"Gerrit project name(Codebase name) to be build\" ) stringParam ( \"BRANCH\" , \"${watchBranch}\" , \"Branch to run from\" ) } } } triggers { gitHubPushTrigger () } properties { githubProjectProperty { projectUrlStr ( \"${githubRepository}\" ) } } } } def createListView ( codebaseName , branchName ) { listView ( \"${codebaseName}/${branchName}\" ) { if ( branchName . toLowerCase () == \"releases\" ) { jobFilters { regex { matchType ( MatchType . INCLUDE_MATCHED ) matchValue ( RegexMatchValue . NAME ) regex ( \"^Create-release.*\" ) } } } else { jobFilters { regex { matchType ( MatchType . INCLUDE_MATCHED ) matchValue ( RegexMatchValue . NAME ) regex ( \"^${branchName}-(Code-review|Build).*\" ) } } } columns { status () weather () name () lastSuccess () lastFailure () lastDuration () buildButton () } } } def createReleasePipeline ( pipelineName , codebaseName , codebaseStages , pipelineScript , repository , credId , gitServerCrName , gitServerCrVersion , jiraIntegrationEnabled , platformType ) { pipelineJob ( \"${codebaseName}/${pipelineName}\" ) { logRotator { numToKeep ( 14 ) daysToKeep ( 30 ) } definition { cpsScm { scm { git { remote { url ( repository ) credentials ( credId ) } branches ( \"master\" ) scriptPath ( \"${pipelineScript}\" ) } } parameters { stringParam ( \"STAGES\" , \"${codebaseStages}\" , \"\" ) if ( pipelineName . contains ( \"Create-release\" )) { stringParam ( \"JIRA_INTEGRATION_ENABLED\" , \"${jiraIntegrationEnabled}\" , \"Is Jira integration enabled\" ) stringParam ( \"PLATFORM_TYPE\" , \"${platformType}\" , \"Platform type\" ) stringParam ( \"GERRIT_PROJECT\" , \"${codebaseName}\" , \"\" ) stringParam ( \"RELEASE_NAME\" , \"\" , \"Name of the release(branch to be created)\" ) stringParam ( \"COMMIT_ID\" , \"\" , \"Commit ID that will be used to create branch from for new release. If empty, HEAD of master will be used\" ) stringParam ( \"GIT_SERVER_CR_NAME\" , \"${gitServerCrName}\" , \"Name of Git Server CR to generate link to Git server\" ) stringParam ( \"GIT_SERVER_CR_VERSION\" , \"${gitServerCrVersion}\" , \"Version of GitServer CR Resource\" ) stringParam ( \"REPOSITORY_PATH\" , \"${repository}\" , \"Full repository path\" ) } } } } } } def registerWebHook ( repositoryPath , type = ' code - review ' ) { def url = repositoryPath . split ( '@' ) [ 1 ] . split ( '/' ) [ 0 ] def owner = repositoryPath . split ( '@' ) [ 1 ] . split ( '/' ) [ 1 ] def repo = repositoryPath . split ( '@' ) [ 1 ] . split ( '/' ) [ 2 ] def apiUrl = ' https : //api.' + url + '/repos/' + owner + '/' + repo + '/hooks' def webhookUrl = '' def webhookConfig = [ : ] def config = [ : ] def events = [] if ( type . equalsIgnoreCase ( ' build ' )) { webhookUrl = System . getenv ( ' JENKINS_UI_URL ' ) + \"/github-webhook/\" events = [ \"push\" ] config [ \"url\" ] = webhookUrl config [ \"content_type\" ] = \"json\" config [ \"insecure_ssl\" ] = 0 webhookConfig [ \"name\" ] = \"web\" webhookConfig [ \"config\" ] = config webhookConfig [ \"events\" ] = events webhookConfig [ \"active\" ] = true } else { webhookUrl = System . getenv ( ' JENKINS_UI_URL ' ) + \"/ghprbhook/\" events = [ \"issue_comment\" , \"pull_request\" ] config [ \"url\" ] = webhookUrl config [ \"content_type\" ] = \"form\" config [ \"insecure_ssl\" ] = 0 webhookConfig [ \"name\" ] = \"web\" webhookConfig [ \"config\" ] = config webhookConfig [ \"events\" ] = events webhookConfig [ \"active\" ] = true } def requestBody = JsonOutput . toJson ( webhookConfig ) def http = new URL ( apiUrl ). openConnection () as HttpURLConnection http . setRequestMethod ( ' POST ' ) http . setDoOutput ( true ) println ( apiUrl ) http . setRequestProperty ( \"Accept\" , ' application / json ' ) http . setRequestProperty ( \"Content-Type\" , ' application / json ' ) http . setRequestProperty ( \"Authorization\" , \"token ${getSecretValue('github-access-token')}\" ) http . outputStream . write ( requestBody . getBytes ( \"UTF-8\" )) http . connect () println ( http . responseCode ) if ( http . responseCode == 201 ) { response = new JsonSlurper (). parseText ( http . inputStream . getText ( ' UTF - 8 ' )) } else { response = new JsonSlurper (). parseText ( http . errorStream . getText ( ' UTF - 8 ' )) } println \"response: ${response}\" } def getSecretValue ( name ) { def creds = com . cloudbees . plugins . credentials . CredentialsProvider . lookupCredentials ( com . cloudbees . plugins . credentials . common . StandardCredentials . class , Jenkins . instance , null , null ) def secret = creds . find { it . properties [ ' id ' ] == name } return secret != null ? secret [ ' secret ' ] : null } As a result, the new custom job-provision will be available in the Advanced CI Settings menu during the application creation: Related Articles \u00b6 Adjust Import Strategy Adjust Integration With Jira Server","title":"Overview"},{"location":"operator-guide/github-integration/#github-integration","text":"Discover the steps below to apply the GitHub integration correctly: Create access token for GitHub: Click the profile account and navigate to Settings; Go to Developer Settings; Select Personal access token and generate a new one with the following parameters Warning Make sure to copy your new personal access token right at this moment because there will not be any ability to see it again. Navigate to Jenkins -> Manage Jenkins -> Manage plugins , and click the Available tab and install the following plugins: GitHub and GitHub Pull Request Builder . Note If the necessary plugins are not available in the list, check out the Installed tab and verify whether they are presented. Navigate to Jenkins -> Credentials -> System -> Global credentials -> Add credentials , and create new credentials with the Secret text kind. In the Secret field, provide your GitHub API token, fill in the ID field with the github-access-token value: Generate and add a new SSH key to the GitHub account. To get more detailed information, please inspect the official GitHub documentation page. Note Use the same SSH key that was added to the GitServer definition. Add a private part of the SSH key to Jenkins by navigating to Jenkins -> Credentials -> System -> Global credentials -> Add credentials ; and create new credentials with the SSH username with private key kind: Navigate to Jenkins -> Manage Jenkins -> Configure system -> GitHub part, and configure the GitHub server: Configure the GitHub Pull Request Builder plugin: Note The Secret field is optional, for details, please refer to the official GitHub pull request builder plugin documentation . Create a new Job Provision by navigating to the Jenkins main page and opening the job-provisions folder: Click New Item; Type the name; Select the Freestyle project option and click OK; Select the This project is parameterized check box and add a few input parameters: NAME; TYPE; BUILD_TOOL; BRANCH; GIT_SERVER_CR_NAME; GIT_SERVER_CR_VERSION; GIT_CREDENTIALS_ID; REPOSITORY_PATH; JIRA_INTEGRATION_ENABLED; Check the Execute concurrent builds if necessary option; Check the Restrict where this project can be run option; Fill in the Label Expression field by typing the master branch name. In the Build section, perform the following: Select DSL Script ; Select the Use the provided DSL script check box: 9.Insert the following code: import groovy.json.* import jenkins.model.Jenkins import javaposse.jobdsl.plugin.* import com.cloudbees.hudson.plugins.folder.* Jenkins jenkins = Jenkins . instance def stages = [ : ] def jiraIntegrationEnabled = Boolean . parseBoolean ( \"${JIRA_INTEGRATION_ENABLED}\" as String ) def commitValidateStage = jiraIntegrationEnabled ? ' ,{ \"name\" : \"commit-validate\" } ' : '' def createJIMStage = jiraIntegrationEnabled ? ' ,{ \"name\" : \"create-jira-issue-metadata\" } ' : '' def platformType = \"${PLATFORM_TYPE}\" def buildStage = platformType == \"kubernetes\" ? ' ,{ \"name\" : \"build-image-kaniko\" }, ' : ' ,{ \"name\" : \"build-image-from-dockerfile\" }, ' def buildTool = \"${BUILD_TOOL}\" def goBuildStage = buildTool . toString () == \"go\" ? ' ,{ \"name\" : \"build\" } ' : ' ,{ \"name\" : \"compile\" } ' stages [ ' Code - review - application ' ] = ' [ { \"name\" : \"checkout\" } ' + \"${commitValidateStage}\" + goBuildStage + ' ,{ \"name\" : \"tests\" },{ \"name\" : \"sonar\" } ] ' stages [ ' Code - review - library ' ] = ' [ { \"name\" : \"checkout\" } ' + \"${commitValidateStage}\" + ' ,{ \"name\" : \"compile\" },{ \"name\" : \"tests\" }, ' + ' { \"name\" : \"sonar\" } ] ' stages [ ' Code - review - autotests ' ] = ' [ { \"name\" : \"checkout\" } ' + \"${commitValidateStage}\" + ' ,{ \"name\" : \"tests\" },{ \"name\" : \"sonar\" } ] ' stages [ ' Build - library - maven ' ] = ' [ { \"name\" : \"checkout\" },{ \"name\" : \"get-version\" },{ \"name\" : \"compile\" }, ' + ' { \"name\" : \"tests\" },{ \"name\" : \"sonar\" },{ \"name\" : \"build\" },{ \"name\" : \"push\" },{ \"name\" : \"git-tag\" } ] ' stages [ ' Build - library - npm ' ] = stages [ ' Build - library - maven ' ] stages [ ' Build - library - gradle ' ] = stages [ ' Build - library - maven ' ] stages [ ' Build - library - dotnet ' ] = ' [ { \"name\" : \"checkout\" },{ \"name\" : \"get-version\" },{ \"name\" : \"compile\" }, ' + ' { \"name\" : \"tests\" },{ \"name\" : \"sonar\" },{ \"name\" : \"push\" } ' + \"${createJIMStage}\" + ' ,{ \"name\" : \"git-tag\" } ] ' stages [ ' Build - application - maven ' ] = ' [ { \"name\" : \"checkout\" },{ \"name\" : \"get-version\" },{ \"name\" : \"compile\" }, ' + ' { \"name\" : \"tests\" },{ \"name\" : \"sonar\" },{ \"name\" : \"build\" } ' + \"${buildStage}\" + ' { \"name\" : \"push\" } ' + \"${createJIMStage}\" + ' ,{ \"name\" : \"git-tag\" } ] ' stages [ ' Build - application - npm ' ] = stages [ ' Build - application - maven ' ] stages [ ' Build - application - gradle ' ] = stages [ ' Build - application - maven ' ] stages [ ' Build - application - dotnet ' ] = ' [ { \"name\" : \"checkout\" },{ \"name\" : \"get-version\" },{ \"name\" : \"compile\" }, ' + ' { \"name\" : \"tests\" },{ \"name\" : \"sonar\" } ' + \"${buildStage}\" + ' { \"name\" : \"push\" } ' + \"${createJIMStage}\" + ' ,{ \"name\" : \"git-tag\" } ] ' stages [ ' Build - application - go ' ] = ' [ { \"name\" : \"checkout\" },{ \"name\" : \"get-version\" },{ \"name\" : \"tests\" },{ \"name\" : \"sonar\" }, ' + ' { \"name\" : \"build\" } ' + \"${buildStage}\" + \"${createJIMStage}\" + ' ,{ \"name\" : \"git-tag\" } ] ' stages [ ' Build - application - python ' ] = ' [ { \"name\" : \"checkout\" },{ \"name\" : \"get-version\" },{ \"name\" : \"compile\" },{ \"name\" : \"tests\" },{ \"name\" : \"sonar\" } ' + \"${buildStage}\" + ' { \"name\" : \"push\" } ' + \"${createJIMStage}\" + ' ,{ \"name\" : \"git-tag\" } ] ' stages [ ' Create - release ' ] = ' [ { \"name\" : \"checkout\" },{ \"name\" : \"create-branch\" },{ \"name\" : \"trigger-job\" } ] ' def buildToolsOutOfTheBox = [ \"maven\" , \"npm\" , \"gradle\" , \"dotnet\" , \"none\" , \"go\" , \"python\" ] def defaultStages = ' [ { \"name\" : \"checkout\" } ' + \"${createJIMStage}\" + ']' def codebaseName = \"${NAME}\" def gitServerCrName = \"${GIT_SERVER_CR_NAME}\" def gitServerCrVersion = \"${GIT_SERVER_CR_VERSION}\" def gitCredentialsId = \"${GIT_CREDENTIALS_ID ? GIT_CREDENTIALS_ID : 'gerrit-ciuser-sshkey'}\" def repositoryPath = \"${REPOSITORY_PATH.replaceAll(~/:\\d+\\\\//,\" / \")}\" def githubRepository = \"https://${repositoryPath.split(\" @ \")[1]}\" def codebaseFolder = jenkins . getItem ( codebaseName ) if ( codebaseFolder == null ) { folder ( codebaseName ) } createListView ( codebaseName , \"Releases\" ) createReleasePipeline ( \"Create-release-${codebaseName}\" , codebaseName , stages [ \"Create-release\" ] , \"create-release.groovy\" , repositoryPath , gitCredentialsId , gitServerCrName , gitServerCrVersion , jiraIntegrationEnabled , platformType ) if ( buildTool . toString (). equalsIgnoreCase ( ' none ' )) { return true } if ( BRANCH ) { def branch = \"${BRANCH}\" def formattedBranch = \"${branch.toUpperCase().replaceAll(/\\\\//, \" - \")}\" createListView ( codebaseName , formattedBranch ) def type = \"${TYPE}\" def supBuildTool = buildToolsOutOfTheBox . contains ( buildTool . toString ()) def crKey = \"Code-review-${type}\" . toString () createCodeReviewPipeline ( \"Code-review-${codebaseName}\" , codebaseName , stages . get ( crKey , defaultStages ), \"code-review.groovy\" , repositoryPath , gitCredentialsId , branch , gitServerCrName , gitServerCrVersion , githubRepository ) registerWebHook ( repositoryPath ) def buildKey = \"Build-${type}-${buildTool.toLowerCase()}\" . toString () if ( type . equalsIgnoreCase ( ' application ' ) || type . equalsIgnoreCase ( ' library ' )) { def jobExists = false if ( \"${formattedBranch}-Build-${codebaseName}\" . toString () in Jenkins . instance . getAllItems (). collect { it . name }) jobExists = true createBuildPipeline ( \"Build-${codebaseName}\" , codebaseName , stages . get ( buildKey , defaultStages ), \"build.groovy\" , repositoryPath , gitCredentialsId , branch , gitServerCrName , gitServerCrVersion , githubRepository ) registerWebHook ( repositoryPath , ' build ' ) if ( ! jobExists ) queue ( \"${codebaseName}/${formattedBranch}-Build-${codebaseName}\" ) } } def createCodeReviewPipeline ( pipelineName , codebaseName , codebaseStages , pipelineScript , repository , credId , watchBranch = \"master\" , gitServerCrName , gitServerCrVersion , githubRepository ) { pipelineJob ( \"${codebaseName}/${watchBranch.toUpperCase().replaceAll(/\\\\//, \" - \")}-${pipelineName}\" ) { logRotator { numToKeep ( 10 ) daysToKeep ( 7 ) } definition { cpsScm { scm { git { remote { url ( repository ) credentials ( credId ) refspec ( \"+refs/pull/*:refs/remotes/origin/pr/*\" ) } branches ( \"\\${ghprbActualCommit}\" ) scriptPath ( \"${pipelineScript}\" ) } } parameters { stringParam ( \"GIT_SERVER_CR_NAME\" , \"${gitServerCrName}\" , \"Name of Git Server CR to generate link to Git server\" ) stringParam ( \"GIT_SERVER_CR_VERSION\" , \"${gitServerCrVersion}\" , \"Version of GitServer CR Resource\" ) stringParam ( \"STAGES\" , \"${codebaseStages}\" , \"Consequence of stages in JSON format to be run during execution\" ) stringParam ( \"GERRIT_PROJECT_NAME\" , \"${codebaseName}\" , \"Gerrit project name(Codebase name) to be build\" ) stringParam ( \"BRANCH\" , \"${watchBranch}\" , \"Branch to build artifact from\" ) } } } triggers { githubPullRequest { cron ( '' ) onlyTriggerPhrase ( false ) useGitHubHooks ( true ) permitAll ( true ) autoCloseFailedPullRequests ( false ) displayBuildErrorsOnDownstreamBuilds ( false ) whiteListTargetBranches ( [ watchBranch . toString () ] ) extensions { commitStatus { context ( ' Jenkins Code - Review ' ) triggeredStatus ( ' Build is Triggered ' ) startedStatus ( ' Build is Started ' ) addTestResults ( true ) completedStatus ( ' SUCCESS ' , ' Verified ' ) completedStatus ( ' FAILURE ' , ' Failed ' ) completedStatus ( ' PENDING ' , ' Penging ' ) completedStatus ( ' ERROR ' , ' Error ' ) } } } } properties { githubProjectProperty { projectUrlStr ( \"${githubRepository}\" ) } } } } def createBuildPipeline ( pipelineName , codebaseName , codebaseStages , pipelineScript , repository , credId , watchBranch = \"master\" , gitServerCrName , gitServerCrVersion , githubRepository ) { pipelineJob ( \"${codebaseName}/${watchBranch.toUpperCase().replaceAll(/\\\\//, \" - \")}-${pipelineName}\" ) { logRotator { numToKeep ( 10 ) daysToKeep ( 7 ) } definition { cpsScm { scm { git { remote { url ( repository ) credentials ( credId ) } branches ( \"${watchBranch}\" ) scriptPath ( \"${pipelineScript}\" ) } } parameters { stringParam ( \"GIT_SERVER_CR_NAME\" , \"${gitServerCrName}\" , \"Name of Git Server CR to generate link to Git server\" ) stringParam ( \"GIT_SERVER_CR_VERSION\" , \"${gitServerCrVersion}\" , \"Version of GitServer CR Resource\" ) stringParam ( \"STAGES\" , \"${codebaseStages}\" , \"Consequence of stages in JSON format to be run during execution\" ) stringParam ( \"GERRIT_PROJECT_NAME\" , \"${codebaseName}\" , \"Gerrit project name(Codebase name) to be build\" ) stringParam ( \"BRANCH\" , \"${watchBranch}\" , \"Branch to run from\" ) } } } triggers { gitHubPushTrigger () } properties { githubProjectProperty { projectUrlStr ( \"${githubRepository}\" ) } } } } def createListView ( codebaseName , branchName ) { listView ( \"${codebaseName}/${branchName}\" ) { if ( branchName . toLowerCase () == \"releases\" ) { jobFilters { regex { matchType ( MatchType . INCLUDE_MATCHED ) matchValue ( RegexMatchValue . NAME ) regex ( \"^Create-release.*\" ) } } } else { jobFilters { regex { matchType ( MatchType . INCLUDE_MATCHED ) matchValue ( RegexMatchValue . NAME ) regex ( \"^${branchName}-(Code-review|Build).*\" ) } } } columns { status () weather () name () lastSuccess () lastFailure () lastDuration () buildButton () } } } def createReleasePipeline ( pipelineName , codebaseName , codebaseStages , pipelineScript , repository , credId , gitServerCrName , gitServerCrVersion , jiraIntegrationEnabled , platformType ) { pipelineJob ( \"${codebaseName}/${pipelineName}\" ) { logRotator { numToKeep ( 14 ) daysToKeep ( 30 ) } definition { cpsScm { scm { git { remote { url ( repository ) credentials ( credId ) } branches ( \"master\" ) scriptPath ( \"${pipelineScript}\" ) } } parameters { stringParam ( \"STAGES\" , \"${codebaseStages}\" , \"\" ) if ( pipelineName . contains ( \"Create-release\" )) { stringParam ( \"JIRA_INTEGRATION_ENABLED\" , \"${jiraIntegrationEnabled}\" , \"Is Jira integration enabled\" ) stringParam ( \"PLATFORM_TYPE\" , \"${platformType}\" , \"Platform type\" ) stringParam ( \"GERRIT_PROJECT\" , \"${codebaseName}\" , \"\" ) stringParam ( \"RELEASE_NAME\" , \"\" , \"Name of the release(branch to be created)\" ) stringParam ( \"COMMIT_ID\" , \"\" , \"Commit ID that will be used to create branch from for new release. If empty, HEAD of master will be used\" ) stringParam ( \"GIT_SERVER_CR_NAME\" , \"${gitServerCrName}\" , \"Name of Git Server CR to generate link to Git server\" ) stringParam ( \"GIT_SERVER_CR_VERSION\" , \"${gitServerCrVersion}\" , \"Version of GitServer CR Resource\" ) stringParam ( \"REPOSITORY_PATH\" , \"${repository}\" , \"Full repository path\" ) } } } } } } def registerWebHook ( repositoryPath , type = ' code - review ' ) { def url = repositoryPath . split ( '@' ) [ 1 ] . split ( '/' ) [ 0 ] def owner = repositoryPath . split ( '@' ) [ 1 ] . split ( '/' ) [ 1 ] def repo = repositoryPath . split ( '@' ) [ 1 ] . split ( '/' ) [ 2 ] def apiUrl = ' https : //api.' + url + '/repos/' + owner + '/' + repo + '/hooks' def webhookUrl = '' def webhookConfig = [ : ] def config = [ : ] def events = [] if ( type . equalsIgnoreCase ( ' build ' )) { webhookUrl = System . getenv ( ' JENKINS_UI_URL ' ) + \"/github-webhook/\" events = [ \"push\" ] config [ \"url\" ] = webhookUrl config [ \"content_type\" ] = \"json\" config [ \"insecure_ssl\" ] = 0 webhookConfig [ \"name\" ] = \"web\" webhookConfig [ \"config\" ] = config webhookConfig [ \"events\" ] = events webhookConfig [ \"active\" ] = true } else { webhookUrl = System . getenv ( ' JENKINS_UI_URL ' ) + \"/ghprbhook/\" events = [ \"issue_comment\" , \"pull_request\" ] config [ \"url\" ] = webhookUrl config [ \"content_type\" ] = \"form\" config [ \"insecure_ssl\" ] = 0 webhookConfig [ \"name\" ] = \"web\" webhookConfig [ \"config\" ] = config webhookConfig [ \"events\" ] = events webhookConfig [ \"active\" ] = true } def requestBody = JsonOutput . toJson ( webhookConfig ) def http = new URL ( apiUrl ). openConnection () as HttpURLConnection http . setRequestMethod ( ' POST ' ) http . setDoOutput ( true ) println ( apiUrl ) http . setRequestProperty ( \"Accept\" , ' application / json ' ) http . setRequestProperty ( \"Content-Type\" , ' application / json ' ) http . setRequestProperty ( \"Authorization\" , \"token ${getSecretValue('github-access-token')}\" ) http . outputStream . write ( requestBody . getBytes ( \"UTF-8\" )) http . connect () println ( http . responseCode ) if ( http . responseCode == 201 ) { response = new JsonSlurper (). parseText ( http . inputStream . getText ( ' UTF - 8 ' )) } else { response = new JsonSlurper (). parseText ( http . errorStream . getText ( ' UTF - 8 ' )) } println \"response: ${response}\" } def getSecretValue ( name ) { def creds = com . cloudbees . plugins . credentials . CredentialsProvider . lookupCredentials ( com . cloudbees . plugins . credentials . common . StandardCredentials . class , Jenkins . instance , null , null ) def secret = creds . find { it . properties [ ' id ' ] == name } return secret != null ? secret [ ' secret ' ] : null } As a result, the new custom job-provision will be available in the Advanced CI Settings menu during the application creation:","title":"GitHub Integration"},{"location":"operator-guide/github-integration/#related-articles","text":"Adjust Import Strategy Adjust Integration With Jira Server","title":"Related Articles"},{"location":"operator-guide/gitlab-integration/","text":"GitLab Integration \u00b6 Discover the steps below to apply the GitLab integration correctly: Create access token in Gitlab : Log in to GitLab ; In the top-right corner, click your avatar and select Settings ; On the User Settings menu, select Access Tokens ; Choose a name and an optional expiry date for the token; In the Scopes block, select the api scope for the token; Click the Create personal access token button. Note Make sure to save the access token as there won`t be the ability to access it once again. Install GitLab plugin by navigating to Manage Jenkins and switching to plugin manager, select the GitLab Plugin check box: Create Jenkins Credential ID by navigating to Jenkins -> Credentials -> System -> Global Credentials -> Add Credentials : Select GitLab API token; Select Global scope; API token - the Access Token that was created earlier; ID - the gitlab-access-token ID; Description - the description of the current Credential ID; Configure Gitlab plugin by navigating to Manage Jenkins -> Configure System and fill in the GitLab plugin settings: Connection name - connection name; Gitlab host URL - a host URL to GitLab; Credentials - credentials with Access Token to GitLab ( gitlab-access-token ); Create a new Job Provision. Navigate to the Jenkins main page and open the job-provisions/ci folder: Click New Item ; Type the name; Select Freestyle project and click OK; Select the This project is parameterized check box and add a few input parameters as the following strings: NAME; TYPE; BUILD_TOOL; BRANCH; GIT_SERVER_CR_NAME; GIT_SERVER_CR_VERSION; GIT_SERVER; GIT_SSH_PORT; GIT_USERNAME; GIT_CREDENTIALS_ID; REPOSITORY_PATH; JIRA_INTEGRATION_ENABLED; Check the Execute concurrent builds if necessary option; Check the Restrict where this project can be run option; Fill in the Label Expression field by typing the master branch name. In the Build section, perform the following: Select DSL Script ; Select the Use the provided DSL script check box: As soon as all the steps above are performed, insert the code: import groovy.json. * import jenkins.model.Jenkins Jenkins jenkins = Jenkins . instance def stages = [:] def jiraIntegrationEnabled = Boolean . parseBoolean ( \"$ {JIRA_INTEGRATION_ENABLED} \" as String ) def commitValidateStage = jiraIntegrationEnabled ? ',{\"name\": \"commit-validate\"}' : '' def createJIMStage = jiraIntegrationEnabled ? ',{\"name\": \"create-jira-issue-metadata\"}' : '' def platformType = \"$ {PLATFORM_TYPE} \" def buildStage = platformType == \"kubernetes\" ? ',{\"name\": \"build-image-kaniko\"},' : ',{\"name\": \"build-image-from-dockerfile\"},' stages [ 'Code-review-application-maven' ] = '[{\"name\": \"checkout\"}' + \"$ {commitValidateStage} \" + ',{\"name\": \"compile\"}' + ',{\"name\": \"tests\"}, {\"name\": \"sonar\"}]' stages [ 'Code-review-application-npm' ] = stages [ 'Code-review-application-maven' ] stages [ 'Code-review-application-gradle' ] = stages [ 'Code-review-application-maven' ] stages [ 'Code-review-application-dotnet' ] = stages [ 'Code-review-application-maven' ] stages [ 'Code-review-application-terraform' ] = '[{\"name\": \"checkout\"},{\"name\": \"tool-init\"},{\"name\": \"lint\"}]' stages [ 'Code-review-application-helm' ] = '[{\"name\": \"checkout\"},{\"name\": \"lint\"}]' stages [ 'Code-review-application-docker' ] = '[{\"name\": \"checkout\"},{\"name\": \"lint\"}]' stages [ 'Code-review-application-go' ] = '[{\"name\": \"checkout\"}' + \"$ {commitValidateStage} \" + ',{\"name\": \"build\"},' + '{\"name\": \"tests\"}, {\"name\": \"sonar\"}]' stages [ 'Code-review-application-python' ] = '[{\"name\": \"checkout\"},{\"name\": \"compile\"},' + '{\"name\": \"tests\"}, {\"name\": \"sonar\"}]' stages [ 'Code-review-library' ] = '[{\"name\": \"checkout\"},{\"name\": \"compile\"},{\"name\": \"tests\"},' + '{\"name\": \"sonar\"}]' stages [ 'Code-review-autotests-maven' ] = '[{\"name\": \"checkout\"},{\"name\": \"tests\"},{\"name\": \"sonar\"}]' stages [ 'Build-library-maven' ] = '[{\"name\": \"checkout\"},{\"name\": \"get-version\"},{\"name\": \"compile\"},' + '{\"name\": \"tests\"},{\"name\": \"sonar\"},{\"name\": \"build\"}' + \"$ {createJIMStage} \" + ',{\"name\": \"git-tag\"}]' stages [ 'Build-library-npm' ] = stages [ 'Build-library-maven' ] stages [ 'Build-library-gradle' ] = stages [ 'Build-library-maven' ] stages [ 'Build-library-dotnet' ] = '[{\"name\": \"checkout\"},{\"name\": \"get-version\"},{\"name\": \"compile\"},' + '{\"name\": \"tests\"},{\"name\": \"sonar\"},{\"name\": \"push\"}' + \"$ {createJIMStage} \" + ',{\"name\": \"git-tag\"}]' stages [ 'Build-application-maven' ] = '[{\"name\": \"checkout\"},{\"name\": \"get-version\"},{\"name\": \"compile\"},' + '{\"name\": \"tests\"},{\"name\": \"sonar\"},{\"name\": \"build\"}' + \"$ {buildStage} \" + '{\"name\": \"push\"}' + \"$ {createJIMStage} \" + ',{\"name\": \"git-tag\"}]' stages [ 'Build-application-python' ] = '[{\"name\": \"checkout\"},{\"name\": \"get-version\"},{\"name\": \"compile\"},{\"name\": \"tests\"},{\"name\": \"sonar\"}' + \"$ {buildStage} \" + '{\"name\":\"push\"}' + \"$ {createJIMStage} \" + ',{\"name\": \"git-tag\"}]' stages [ 'Build-application-npm' ] = stages [ 'Build-application-maven' ] stages [ 'Build-application-gradle' ] = stages [ 'Build-application-maven' ] stages [ 'Build-application-dotnet' ] = '[{\"name\": \"checkout\"},{\"name\": \"get-version\"},{\"name\": \"compile\"},' + '{\"name\": \"tests\"},{\"name\": \"sonar\"}' + \"$ {buildStage} \" + '{\"name\": \"push\"}' + \"$ {createJIMStage} \" + ',{\"name\": \"git-tag\"}]' stages [ 'Build-application-terraform' ] = '[{\"name\": \"checkout\"},{\"name\": \"tool-init\"},' + '{\"name\": \"lint\"},{\"name\": \"git-tag\"}]' stages [ 'Build-application-helm' ] = '[{\"name\": \"checkout\"},{\"name\": \"lint\"}]' stages [ 'Build-application-docker' ] = '[{\"name\": \"checkout\"},{\"name\": \"lint\"}]' stages [ 'Build-application-go' ] = '[{\"name\": \"checkout\"},{\"name\": \"get-version\"},{\"name\": \"tests\"},{\"name\": \"sonar\"},' + '{\"name\": \"build\"}' + \"$ {buildStage} \" + \"$ {createJIMStage} \" + '{\"name\": \"git-tag\"}]' stages [ 'Create-release' ] = '[{\"name\": \"checkout\"},{\"name\": \"create-branch\"},{\"name\": \"trigger-job\"}]' def codebaseName = \"$ {NAME} \" def buildTool = \"$ {BUILD_TOOL} \" def gitServerCrName = \"$ {GIT_SERVER_CR_NAME} \" def gitServerCrVersion = \"$ {GIT_SERVER_CR_VERSION} \" def gitServer = \"${GIT_SERVER ? GIT_SERVER : 'gerrit'}\" def gitSshPort = \"${GIT_SSH_PORT ? GIT_SSH_PORT : '29418'}\" def gitUsername = \"${GIT_USERNAME ? GIT_USERNAME : 'jenkins'}\" def gitCredentialsId = \"${GIT_CREDENTIALS_ID ? GIT_CREDENTIALS_ID : 'gerrit-ciuser-sshkey'}\" def defaultRepoPath = \"ssh://$ {gitUsername} @$ {gitServer} :$ {gitSshPort} /$ {codebaseName} \" def repositoryPath = \"${REPOSITORY_PATH ? REPOSITORY_PATH : defaultRepoPath}\" def codebaseFolder = jenkins . getItem ( codebaseName ) if ( codebaseFolder == null ) { folder ( codebaseName ) } createListView ( codebaseName , \"Releases\" ) createReleasePipeline ( \"Create-release-$ {codebaseName} \" , codebaseName , stages [ \"Create-release\" ], \"create-release.groovy\" , repositoryPath , gitCredentialsId , gitServerCrName , gitServerCrVersion , jiraIntegrationEnabled , platformType ) if ( BRANCH ) { def branch = \"$ {BRANCH} \" def formattedBranch = \"${branch.toUpperCase().replaceAll(/ \\\\ //, \" - \")}\" createListView ( codebaseName , formattedBranch ) def type = \"$ {TYPE} \" createCiPipeline ( \"Code-review-$ {codebaseName} \" , codebaseName , stages [ \"Code-review-$ {type} -${buildTool.toLowerCase()}\" ], \"code-review.groovy\" , repositoryPath , gitCredentialsId , branch , gitServerCrName , gitServerCrVersion ) if ( type . equalsIgnoreCase ( 'application' ) || type . equalsIgnoreCase ( 'library' )) { def jobExists = false if ( \"$ {formattedBranch} -Build-$ {codebaseName} \" . toString () in Jenkins . instance . getAllItems () . collect { it . name }) { jobExists = true } createCiPipeline ( \"Build-$ {codebaseName} \" , codebaseName , stages [ \"Build-$ {type} -${buildTool.toLowerCase()}\" ], \"build.groovy\" , repositoryPath , gitCredentialsId , branch , gitServerCrName , gitServerCrVersion ) if ( ! jobExists ) { queue ( \"$ {codebaseName} /$ {formattedBranch} -Build-$ {codebaseName} \" ) } } } def createCiPipeline ( pipelineName , codebaseName , codebaseStages , pipelineScript , repository , credId , watchBranch = \"master\" , gitServerCrName , gitServerCrVersion ) { def jobName = \"${watchBranch.toUpperCase().replaceAll(/ \\\\ //, \" - \")}-$ {pipelineName} \" def existingJob = Jenkins . getInstance () . getItemByFullName ( \"$ {codebaseName} /$ {jobName} \" ) def webhookToken = null if ( existingJob ) { def triggersMap = existingJob . getTriggers () triggersMap . each { key , value -> webhookToken = value . getSecretToken () } } else { def random = new byte [ 16 ] new java . security . SecureRandom () . nextBytes ( random ) webhookToken = random . encodeHex () . toString () } pipelineJob ( \"$ {codebaseName} /$ {jobName} \" ) { logRotator { numToKeep ( 10 ) daysToKeep ( 7 ) } properties { gitLabConnection { gitLabConnection ( 'git.epam.com' ) } } definition { cpsScm { scm { git { remote { url ( repository ) credentials ( credId ) } branches ( pipelineName . contains ( \"Build\" ) ? \"$ {watchBranch} \" : \"\\$ {gitlabMergeRequestLastCommit} \" ) scriptPath ( \"$ {pipelineScript} \" ) } } parameters { stringParam ( \"GIT_SERVER_CR_NAME\" , \"$ {gitServerCrName} \" , \"Name of Git Server CR to generate link to Git server\" ) stringParam ( \"GIT_SERVER_CR_VERSION\" , \"$ {gitServerCrVersion} \" , \"Version of GitServer CR Resource\" ) stringParam ( \"STAGES\" , \"$ {codebaseStages} \" , \"Consequence of stages in JSON format to be run during execution\" ) stringParam ( \"GERRIT_PROJECT_NAME\" , \"$ {codebaseName} \" , \"Gerrit project name(Codebase name) to be build\" ) if ( pipelineName . contains ( \"Build\" )) stringParam ( \"BRANCH\" , \"$ {watchBranch} \" , \"Branch to build artifact from\" ) else stringParam ( \"BRANCH\" , \"\\$ {gitlabMergeRequestLastCommit} \" , \"Branch to build artifact from\" ) } } } triggers { gitlabPush { buildOnMergeRequestEvents ( pipelineName . contains ( \"Build\" ) ? false : true ) buildOnPushEvents ( pipelineName . contains ( \"Build\" ) ? true : false ) enableCiSkip ( false ) setBuildDescription ( true ) rebuildOpenMergeRequest ( pipelineName . contains ( \"Build\" ) ? 'never' : 'source' ) commentTrigger ( \"Build it please\" ) skipWorkInProgressMergeRequest ( true ) targetBranchRegex ( \"$ {watchBranch} \" ) } } configure { it / triggers / 'com.dabsquared.gitlabjenkins.GitLabPushTrigger' << secretToken ( webhookToken ) it / triggers / 'com.dabsquared.gitlabjenkins.GitLabPushTrigger' << triggerOnApprovedMergeRequest ( pipelineName . contains ( \"Build\" ) ? false : true ) it / triggers / 'com.dabsquared.gitlabjenkins.GitLabPushTrigger' << pendingBuildName ( pipelineName . contains ( \"Build\" ) ? \"\" : \"Jenkins\" ) } } registerWebHook ( repository , codebaseName , jobName , webhookToken ) } def createReleasePipeline ( pipelineName , codebaseName , codebaseStages , pipelineScript , repository , credId , gitServerCrName , gitServerCrVersion , jiraIntegrationEnabled , platformType ) { pipelineJob ( \"$ {codebaseName} /$ {pipelineName} \" ) { logRotator { numToKeep ( 14 ) daysToKeep ( 30 ) } definition { cpsScm { scm { git { remote { url ( repository ) credentials ( credId ) } branches ( \"master\" ) scriptPath ( \"$ {pipelineScript} \" ) } } parameters { stringParam ( \"STAGES\" , \"$ {codebaseStages} \" , \"\" ) if ( pipelineName . contains ( \"Create-release\" )) { stringParam ( \"JIRA_INTEGRATION_ENABLED\" , \"$ {jiraIntegrationEnabled} \" , \"Is Jira integration enabled\" ) stringParam ( \"PLATFORM_TYPE\" , \"$ {platformType} \" , \"Platform type\" ) stringParam ( \"GERRIT_PROJECT\" , \"$ {codebaseName} \" , \"\" ) stringParam ( \"RELEASE_NAME\" , \"\" , \"Name of the release(branch to be created)\" ) stringParam ( \"COMMIT_ID\" , \"\" , \"Commit ID that will be used to create branch from for new release. If empty, HEAD of master will be used\" ) stringParam ( \"GIT_SERVER_CR_NAME\" , \"$ {gitServerCrName} \" , \"Name of Git Server CR to generate link to Git server\" ) stringParam ( \"GIT_SERVER_CR_VERSION\" , \"$ {gitServerCrVersion} \" , \"Version of GitServer CR Resource\" ) stringParam ( \"REPOSITORY_PATH\" , \"$ {repository} \" , \"Full repository path\" ) } } } } } } def createListView ( codebaseName , branchName ) { listView ( \"$ {codebaseName} /$ {branchName} \" ) { if ( branchName . toLowerCase () == \"releases\" ) { jobFilters { regex { matchType ( MatchType . INCLUDE_MATCHED ) matchValue ( RegexMatchValue . NAME ) regex ( \"^Create-release.*\" ) } } } else { jobFilters { regex { matchType ( MatchType . INCLUDE_MATCHED ) matchValue ( RegexMatchValue . NAME ) regex ( \"^$ {branchName} -(Code-review|Build).*\" ) } } } columns { status () weather () name () lastSuccess () lastFailure () lastDuration () buildButton () } } } def registerWebHook ( repositoryPath , codebaseName , jobName , webhookToken ) { def apiUrl = 'https://' + repositoryPath . replaceAll ( \"ssh://\" , \"\" ) . split ( '@' )[ 1 ] . replace ( '/' , \" %2F \" ) . replaceAll ( ~/ : \\ d +% 2 F / , '/api/v4/projects/' ) + '/hooks' def jobWebhookUrl = \"${System.getenv('JENKINS_UI_URL')}/project/$ {codebaseName} /$ {jobName} \" def gitlabToken = getSecretValue ( 'gitlab-access-token' ) if ( checkWebHookExist ( apiUrl , jobWebhookUrl , gitlabToken )) { println ( \"[JENKINS][DEBUG] Webhook for job $ {jobName} is already exist \\r\\n \" ) return } println ( \"[JENKINS][DEBUG] Creating webhook for job $ {jobName} \" ) def webhookConfig = [:] webhookConfig [ \"url\" ] = jobWebhookUrl webhookConfig [ \"push_events\" ] = jobName . contains ( \"Build\" ) ? \"true\" : \"false\" webhookConfig [ \"merge_requests_events\" ] = jobName . contains ( \"Build\" ) ? \"false\" : \"true\" webhookConfig [ \"issues_events\" ] = \"false\" webhookConfig [ \"confidential_issues_events\" ] = \"false\" webhookConfig [ \"tag_push_events\" ] = \"false\" webhookConfig [ \"note_events\" ] = \"true\" webhookConfig [ \"job_events\" ] = \"false\" webhookConfig [ \"pipeline_events\" ] = \"false\" webhookConfig [ \"wiki_page_events\" ] = \"false\" webhookConfig [ \"enable_ssl_verification\" ] = \"true\" webhookConfig [ \"token\" ] = webhookToken def requestBody = JsonOutput . toJson ( webhookConfig ) def httpConnector = new URL ( apiUrl ) . openConnection () as HttpURLConnection httpConnector . setRequestMethod ( 'POST' ) httpConnector . setDoOutput ( true ) httpConnector . setRequestProperty ( \"Accept\" , 'application/json' ) httpConnector . setRequestProperty ( \"Content-Type\" , 'application/json' ) httpConnector . setRequestProperty ( \"PRIVATE-TOKEN\" , \"$ {gitlabToken} \" ) httpConnector . outputStream . write ( requestBody . getBytes ( \"UTF-8\" )) httpConnector . connect () if ( httpConnector . responseCode == 201 ) println ( \"[JENKINS][DEBUG] Webhook for job $ {jobName} has been created \\r\\n \" ) else { println ( \"[JENKINS][ERROR] Responce code - $ {httpConnector.responseCode} \" ) def response = new JsonSlurper () . parseText ( httpConnector . errorStream . getText ( 'UTF-8' )) println ( \"[JENKINS][ERROR] Failed to create webhook for job $ {jobName} . Response - $ {response} \" ) } } def checkWebHookExist ( apiUrl , jobWebhookUrl , gitlabToken ) { println ( \"[JENKINS][DEBUG] Checking if webhook $ {jobWebhookUrl} exists\" ) def httpConnector = new URL ( apiUrl ) . openConnection () as HttpURLConnection httpConnector . setRequestMethod ( 'GET' ) httpConnector . setDoOutput ( true ) httpConnector . setRequestProperty ( \"Accept\" , 'application/json' ) httpConnector . setRequestProperty ( \"Content-Type\" , 'application/json' ) httpConnector . setRequestProperty ( \"PRIVATE-TOKEN\" , \"$ {gitlabToken} \" ) httpConnector . connect () if ( httpConnector . responseCode == 200 ) { def response = new JsonSlurper () . parseText ( httpConnector . inputStream . getText ( 'UTF-8' )) return response . find { it . url == jobWebhookUrl } ? true : false } } def getSecretValue ( name ) { def creds = com . cloudbees . plugins . credentials . CredentialsProvider . lookupCredentials ( com . cloudbees . plugins . credentials . common . StandardCredentials . class , Jenkins . instance , null , null ) def secret = creds . find { it . properties [ 'id' ] == name } return secret != null ? secret . getApiToken () : null } Create Secret, GitServer CR and Jenkins credentials with the \"gitlab\" ID by following the instruction: Adjust Import Strategy After the steps above are performed, the new custom job-provision will be available in Advanced CI Settings during the application creation. Note Using the GitLab integration, a webhook is automatically created. After the removal of the application, the webhook stops working but not deleted. If necessary, it must be deleted manually.* Related Articles \u00b6 Adjust Import Strategy Adjust Integration With Jira Server","title":"Overview"},{"location":"operator-guide/gitlab-integration/#gitlab-integration","text":"Discover the steps below to apply the GitLab integration correctly: Create access token in Gitlab : Log in to GitLab ; In the top-right corner, click your avatar and select Settings ; On the User Settings menu, select Access Tokens ; Choose a name and an optional expiry date for the token; In the Scopes block, select the api scope for the token; Click the Create personal access token button. Note Make sure to save the access token as there won`t be the ability to access it once again. Install GitLab plugin by navigating to Manage Jenkins and switching to plugin manager, select the GitLab Plugin check box: Create Jenkins Credential ID by navigating to Jenkins -> Credentials -> System -> Global Credentials -> Add Credentials : Select GitLab API token; Select Global scope; API token - the Access Token that was created earlier; ID - the gitlab-access-token ID; Description - the description of the current Credential ID; Configure Gitlab plugin by navigating to Manage Jenkins -> Configure System and fill in the GitLab plugin settings: Connection name - connection name; Gitlab host URL - a host URL to GitLab; Credentials - credentials with Access Token to GitLab ( gitlab-access-token ); Create a new Job Provision. Navigate to the Jenkins main page and open the job-provisions/ci folder: Click New Item ; Type the name; Select Freestyle project and click OK; Select the This project is parameterized check box and add a few input parameters as the following strings: NAME; TYPE; BUILD_TOOL; BRANCH; GIT_SERVER_CR_NAME; GIT_SERVER_CR_VERSION; GIT_SERVER; GIT_SSH_PORT; GIT_USERNAME; GIT_CREDENTIALS_ID; REPOSITORY_PATH; JIRA_INTEGRATION_ENABLED; Check the Execute concurrent builds if necessary option; Check the Restrict where this project can be run option; Fill in the Label Expression field by typing the master branch name. In the Build section, perform the following: Select DSL Script ; Select the Use the provided DSL script check box: As soon as all the steps above are performed, insert the code: import groovy.json. * import jenkins.model.Jenkins Jenkins jenkins = Jenkins . instance def stages = [:] def jiraIntegrationEnabled = Boolean . parseBoolean ( \"$ {JIRA_INTEGRATION_ENABLED} \" as String ) def commitValidateStage = jiraIntegrationEnabled ? ',{\"name\": \"commit-validate\"}' : '' def createJIMStage = jiraIntegrationEnabled ? ',{\"name\": \"create-jira-issue-metadata\"}' : '' def platformType = \"$ {PLATFORM_TYPE} \" def buildStage = platformType == \"kubernetes\" ? ',{\"name\": \"build-image-kaniko\"},' : ',{\"name\": \"build-image-from-dockerfile\"},' stages [ 'Code-review-application-maven' ] = '[{\"name\": \"checkout\"}' + \"$ {commitValidateStage} \" + ',{\"name\": \"compile\"}' + ',{\"name\": \"tests\"}, {\"name\": \"sonar\"}]' stages [ 'Code-review-application-npm' ] = stages [ 'Code-review-application-maven' ] stages [ 'Code-review-application-gradle' ] = stages [ 'Code-review-application-maven' ] stages [ 'Code-review-application-dotnet' ] = stages [ 'Code-review-application-maven' ] stages [ 'Code-review-application-terraform' ] = '[{\"name\": \"checkout\"},{\"name\": \"tool-init\"},{\"name\": \"lint\"}]' stages [ 'Code-review-application-helm' ] = '[{\"name\": \"checkout\"},{\"name\": \"lint\"}]' stages [ 'Code-review-application-docker' ] = '[{\"name\": \"checkout\"},{\"name\": \"lint\"}]' stages [ 'Code-review-application-go' ] = '[{\"name\": \"checkout\"}' + \"$ {commitValidateStage} \" + ',{\"name\": \"build\"},' + '{\"name\": \"tests\"}, {\"name\": \"sonar\"}]' stages [ 'Code-review-application-python' ] = '[{\"name\": \"checkout\"},{\"name\": \"compile\"},' + '{\"name\": \"tests\"}, {\"name\": \"sonar\"}]' stages [ 'Code-review-library' ] = '[{\"name\": \"checkout\"},{\"name\": \"compile\"},{\"name\": \"tests\"},' + '{\"name\": \"sonar\"}]' stages [ 'Code-review-autotests-maven' ] = '[{\"name\": \"checkout\"},{\"name\": \"tests\"},{\"name\": \"sonar\"}]' stages [ 'Build-library-maven' ] = '[{\"name\": \"checkout\"},{\"name\": \"get-version\"},{\"name\": \"compile\"},' + '{\"name\": \"tests\"},{\"name\": \"sonar\"},{\"name\": \"build\"}' + \"$ {createJIMStage} \" + ',{\"name\": \"git-tag\"}]' stages [ 'Build-library-npm' ] = stages [ 'Build-library-maven' ] stages [ 'Build-library-gradle' ] = stages [ 'Build-library-maven' ] stages [ 'Build-library-dotnet' ] = '[{\"name\": \"checkout\"},{\"name\": \"get-version\"},{\"name\": \"compile\"},' + '{\"name\": \"tests\"},{\"name\": \"sonar\"},{\"name\": \"push\"}' + \"$ {createJIMStage} \" + ',{\"name\": \"git-tag\"}]' stages [ 'Build-application-maven' ] = '[{\"name\": \"checkout\"},{\"name\": \"get-version\"},{\"name\": \"compile\"},' + '{\"name\": \"tests\"},{\"name\": \"sonar\"},{\"name\": \"build\"}' + \"$ {buildStage} \" + '{\"name\": \"push\"}' + \"$ {createJIMStage} \" + ',{\"name\": \"git-tag\"}]' stages [ 'Build-application-python' ] = '[{\"name\": \"checkout\"},{\"name\": \"get-version\"},{\"name\": \"compile\"},{\"name\": \"tests\"},{\"name\": \"sonar\"}' + \"$ {buildStage} \" + '{\"name\":\"push\"}' + \"$ {createJIMStage} \" + ',{\"name\": \"git-tag\"}]' stages [ 'Build-application-npm' ] = stages [ 'Build-application-maven' ] stages [ 'Build-application-gradle' ] = stages [ 'Build-application-maven' ] stages [ 'Build-application-dotnet' ] = '[{\"name\": \"checkout\"},{\"name\": \"get-version\"},{\"name\": \"compile\"},' + '{\"name\": \"tests\"},{\"name\": \"sonar\"}' + \"$ {buildStage} \" + '{\"name\": \"push\"}' + \"$ {createJIMStage} \" + ',{\"name\": \"git-tag\"}]' stages [ 'Build-application-terraform' ] = '[{\"name\": \"checkout\"},{\"name\": \"tool-init\"},' + '{\"name\": \"lint\"},{\"name\": \"git-tag\"}]' stages [ 'Build-application-helm' ] = '[{\"name\": \"checkout\"},{\"name\": \"lint\"}]' stages [ 'Build-application-docker' ] = '[{\"name\": \"checkout\"},{\"name\": \"lint\"}]' stages [ 'Build-application-go' ] = '[{\"name\": \"checkout\"},{\"name\": \"get-version\"},{\"name\": \"tests\"},{\"name\": \"sonar\"},' + '{\"name\": \"build\"}' + \"$ {buildStage} \" + \"$ {createJIMStage} \" + '{\"name\": \"git-tag\"}]' stages [ 'Create-release' ] = '[{\"name\": \"checkout\"},{\"name\": \"create-branch\"},{\"name\": \"trigger-job\"}]' def codebaseName = \"$ {NAME} \" def buildTool = \"$ {BUILD_TOOL} \" def gitServerCrName = \"$ {GIT_SERVER_CR_NAME} \" def gitServerCrVersion = \"$ {GIT_SERVER_CR_VERSION} \" def gitServer = \"${GIT_SERVER ? GIT_SERVER : 'gerrit'}\" def gitSshPort = \"${GIT_SSH_PORT ? GIT_SSH_PORT : '29418'}\" def gitUsername = \"${GIT_USERNAME ? GIT_USERNAME : 'jenkins'}\" def gitCredentialsId = \"${GIT_CREDENTIALS_ID ? GIT_CREDENTIALS_ID : 'gerrit-ciuser-sshkey'}\" def defaultRepoPath = \"ssh://$ {gitUsername} @$ {gitServer} :$ {gitSshPort} /$ {codebaseName} \" def repositoryPath = \"${REPOSITORY_PATH ? REPOSITORY_PATH : defaultRepoPath}\" def codebaseFolder = jenkins . getItem ( codebaseName ) if ( codebaseFolder == null ) { folder ( codebaseName ) } createListView ( codebaseName , \"Releases\" ) createReleasePipeline ( \"Create-release-$ {codebaseName} \" , codebaseName , stages [ \"Create-release\" ], \"create-release.groovy\" , repositoryPath , gitCredentialsId , gitServerCrName , gitServerCrVersion , jiraIntegrationEnabled , platformType ) if ( BRANCH ) { def branch = \"$ {BRANCH} \" def formattedBranch = \"${branch.toUpperCase().replaceAll(/ \\\\ //, \" - \")}\" createListView ( codebaseName , formattedBranch ) def type = \"$ {TYPE} \" createCiPipeline ( \"Code-review-$ {codebaseName} \" , codebaseName , stages [ \"Code-review-$ {type} -${buildTool.toLowerCase()}\" ], \"code-review.groovy\" , repositoryPath , gitCredentialsId , branch , gitServerCrName , gitServerCrVersion ) if ( type . equalsIgnoreCase ( 'application' ) || type . equalsIgnoreCase ( 'library' )) { def jobExists = false if ( \"$ {formattedBranch} -Build-$ {codebaseName} \" . toString () in Jenkins . instance . getAllItems () . collect { it . name }) { jobExists = true } createCiPipeline ( \"Build-$ {codebaseName} \" , codebaseName , stages [ \"Build-$ {type} -${buildTool.toLowerCase()}\" ], \"build.groovy\" , repositoryPath , gitCredentialsId , branch , gitServerCrName , gitServerCrVersion ) if ( ! jobExists ) { queue ( \"$ {codebaseName} /$ {formattedBranch} -Build-$ {codebaseName} \" ) } } } def createCiPipeline ( pipelineName , codebaseName , codebaseStages , pipelineScript , repository , credId , watchBranch = \"master\" , gitServerCrName , gitServerCrVersion ) { def jobName = \"${watchBranch.toUpperCase().replaceAll(/ \\\\ //, \" - \")}-$ {pipelineName} \" def existingJob = Jenkins . getInstance () . getItemByFullName ( \"$ {codebaseName} /$ {jobName} \" ) def webhookToken = null if ( existingJob ) { def triggersMap = existingJob . getTriggers () triggersMap . each { key , value -> webhookToken = value . getSecretToken () } } else { def random = new byte [ 16 ] new java . security . SecureRandom () . nextBytes ( random ) webhookToken = random . encodeHex () . toString () } pipelineJob ( \"$ {codebaseName} /$ {jobName} \" ) { logRotator { numToKeep ( 10 ) daysToKeep ( 7 ) } properties { gitLabConnection { gitLabConnection ( 'git.epam.com' ) } } definition { cpsScm { scm { git { remote { url ( repository ) credentials ( credId ) } branches ( pipelineName . contains ( \"Build\" ) ? \"$ {watchBranch} \" : \"\\$ {gitlabMergeRequestLastCommit} \" ) scriptPath ( \"$ {pipelineScript} \" ) } } parameters { stringParam ( \"GIT_SERVER_CR_NAME\" , \"$ {gitServerCrName} \" , \"Name of Git Server CR to generate link to Git server\" ) stringParam ( \"GIT_SERVER_CR_VERSION\" , \"$ {gitServerCrVersion} \" , \"Version of GitServer CR Resource\" ) stringParam ( \"STAGES\" , \"$ {codebaseStages} \" , \"Consequence of stages in JSON format to be run during execution\" ) stringParam ( \"GERRIT_PROJECT_NAME\" , \"$ {codebaseName} \" , \"Gerrit project name(Codebase name) to be build\" ) if ( pipelineName . contains ( \"Build\" )) stringParam ( \"BRANCH\" , \"$ {watchBranch} \" , \"Branch to build artifact from\" ) else stringParam ( \"BRANCH\" , \"\\$ {gitlabMergeRequestLastCommit} \" , \"Branch to build artifact from\" ) } } } triggers { gitlabPush { buildOnMergeRequestEvents ( pipelineName . contains ( \"Build\" ) ? false : true ) buildOnPushEvents ( pipelineName . contains ( \"Build\" ) ? true : false ) enableCiSkip ( false ) setBuildDescription ( true ) rebuildOpenMergeRequest ( pipelineName . contains ( \"Build\" ) ? 'never' : 'source' ) commentTrigger ( \"Build it please\" ) skipWorkInProgressMergeRequest ( true ) targetBranchRegex ( \"$ {watchBranch} \" ) } } configure { it / triggers / 'com.dabsquared.gitlabjenkins.GitLabPushTrigger' << secretToken ( webhookToken ) it / triggers / 'com.dabsquared.gitlabjenkins.GitLabPushTrigger' << triggerOnApprovedMergeRequest ( pipelineName . contains ( \"Build\" ) ? false : true ) it / triggers / 'com.dabsquared.gitlabjenkins.GitLabPushTrigger' << pendingBuildName ( pipelineName . contains ( \"Build\" ) ? \"\" : \"Jenkins\" ) } } registerWebHook ( repository , codebaseName , jobName , webhookToken ) } def createReleasePipeline ( pipelineName , codebaseName , codebaseStages , pipelineScript , repository , credId , gitServerCrName , gitServerCrVersion , jiraIntegrationEnabled , platformType ) { pipelineJob ( \"$ {codebaseName} /$ {pipelineName} \" ) { logRotator { numToKeep ( 14 ) daysToKeep ( 30 ) } definition { cpsScm { scm { git { remote { url ( repository ) credentials ( credId ) } branches ( \"master\" ) scriptPath ( \"$ {pipelineScript} \" ) } } parameters { stringParam ( \"STAGES\" , \"$ {codebaseStages} \" , \"\" ) if ( pipelineName . contains ( \"Create-release\" )) { stringParam ( \"JIRA_INTEGRATION_ENABLED\" , \"$ {jiraIntegrationEnabled} \" , \"Is Jira integration enabled\" ) stringParam ( \"PLATFORM_TYPE\" , \"$ {platformType} \" , \"Platform type\" ) stringParam ( \"GERRIT_PROJECT\" , \"$ {codebaseName} \" , \"\" ) stringParam ( \"RELEASE_NAME\" , \"\" , \"Name of the release(branch to be created)\" ) stringParam ( \"COMMIT_ID\" , \"\" , \"Commit ID that will be used to create branch from for new release. If empty, HEAD of master will be used\" ) stringParam ( \"GIT_SERVER_CR_NAME\" , \"$ {gitServerCrName} \" , \"Name of Git Server CR to generate link to Git server\" ) stringParam ( \"GIT_SERVER_CR_VERSION\" , \"$ {gitServerCrVersion} \" , \"Version of GitServer CR Resource\" ) stringParam ( \"REPOSITORY_PATH\" , \"$ {repository} \" , \"Full repository path\" ) } } } } } } def createListView ( codebaseName , branchName ) { listView ( \"$ {codebaseName} /$ {branchName} \" ) { if ( branchName . toLowerCase () == \"releases\" ) { jobFilters { regex { matchType ( MatchType . INCLUDE_MATCHED ) matchValue ( RegexMatchValue . NAME ) regex ( \"^Create-release.*\" ) } } } else { jobFilters { regex { matchType ( MatchType . INCLUDE_MATCHED ) matchValue ( RegexMatchValue . NAME ) regex ( \"^$ {branchName} -(Code-review|Build).*\" ) } } } columns { status () weather () name () lastSuccess () lastFailure () lastDuration () buildButton () } } } def registerWebHook ( repositoryPath , codebaseName , jobName , webhookToken ) { def apiUrl = 'https://' + repositoryPath . replaceAll ( \"ssh://\" , \"\" ) . split ( '@' )[ 1 ] . replace ( '/' , \" %2F \" ) . replaceAll ( ~/ : \\ d +% 2 F / , '/api/v4/projects/' ) + '/hooks' def jobWebhookUrl = \"${System.getenv('JENKINS_UI_URL')}/project/$ {codebaseName} /$ {jobName} \" def gitlabToken = getSecretValue ( 'gitlab-access-token' ) if ( checkWebHookExist ( apiUrl , jobWebhookUrl , gitlabToken )) { println ( \"[JENKINS][DEBUG] Webhook for job $ {jobName} is already exist \\r\\n \" ) return } println ( \"[JENKINS][DEBUG] Creating webhook for job $ {jobName} \" ) def webhookConfig = [:] webhookConfig [ \"url\" ] = jobWebhookUrl webhookConfig [ \"push_events\" ] = jobName . contains ( \"Build\" ) ? \"true\" : \"false\" webhookConfig [ \"merge_requests_events\" ] = jobName . contains ( \"Build\" ) ? \"false\" : \"true\" webhookConfig [ \"issues_events\" ] = \"false\" webhookConfig [ \"confidential_issues_events\" ] = \"false\" webhookConfig [ \"tag_push_events\" ] = \"false\" webhookConfig [ \"note_events\" ] = \"true\" webhookConfig [ \"job_events\" ] = \"false\" webhookConfig [ \"pipeline_events\" ] = \"false\" webhookConfig [ \"wiki_page_events\" ] = \"false\" webhookConfig [ \"enable_ssl_verification\" ] = \"true\" webhookConfig [ \"token\" ] = webhookToken def requestBody = JsonOutput . toJson ( webhookConfig ) def httpConnector = new URL ( apiUrl ) . openConnection () as HttpURLConnection httpConnector . setRequestMethod ( 'POST' ) httpConnector . setDoOutput ( true ) httpConnector . setRequestProperty ( \"Accept\" , 'application/json' ) httpConnector . setRequestProperty ( \"Content-Type\" , 'application/json' ) httpConnector . setRequestProperty ( \"PRIVATE-TOKEN\" , \"$ {gitlabToken} \" ) httpConnector . outputStream . write ( requestBody . getBytes ( \"UTF-8\" )) httpConnector . connect () if ( httpConnector . responseCode == 201 ) println ( \"[JENKINS][DEBUG] Webhook for job $ {jobName} has been created \\r\\n \" ) else { println ( \"[JENKINS][ERROR] Responce code - $ {httpConnector.responseCode} \" ) def response = new JsonSlurper () . parseText ( httpConnector . errorStream . getText ( 'UTF-8' )) println ( \"[JENKINS][ERROR] Failed to create webhook for job $ {jobName} . Response - $ {response} \" ) } } def checkWebHookExist ( apiUrl , jobWebhookUrl , gitlabToken ) { println ( \"[JENKINS][DEBUG] Checking if webhook $ {jobWebhookUrl} exists\" ) def httpConnector = new URL ( apiUrl ) . openConnection () as HttpURLConnection httpConnector . setRequestMethod ( 'GET' ) httpConnector . setDoOutput ( true ) httpConnector . setRequestProperty ( \"Accept\" , 'application/json' ) httpConnector . setRequestProperty ( \"Content-Type\" , 'application/json' ) httpConnector . setRequestProperty ( \"PRIVATE-TOKEN\" , \"$ {gitlabToken} \" ) httpConnector . connect () if ( httpConnector . responseCode == 200 ) { def response = new JsonSlurper () . parseText ( httpConnector . inputStream . getText ( 'UTF-8' )) return response . find { it . url == jobWebhookUrl } ? true : false } } def getSecretValue ( name ) { def creds = com . cloudbees . plugins . credentials . CredentialsProvider . lookupCredentials ( com . cloudbees . plugins . credentials . common . StandardCredentials . class , Jenkins . instance , null , null ) def secret = creds . find { it . properties [ 'id' ] == name } return secret != null ? secret . getApiToken () : null } Create Secret, GitServer CR and Jenkins credentials with the \"gitlab\" ID by following the instruction: Adjust Import Strategy After the steps above are performed, the new custom job-provision will be available in Advanced CI Settings during the application creation. Note Using the GitLab integration, a webhook is automatically created. After the removal of the application, the webhook stops working but not deleted. If necessary, it must be deleted manually.*","title":"GitLab Integration"},{"location":"operator-guide/gitlab-integration/#related-articles","text":"Adjust Import Strategy Adjust Integration With Jira Server","title":"Related Articles"},{"location":"operator-guide/gitlabci-integration/","text":"Adjust GitLab CI Tool \u00b6 EDP allows selecting one of two available CI (Continuous Integration) tools, namely: Jenkins or GitLab. The Jenkins tool is available by default. To use the GitLab CI tool, it is required to make it available first. Follow the steps below to adjust the GitLab CI tool: In GitLab, add the environment variables to the project. To add variables, navigate to Settings -> CI/CD -> Expand Variables -> Add Variable : Apply the necessary variables as they differ in accordance with the cluster OpenShift / Kubernetes, see below: OpenShift Environment Variables Description DOCKER_REGISTRY_URL URL to OpenShift docker registry DOCKER_REGISTRY_PASSWORD Service Account token that has an access to registry DOCKER_REGISTRY_USER user name OPENSHIFT_SA_TOKEN token that can be used to log in to OpenShift Info In order to get access to the Docker registry and OpenShift, use the gitlab-ci ServiceAccount; pay attention that SA description contains the credentials and secrets: Kubernetes Environment Variables Description DOCKER_REGISTRY_URL URL to Amazon ECR AWS_ACCESS_KEY_ID auto IAM user access key AWS_SECRET_ACCESS_KEY auto IAM user secret access key K8S_SA_TOKEN token that can be used to log in to Kubernetes Note To get the access to ECR, it is required to have an auto IAM user that has rights to push/create a repository. In Admin Console, select the CI tool in the Advanced Settings menu during the codebase creation: Note The selection of the CI tool is available only with the Import strategy. As soon as the codebase is provisioned, the .gitlab-ci.yml file will be created in the repository that describes the pipeline's stages and logic:","title":"Adjust GitLab CI Tool"},{"location":"operator-guide/gitlabci-integration/#adjust-gitlab-ci-tool","text":"EDP allows selecting one of two available CI (Continuous Integration) tools, namely: Jenkins or GitLab. The Jenkins tool is available by default. To use the GitLab CI tool, it is required to make it available first. Follow the steps below to adjust the GitLab CI tool: In GitLab, add the environment variables to the project. To add variables, navigate to Settings -> CI/CD -> Expand Variables -> Add Variable : Apply the necessary variables as they differ in accordance with the cluster OpenShift / Kubernetes, see below: OpenShift Environment Variables Description DOCKER_REGISTRY_URL URL to OpenShift docker registry DOCKER_REGISTRY_PASSWORD Service Account token that has an access to registry DOCKER_REGISTRY_USER user name OPENSHIFT_SA_TOKEN token that can be used to log in to OpenShift Info In order to get access to the Docker registry and OpenShift, use the gitlab-ci ServiceAccount; pay attention that SA description contains the credentials and secrets: Kubernetes Environment Variables Description DOCKER_REGISTRY_URL URL to Amazon ECR AWS_ACCESS_KEY_ID auto IAM user access key AWS_SECRET_ACCESS_KEY auto IAM user secret access key K8S_SA_TOKEN token that can be used to log in to Kubernetes Note To get the access to ECR, it is required to have an auto IAM user that has rights to push/create a repository. In Admin Console, select the CI tool in the Advanced Settings menu during the codebase creation: Note The selection of the CI tool is available only with the Import strategy. As soon as the codebase is provisioned, the .gitlab-ci.yml file will be created in the repository that describes the pipeline's stages and logic:","title":"Adjust GitLab CI Tool"},{"location":"operator-guide/import-strategy/","text":"Enable VCS Import Strategy \u00b6 In order to use the import strategy, it is required to add Secret with SSH key, GitServer CR, and Jenkins credentials by following the steps below: Create Secret in the OpenShift/K8S namespace for the Git account with the id_rsa , id_rsa.pub , and username fields: As a sample, it is possible to use the following command: kubectl create secret generic gitlab - n edp \\ -- from - file = id_rsa = id_rsa \\ -- from - file id_rsa . pub = id_rsa . pub \\ --from-literal=username=user@gitlab.com Create GitServer CR in the OpenShift/K8S namespace with the gitHost , gitUser , httpsPort , sshPort , nameSshKeySecret , and createCodeReviewPipeline fields: As a sample, it is possible to use the following template: apiVersion : v2 . edp . epam . com / v1alpha1 kind : GitServer metadata : name : git - example spec : createCodeReviewPipeline : false gitHost : git . example . com gitUser : git httpsPort : 443 nameSshKeySecret : gitlab - sshkey sshPort : 22 Note The value of the nameSshKeySecret property is the name of the Secret that is indicated in the first point above. Create a Credential in Jenkins with the same ID as in the nameSshKeySecret property, and with the private key. Navigate to Jenkins -> Credentials -> System -> Global credentials -> Add Credentials : Change the Deployment Config of the Admin Console by adding the Import strategy to the INTEGRATION_STRATEGIES variable: As soon as the Admin Console is redeployed, the Import strategy will be added to the Create Application page. For details, please refer to the Add Applications page.","title":"Enable VCS Import Strategy"},{"location":"operator-guide/import-strategy/#enable-vcs-import-strategy","text":"In order to use the import strategy, it is required to add Secret with SSH key, GitServer CR, and Jenkins credentials by following the steps below: Create Secret in the OpenShift/K8S namespace for the Git account with the id_rsa , id_rsa.pub , and username fields: As a sample, it is possible to use the following command: kubectl create secret generic gitlab - n edp \\ -- from - file = id_rsa = id_rsa \\ -- from - file id_rsa . pub = id_rsa . pub \\ --from-literal=username=user@gitlab.com Create GitServer CR in the OpenShift/K8S namespace with the gitHost , gitUser , httpsPort , sshPort , nameSshKeySecret , and createCodeReviewPipeline fields: As a sample, it is possible to use the following template: apiVersion : v2 . edp . epam . com / v1alpha1 kind : GitServer metadata : name : git - example spec : createCodeReviewPipeline : false gitHost : git . example . com gitUser : git httpsPort : 443 nameSshKeySecret : gitlab - sshkey sshPort : 22 Note The value of the nameSshKeySecret property is the name of the Secret that is indicated in the first point above. Create a Credential in Jenkins with the same ID as in the nameSshKeySecret property, and with the private key. Navigate to Jenkins -> Credentials -> System -> Global credentials -> Add Credentials : Change the Deployment Config of the Admin Console by adding the Import strategy to the INTEGRATION_STRATEGIES variable: As soon as the Admin Console is redeployed, the Import strategy will be added to the Create Application page. For details, please refer to the Add Applications page.","title":"Enable VCS Import Strategy"},{"location":"operator-guide/jira-gerrit-integration/","text":"Gerrit to Jira Integration \u00b6 In order to adjust the Version Control System integration with Jira Server, first make sure you have the following prerequisites: VCS Server Jira Crucible When checked the prerequisites, follow the steps below to proceed with the integration: Integrate every project in VCS Server with every project in Crucible by creating a corresponding request in EPAM Support Portal . Add the repositories links and fill in the Keep Informed field as this request must be approved. Provide additional details to the support team. If the VCS is Gerrit, inspect the sample below of its integration: 2.1 Create a new \"crucible- \" user in Gerrit with SSH key and add a new user to the \"Non-Interactive Users\" Gerrit group; 2.2 Create a new group in Gerrit \"crucible-watcher-group\" and add the \"crucible- \" user; 2.3 Provide access to All-Projects for the \"crucible-watcher-group\" group: To link commits with Jira ticket, being in Gerrit, enter a Jira ticket ID in a commit message using the specific format: [PROJECT-CODE-1234]: commit message where PROJECT-CODE is a specific code of a project, 1234 is an ID number, and a commit message. As a result, all Gerrit commits will be displayed on Crucible : Related Articles \u00b6 Adjust Integration With Jira Server","title":"Gerrit to Jira Integration"},{"location":"operator-guide/jira-gerrit-integration/#gerrit-to-jira-integration","text":"In order to adjust the Version Control System integration with Jira Server, first make sure you have the following prerequisites: VCS Server Jira Crucible When checked the prerequisites, follow the steps below to proceed with the integration: Integrate every project in VCS Server with every project in Crucible by creating a corresponding request in EPAM Support Portal . Add the repositories links and fill in the Keep Informed field as this request must be approved. Provide additional details to the support team. If the VCS is Gerrit, inspect the sample below of its integration: 2.1 Create a new \"crucible- \" user in Gerrit with SSH key and add a new user to the \"Non-Interactive Users\" Gerrit group; 2.2 Create a new group in Gerrit \"crucible-watcher-group\" and add the \"crucible- \" user; 2.3 Provide access to All-Projects for the \"crucible-watcher-group\" group: To link commits with Jira ticket, being in Gerrit, enter a Jira ticket ID in a commit message using the specific format: [PROJECT-CODE-1234]: commit message where PROJECT-CODE is a specific code of a project, 1234 is an ID number, and a commit message. As a result, all Gerrit commits will be displayed on Crucible :","title":"Gerrit to Jira Integration"},{"location":"operator-guide/jira-gerrit-integration/#related-articles","text":"Adjust Integration With Jira Server","title":"Related Articles"},{"location":"operator-guide/jira-integration/","text":"Jira Integration \u00b6 In order to adjust the Jira server integration, first add JiraServer CR by performing the following: Create Secret in the OpenShift/K8S namespace for Jira Server account with the username and password fields: apiVersion : v1 data : password : passwordInBase64 username : usernameInBase64 kind : Secret metadata : name : epam - jira - user type : kubernetes . io / basic - auth Create JiraServer CR in the OpenShift/K8S namespace with the apiUrl , credentialName and rootUrl fields: apiVersion : v2 . edp . epam . com / v1alpha1 kind : JiraServer metadata : name : epam - jira spec : apiUrl : 'https://jira-api.example.com' credentialName : jira - user rootUrl : 'https://jira.example.com' status : available : true last_time_updated : '2021-04-05T10:51:07.042048633Z' Note The value of the credentialName property is the name of the Secret, which is indicated in the first point above. Being in Admin Console, navigate to the Advanced Settings menu to check that the Integrate with Jira Server check box became available:","title":"Overview"},{"location":"operator-guide/jira-integration/#jira-integration","text":"In order to adjust the Jira server integration, first add JiraServer CR by performing the following: Create Secret in the OpenShift/K8S namespace for Jira Server account with the username and password fields: apiVersion : v1 data : password : passwordInBase64 username : usernameInBase64 kind : Secret metadata : name : epam - jira - user type : kubernetes . io / basic - auth Create JiraServer CR in the OpenShift/K8S namespace with the apiUrl , credentialName and rootUrl fields: apiVersion : v2 . edp . epam . com / v1alpha1 kind : JiraServer metadata : name : epam - jira spec : apiUrl : 'https://jira-api.example.com' credentialName : jira - user rootUrl : 'https://jira.example.com' status : available : true last_time_updated : '2021-04-05T10:51:07.042048633Z' Note The value of the credentialName property is the name of the Secret, which is indicated in the first point above. Being in Admin Console, navigate to the Advanced Settings menu to check that the Integrate with Jira Server check box became available:","title":"Jira Integration"},{"location":"user-guide/","text":"Overview \u00b6 This guide is for developers who have EDP installed and use for CI/CD configuration.","title":"Overview"},{"location":"user-guide/#overview","text":"This guide is for developers who have EDP installed and use for CI/CD configuration.","title":"Overview"},{"location":"user-guide/add-application/","text":"Add Application \u00b6 Admin Console allows to create, clone, import an application and add it to the environment with its subsequent deployment in Gerrit and building of the Code Review and Build pipelines in Jenkins. To add an application, navigate to the Applications section on the left-side navigation bar and click the Create button. Once clicked, the six-step menu will appear: The Codebase Info Menu The Application Info Menu The Advanced Settings Menu The Version Control System Info Menu The Exposing Service Info Menu The Database Menu Note The Version Control System Info menu is available in case this option is predefined The Codebase Info Menu \u00b6 In the Codebase Integration Strategy field, select the necessary option that is the configuration strategy for the replication with Gerrit: Create \u2013 creates a project on the pattern in accordance with an application language, a build tool, and a framework. Clone \u2013 clones the indicated repository into EPAM Delivery Platform. While cloning the existing repository, you have to fill in the additional fields as well. Import - allows configuring a replication from the Git server. While importing the existing repository, you have to select the Git server and define the respective path to the repository. Note In order to use the import strategy, make sure to adjust it by following the Adjust Import Strategy page. In the Git Repository URL field, specify the link to the repository that is to be cloned. If the Import strategy is selected, specify the following fields: a. Git Server where the repository is located. b. Relative path to the repository on the server. Select the Codebase Authentication check box and fill in the requested fields: Repository Login \u2013 enter your login data. Repository password (or API Token) \u2013 enter your password or indicate the API Token. Note The Codebase Authentication check box should be selected just in case you clone the private repository. If you define the public one, there is no need to enter credentials. Click the Proceed button to be switched to the next menu. The Application Info Menu \u00b6 Type the name of the application in the Application Name field by entering at least two characters and by using the lower-case letters, numbers and inner dashes. Note If the Import strategy is used, the Application Name field will not be displayed. Specify the name of the default branch where you want the development to be performed. Note The default branch cannot be deleted. Select any of the supported application languages with its framework in the Application Code Language/framework field: Java \u2013 selecting Java allows using Java 8 or Java 11. JavaScript - selecting JavaScript allows using the React framework. DotNet - selecting DotNet allows using the DotNet v.2.1 and DotNet v.3.1. Go - selecting Go allows using the Beego and Operator SDK frameworks. Python - selecting Python allows using the Python v.3.8. Other - selecting Other allows extending the default code languages when creating a codebase with the clone/import strategy. To add another code language, inspect the Add Other Code Language section. Note The Create strategy does not allow to customize the default code language set. Choose the necessary build tool in the Select Build Tool field: Java - selecting Java allows using the Gradle or Maven tool. JavaScript - selecting JavaScript allows using the NPM tool. .Net - selecting .Net allows using the .Net tool. Note The Select Build Tool field disposes of the default tools and can be changed in accordance with the selected code language. Select the Multi-Module Project check box that becomes available if the Java code language and the Maven build tool are selected. Click the Proceed button to be switched to the next menu. Note If your project is a multi-modular, add a property to the project root POM-file: <deployable.module> for a Maven project. <DeployableModule> for a DotNet project. The Advanced Settings Menu \u00b6 Select CI pipeline provisioner that will be handling a codebase. For details, refer to the Add Job Provision instruction and become familiar with the main steps to add an additional job provisioner. Select Jenkins slave that will be used to handle a codebase. For details, refer to the Add Jenkins Slave instruction and inspect the steps that should be done to add a new Jenkins slave. Select the necessary codebase versioning type: default - the previous versioning logic that is realized in EDP Admin Console 2.2.0 and lower versions. Using the default versioning type, in order to specify the version of the current artifacts, images, and tags in the Version Control System, a developer should navigate to the corresponding file and change the version manually . edp - the new versioning logic that is available in EDP Admin Console 2.3.0 and subsequent versions. Using the edp versioning type, a developer indicates the version number from which all the artifacts will be versioned and, as a result, automatically registered in the corresponding file (e.g. pom.xml). When selecting the edp versioning type, the extra field will appear: a. Type the version number from which you want the artifacts to be versioned. Note The Start Version From field should be filled out in compliance with the semantic versioning rules, e.g. 1.2.3 or 10.10.10. In the Select Deployment Script field, specify one of the available options: helm-chart / openshift-template that are predefined in case it is OpenShift or EKS. In the Select CI Tool field, choose the necessary tool: Jenkins or GitLab CI, where Jenkins is the default tool and the GitLab CI tool can be additionally adjusted. For details, please refer to the Adjust GitLab CI Tool page. Note The GitLab CI tool is available only with the Import strategy and makes the Jira integration feature unavailable. Select the Integrate with Jira Server checkbox in case it is required to connect Jira tickets with the commits and have a respective label in the Fix Version field. Note To adjust the Jira integration functionality, first apply the necessary changes described on the Adjust Integration With Jira Server page, and setup the VCS Integration With Jira Server . Pay attention that the Jira integration feature is not available when using the GitLab CI tool. In the Select Jira Server field, select the Jira server. Indicate the pattern using any character, which is followed on the project, to validate a commit message. Indicate the pattern using any character, which is followed on the project, to find a Jira ticket number in a commit message. In the Advanced Mapping section, specify the names of the Jira fields that should be filled in with attributes from EDP. Upon clicking the question mark icon, observe the tips on how to indicate and combine variables necessary for identifying the format of values to be displayed. a. Select the name of the field in a Jira ticket. The available fields are the following: Fix Version/s , Component/s and Labels . b. Select the pattern of predefined variables, based on which the value from EDP will be displayed in Jira. Combine several variables to obtain the desired value. For the Fix Version/s field, select the EDP_VERSION variable that represents an EDP upgrade version, as in 2.7.0-SNAPSHOT . Combine variables to make the value more informative. For example, the pattern EDP_VERSION-EDP_COMPONENT will be displayed as 2.7.0-SNAPSHOT-nexus-operator in Jira; For the Component/s field, select the EDP_COMPONENT variable that defines the name of the existing repository. For example, nexus-operator ; For the Labels field, select the EDP_GITTAG variable that defines a tag assigned to the commit in GitHub. For example, build/2.7.0-SNAPSHOT.59 . c. Click the plus icon to add more Jira field names. d. Click the delete icon to remove the Jira field name. Select the Integrate with Perf Server checkbox in case it is required to connect to the PERF Board ( Project Performance Board ). Such functionality allows monitoring the overall team performance and setting up necessary metrics. Note To adjust the Perf Server integration functionality, first deploy Perf Operator. To get more information about the Perf Operator installation and architecture, please refer to the PERF Operator page. In the Select Perf Server field, select the name of the Perf server with which the integration should be performed. Click the Proceed button to be switched to the next menu. Select the necessary DataSource ( Jenkins/GitLab, Sonar ) from which the data should be transferred to the Project Performance Board. Click the Proceed button to be switched to the next menu. The Version Control System Info Menu \u00b6 Enter the login credentials into the VCS Login field. Enter the password into the VCS Password (or API Token) field OR add the API Token. Click the Proceed button to be switched to the next menu. Note The VCS Info step is skipped in case there is no need to integrate the version control for the application deployment. If the cloned application includes the VCS, this step should be completed as well. The Exposing Service Info Menu \u00b6 Select the Need Route check box to create a route component in the OpenShift project for the externally reachable host name. As a result, the added application will be accessible in a browser. Fill in the necessary fields and proceed to the final menu: Name \u2013 type the name by entering at least two characters and by using the lower-case letters, numbers and inner dashes. The mentioned name will be as a prefix for the host name. Path \u2013 specify the path starting with the /api characters. The mentioned path will be at the end of the URL path. Click the Proceed button. Once clicked, the CONFIRMATION summary will appear displaying all the specified options and settings, click Continue to complete the application addition. Note After the complete adding of the application, please refer to the Application Overview page. Related Articles \u00b6 Application Overview Delivery Dashboard Diagram Add CD Pipelines Adjust Integration With Jira Server Adjust VCS Integration With Jira Server","title":"Add Application"},{"location":"user-guide/add-application/#add-application","text":"Admin Console allows to create, clone, import an application and add it to the environment with its subsequent deployment in Gerrit and building of the Code Review and Build pipelines in Jenkins. To add an application, navigate to the Applications section on the left-side navigation bar and click the Create button. Once clicked, the six-step menu will appear: The Codebase Info Menu The Application Info Menu The Advanced Settings Menu The Version Control System Info Menu The Exposing Service Info Menu The Database Menu Note The Version Control System Info menu is available in case this option is predefined","title":"Add Application"},{"location":"user-guide/add-application/#the-codebase-info-menu","text":"In the Codebase Integration Strategy field, select the necessary option that is the configuration strategy for the replication with Gerrit: Create \u2013 creates a project on the pattern in accordance with an application language, a build tool, and a framework. Clone \u2013 clones the indicated repository into EPAM Delivery Platform. While cloning the existing repository, you have to fill in the additional fields as well. Import - allows configuring a replication from the Git server. While importing the existing repository, you have to select the Git server and define the respective path to the repository. Note In order to use the import strategy, make sure to adjust it by following the Adjust Import Strategy page. In the Git Repository URL field, specify the link to the repository that is to be cloned. If the Import strategy is selected, specify the following fields: a. Git Server where the repository is located. b. Relative path to the repository on the server. Select the Codebase Authentication check box and fill in the requested fields: Repository Login \u2013 enter your login data. Repository password (or API Token) \u2013 enter your password or indicate the API Token. Note The Codebase Authentication check box should be selected just in case you clone the private repository. If you define the public one, there is no need to enter credentials. Click the Proceed button to be switched to the next menu.","title":"The Codebase Info Menu"},{"location":"user-guide/add-application/#the-application-info-menu","text":"Type the name of the application in the Application Name field by entering at least two characters and by using the lower-case letters, numbers and inner dashes. Note If the Import strategy is used, the Application Name field will not be displayed. Specify the name of the default branch where you want the development to be performed. Note The default branch cannot be deleted. Select any of the supported application languages with its framework in the Application Code Language/framework field: Java \u2013 selecting Java allows using Java 8 or Java 11. JavaScript - selecting JavaScript allows using the React framework. DotNet - selecting DotNet allows using the DotNet v.2.1 and DotNet v.3.1. Go - selecting Go allows using the Beego and Operator SDK frameworks. Python - selecting Python allows using the Python v.3.8. Other - selecting Other allows extending the default code languages when creating a codebase with the clone/import strategy. To add another code language, inspect the Add Other Code Language section. Note The Create strategy does not allow to customize the default code language set. Choose the necessary build tool in the Select Build Tool field: Java - selecting Java allows using the Gradle or Maven tool. JavaScript - selecting JavaScript allows using the NPM tool. .Net - selecting .Net allows using the .Net tool. Note The Select Build Tool field disposes of the default tools and can be changed in accordance with the selected code language. Select the Multi-Module Project check box that becomes available if the Java code language and the Maven build tool are selected. Click the Proceed button to be switched to the next menu. Note If your project is a multi-modular, add a property to the project root POM-file: <deployable.module> for a Maven project. <DeployableModule> for a DotNet project.","title":"The Application Info Menu"},{"location":"user-guide/add-application/#the-advanced-settings-menu","text":"Select CI pipeline provisioner that will be handling a codebase. For details, refer to the Add Job Provision instruction and become familiar with the main steps to add an additional job provisioner. Select Jenkins slave that will be used to handle a codebase. For details, refer to the Add Jenkins Slave instruction and inspect the steps that should be done to add a new Jenkins slave. Select the necessary codebase versioning type: default - the previous versioning logic that is realized in EDP Admin Console 2.2.0 and lower versions. Using the default versioning type, in order to specify the version of the current artifacts, images, and tags in the Version Control System, a developer should navigate to the corresponding file and change the version manually . edp - the new versioning logic that is available in EDP Admin Console 2.3.0 and subsequent versions. Using the edp versioning type, a developer indicates the version number from which all the artifacts will be versioned and, as a result, automatically registered in the corresponding file (e.g. pom.xml). When selecting the edp versioning type, the extra field will appear: a. Type the version number from which you want the artifacts to be versioned. Note The Start Version From field should be filled out in compliance with the semantic versioning rules, e.g. 1.2.3 or 10.10.10. In the Select Deployment Script field, specify one of the available options: helm-chart / openshift-template that are predefined in case it is OpenShift or EKS. In the Select CI Tool field, choose the necessary tool: Jenkins or GitLab CI, where Jenkins is the default tool and the GitLab CI tool can be additionally adjusted. For details, please refer to the Adjust GitLab CI Tool page. Note The GitLab CI tool is available only with the Import strategy and makes the Jira integration feature unavailable. Select the Integrate with Jira Server checkbox in case it is required to connect Jira tickets with the commits and have a respective label in the Fix Version field. Note To adjust the Jira integration functionality, first apply the necessary changes described on the Adjust Integration With Jira Server page, and setup the VCS Integration With Jira Server . Pay attention that the Jira integration feature is not available when using the GitLab CI tool. In the Select Jira Server field, select the Jira server. Indicate the pattern using any character, which is followed on the project, to validate a commit message. Indicate the pattern using any character, which is followed on the project, to find a Jira ticket number in a commit message. In the Advanced Mapping section, specify the names of the Jira fields that should be filled in with attributes from EDP. Upon clicking the question mark icon, observe the tips on how to indicate and combine variables necessary for identifying the format of values to be displayed. a. Select the name of the field in a Jira ticket. The available fields are the following: Fix Version/s , Component/s and Labels . b. Select the pattern of predefined variables, based on which the value from EDP will be displayed in Jira. Combine several variables to obtain the desired value. For the Fix Version/s field, select the EDP_VERSION variable that represents an EDP upgrade version, as in 2.7.0-SNAPSHOT . Combine variables to make the value more informative. For example, the pattern EDP_VERSION-EDP_COMPONENT will be displayed as 2.7.0-SNAPSHOT-nexus-operator in Jira; For the Component/s field, select the EDP_COMPONENT variable that defines the name of the existing repository. For example, nexus-operator ; For the Labels field, select the EDP_GITTAG variable that defines a tag assigned to the commit in GitHub. For example, build/2.7.0-SNAPSHOT.59 . c. Click the plus icon to add more Jira field names. d. Click the delete icon to remove the Jira field name. Select the Integrate with Perf Server checkbox in case it is required to connect to the PERF Board ( Project Performance Board ). Such functionality allows monitoring the overall team performance and setting up necessary metrics. Note To adjust the Perf Server integration functionality, first deploy Perf Operator. To get more information about the Perf Operator installation and architecture, please refer to the PERF Operator page. In the Select Perf Server field, select the name of the Perf server with which the integration should be performed. Click the Proceed button to be switched to the next menu. Select the necessary DataSource ( Jenkins/GitLab, Sonar ) from which the data should be transferred to the Project Performance Board. Click the Proceed button to be switched to the next menu.","title":"The Advanced Settings Menu"},{"location":"user-guide/add-application/#the-version-control-system-info-menu","text":"Enter the login credentials into the VCS Login field. Enter the password into the VCS Password (or API Token) field OR add the API Token. Click the Proceed button to be switched to the next menu. Note The VCS Info step is skipped in case there is no need to integrate the version control for the application deployment. If the cloned application includes the VCS, this step should be completed as well.","title":"The Version Control System Info Menu"},{"location":"user-guide/add-application/#the-exposing-service-info-menu","text":"Select the Need Route check box to create a route component in the OpenShift project for the externally reachable host name. As a result, the added application will be accessible in a browser. Fill in the necessary fields and proceed to the final menu: Name \u2013 type the name by entering at least two characters and by using the lower-case letters, numbers and inner dashes. The mentioned name will be as a prefix for the host name. Path \u2013 specify the path starting with the /api characters. The mentioned path will be at the end of the URL path. Click the Proceed button. Once clicked, the CONFIRMATION summary will appear displaying all the specified options and settings, click Continue to complete the application addition. Note After the complete adding of the application, please refer to the Application Overview page.","title":"The Exposing Service Info Menu"},{"location":"user-guide/add-application/#related-articles","text":"Application Overview Delivery Dashboard Diagram Add CD Pipelines Adjust Integration With Jira Server Adjust VCS Integration With Jira Server","title":"Related Articles"},{"location":"user-guide/add-autotest/","text":"Add Autotests \u00b6 Admin Console enables to clone or import an autotest and add it to the environment with its subsequent deployment in Gerrit and building of the Code Review pipeline in Jenkins. Navigate to the Autotests section on the left-side navigation bar and click the Create button. Once clicked, the four-step menu will appear: The Codebase Info Menu The Autotest Info Menu The Advanced Settings Menu The Version Control System Info Menu The Codebase Info Menu \u00b6 There are two available strategies: clone and import. The Clone strategy flow is displayed below: Clone - this strategy allows cloning the autotest from the indicated repository into EPAM Delivery Platform. While cloning the existing repository, you have to fill in the additional fields as well. In the Git Repository URL field, specify the link to the repository with the autotest. Select the Codebase Authentication check box and fill in the requested fields: Repository Login \u2013 enter your login data. Repository password (or API Token) \u2013 enter your password or indicate the API Token. If there is a necessity to use the Import strategy that allows configuring a replication from the Git server, explore the steps below: a. Import - this strategy allows configuring a replication from the Git server. Note In order to use the import strategy, make sure to adjust it by following the Adjust Import Strategy page. b. In the Git Server field, select the necessary Git server from the drop-down list. c. In the Relative path field, indicate the respective path to the repository, e.g. /epmd-edp/examples/basic/edp-auto-tests-simple-example . After completing the Codebase Info menu step, click the Proceed button to be switched to the next menu. The Autotest Info Menu \u00b6 Fill in the Autotest Name field by entering at least two characters and by using the lower-case letters, numbers and inner dashes. Info The Import strategy does not have an Autotest Name field. Specify the name of the default branch where you want the development to be performed. Note The default branch cannot be deleted. Type the necessary description in the Description field. In the Autotest Code Language field, select the Java code language (specify Java 8 or Java 11 to be used) and get the default Maven build tool OR add another code language. Selecting Other allows extending the default code languages and get the necessary build tool, for details, inspect the Add Other Code Language section. The Select Build Tool field can dispose of the default Maven tool, Gradle or other built tool in accordance with the selected code language. All the autotest reports will be created in the Allure framework that is available In the Autotest Report Framework field by default. Click the Proceed button to be switched to the next menu. The Advanced Settings Menu \u00b6 Select CI pipeline provisioner that will be used to handle a codebase. For details, refer to the Add Job Provision instruction and become familiar with the main steps to add an additional job provisioner. Select Jenkins slave that will be used to handle a codebase. For details, refer to the Add Jenkins Slave instruction and inspect the steps that should be done to add a new Jenkins slave. Select the necessary codebase versioning type: default - the previous versioning logic that is realized in EDP Admin Console 2.2.0 and lower versions. Using the default versioning type, in order to specify the version of the current artifacts, images, and tags in the Version Control System, a developer should navigate to the corresponding file and change the version manually . edp - the new versioning logic that is available in EDP Admin Console 2.3.0 and subsequent versions. Using the edp versioning type, a developer indicates the version number from which all the artifacts will be versioned and, as a result, automatically registered in the corresponding file (e.g. pom.xml). When selecting the edp versioning type, the extra field will appear: a. Type the version number from which you want the artifacts to be versioned. Note The Start Version From field should be filled out in compliance with the semantic versioning rules, e.g. 1.2.3 or 10.10.10. In the Select CI Tool field, choose the necessary tool: Jenkins or GitLab CI, where Jenkins is the default tool and the GitLab CI tool can be additionally adjusted. For details, please refer to the Adjust GitLab CI Tool page. Note The GitLab CI tool is available only with the Import strategy and makes the Jira integration feature unavailable. Select the Integrate with Jira Server checkbox in case it is required to connect Jira tickets with the commits and have a respective label in the Fix Version field. Note To adjust the Jira integration functionality, first apply the necessary changes described on the Adjust Integration With Jira Server page, and setup the VCS Integration With Jira Server . Pay attention that the Jira integration feature is not available when using the GitLab CI tool. As soon as the Jira server is set, select it in the Select Jira Server field. Indicate the pattern using any character, which is followed on the project, to validate a commit message. Indicate the pattern using any character, which is followed on the project, to find a Jira ticket number in a commit message. In the Advanced Mapping section, specify the names of the Jira fields that should be filled in with attributes from EDP. Upon clicking the question mark icon, observe the tips on how to indicate and combine variables necessary for identifying the format of values to be displayed. a. Select the name of the field in a Jira ticket. The available fields are the following: Fix Version/s , Component/s and Labels . b. Select the pattern of predefined variables, based on which the value from EDP will be displayed in Jira. Combine several variables to obtain the desired value. For the Fix Version/s field, select the EDP_VERSION variable that represents an EDP upgrade version, as in 2.7.0-SNAPSHOT . Combine variables to make the value more informative. For example, the pattern EDP_VERSION-EDP_COMPONENT will be displayed as 2.7.0-SNAPSHOT-nexus-operator in Jira; For the Component/s field, select the EDP_COMPONENT variable that defines the name of the existing repository. For example, nexus-operator ; For the Labels field, select the EDP_GITTAG variable that defines a tag assigned to the commit in GitHub. For example, build/2.7.0-SNAPSHOT.59 . c. Click the plus icon to add more Jira field names. d. Click the delete icon to remove the Jira field name. Select the Integrate with Perf Server checkbox in case it is required to connect to the PERF Board ( Project Performance Board ). Such functionality allows monitoring the overall team performance and setting up necessary metrics. Note To adjust the Perf Server integration functionality, first deploy Perf Operator. To get more information about the Perf Operator installation and architecture, please refer to the PERF Operator page. In the Select Perf Server field, select the name of the Perf server with which the integration should be performed and click the Proceed button to be switched to the next menu. Select the necessary DataSource ( Jenkins/GitLab, Sonar ) from which the data should be transferred to the Project Performance Board. Click the Create button to create an autotest or click the Proceed button to be switched to the next VCS menu that can be predefined. The Version Control System Info Menu \u00b6 Once navigated to the VCS Info menu, perform the following: Enter the login credentials into the VCS Login field. Enter the password into the VCS Password (or API Token) field OR add the API Token. Click the Create button, check the CONFIRMATION summary, click Continue to add an autotest to the Autotests list. Note After the complete adding of the autotest, inspect the Autotest Overview part. Related Articles \u00b6 Autotest Overview Delivery Dashboard Diagram Add CD Pipelines Adjust Integration With Jira Server Adjust VCS Integration With Jira Server","title":"Add Autotests"},{"location":"user-guide/add-autotest/#add-autotests","text":"Admin Console enables to clone or import an autotest and add it to the environment with its subsequent deployment in Gerrit and building of the Code Review pipeline in Jenkins. Navigate to the Autotests section on the left-side navigation bar and click the Create button. Once clicked, the four-step menu will appear: The Codebase Info Menu The Autotest Info Menu The Advanced Settings Menu The Version Control System Info Menu","title":"Add Autotests"},{"location":"user-guide/add-autotest/#the-codebase-info-menu","text":"There are two available strategies: clone and import. The Clone strategy flow is displayed below: Clone - this strategy allows cloning the autotest from the indicated repository into EPAM Delivery Platform. While cloning the existing repository, you have to fill in the additional fields as well. In the Git Repository URL field, specify the link to the repository with the autotest. Select the Codebase Authentication check box and fill in the requested fields: Repository Login \u2013 enter your login data. Repository password (or API Token) \u2013 enter your password or indicate the API Token. If there is a necessity to use the Import strategy that allows configuring a replication from the Git server, explore the steps below: a. Import - this strategy allows configuring a replication from the Git server. Note In order to use the import strategy, make sure to adjust it by following the Adjust Import Strategy page. b. In the Git Server field, select the necessary Git server from the drop-down list. c. In the Relative path field, indicate the respective path to the repository, e.g. /epmd-edp/examples/basic/edp-auto-tests-simple-example . After completing the Codebase Info menu step, click the Proceed button to be switched to the next menu.","title":"The Codebase Info Menu"},{"location":"user-guide/add-autotest/#the-autotest-info-menu","text":"Fill in the Autotest Name field by entering at least two characters and by using the lower-case letters, numbers and inner dashes. Info The Import strategy does not have an Autotest Name field. Specify the name of the default branch where you want the development to be performed. Note The default branch cannot be deleted. Type the necessary description in the Description field. In the Autotest Code Language field, select the Java code language (specify Java 8 or Java 11 to be used) and get the default Maven build tool OR add another code language. Selecting Other allows extending the default code languages and get the necessary build tool, for details, inspect the Add Other Code Language section. The Select Build Tool field can dispose of the default Maven tool, Gradle or other built tool in accordance with the selected code language. All the autotest reports will be created in the Allure framework that is available In the Autotest Report Framework field by default. Click the Proceed button to be switched to the next menu.","title":"The Autotest Info Menu"},{"location":"user-guide/add-autotest/#the-advanced-settings-menu","text":"Select CI pipeline provisioner that will be used to handle a codebase. For details, refer to the Add Job Provision instruction and become familiar with the main steps to add an additional job provisioner. Select Jenkins slave that will be used to handle a codebase. For details, refer to the Add Jenkins Slave instruction and inspect the steps that should be done to add a new Jenkins slave. Select the necessary codebase versioning type: default - the previous versioning logic that is realized in EDP Admin Console 2.2.0 and lower versions. Using the default versioning type, in order to specify the version of the current artifacts, images, and tags in the Version Control System, a developer should navigate to the corresponding file and change the version manually . edp - the new versioning logic that is available in EDP Admin Console 2.3.0 and subsequent versions. Using the edp versioning type, a developer indicates the version number from which all the artifacts will be versioned and, as a result, automatically registered in the corresponding file (e.g. pom.xml). When selecting the edp versioning type, the extra field will appear: a. Type the version number from which you want the artifacts to be versioned. Note The Start Version From field should be filled out in compliance with the semantic versioning rules, e.g. 1.2.3 or 10.10.10. In the Select CI Tool field, choose the necessary tool: Jenkins or GitLab CI, where Jenkins is the default tool and the GitLab CI tool can be additionally adjusted. For details, please refer to the Adjust GitLab CI Tool page. Note The GitLab CI tool is available only with the Import strategy and makes the Jira integration feature unavailable. Select the Integrate with Jira Server checkbox in case it is required to connect Jira tickets with the commits and have a respective label in the Fix Version field. Note To adjust the Jira integration functionality, first apply the necessary changes described on the Adjust Integration With Jira Server page, and setup the VCS Integration With Jira Server . Pay attention that the Jira integration feature is not available when using the GitLab CI tool. As soon as the Jira server is set, select it in the Select Jira Server field. Indicate the pattern using any character, which is followed on the project, to validate a commit message. Indicate the pattern using any character, which is followed on the project, to find a Jira ticket number in a commit message. In the Advanced Mapping section, specify the names of the Jira fields that should be filled in with attributes from EDP. Upon clicking the question mark icon, observe the tips on how to indicate and combine variables necessary for identifying the format of values to be displayed. a. Select the name of the field in a Jira ticket. The available fields are the following: Fix Version/s , Component/s and Labels . b. Select the pattern of predefined variables, based on which the value from EDP will be displayed in Jira. Combine several variables to obtain the desired value. For the Fix Version/s field, select the EDP_VERSION variable that represents an EDP upgrade version, as in 2.7.0-SNAPSHOT . Combine variables to make the value more informative. For example, the pattern EDP_VERSION-EDP_COMPONENT will be displayed as 2.7.0-SNAPSHOT-nexus-operator in Jira; For the Component/s field, select the EDP_COMPONENT variable that defines the name of the existing repository. For example, nexus-operator ; For the Labels field, select the EDP_GITTAG variable that defines a tag assigned to the commit in GitHub. For example, build/2.7.0-SNAPSHOT.59 . c. Click the plus icon to add more Jira field names. d. Click the delete icon to remove the Jira field name. Select the Integrate with Perf Server checkbox in case it is required to connect to the PERF Board ( Project Performance Board ). Such functionality allows monitoring the overall team performance and setting up necessary metrics. Note To adjust the Perf Server integration functionality, first deploy Perf Operator. To get more information about the Perf Operator installation and architecture, please refer to the PERF Operator page. In the Select Perf Server field, select the name of the Perf server with which the integration should be performed and click the Proceed button to be switched to the next menu. Select the necessary DataSource ( Jenkins/GitLab, Sonar ) from which the data should be transferred to the Project Performance Board. Click the Create button to create an autotest or click the Proceed button to be switched to the next VCS menu that can be predefined.","title":"The Advanced Settings Menu"},{"location":"user-guide/add-autotest/#the-version-control-system-info-menu","text":"Once navigated to the VCS Info menu, perform the following: Enter the login credentials into the VCS Login field. Enter the password into the VCS Password (or API Token) field OR add the API Token. Click the Create button, check the CONFIRMATION summary, click Continue to add an autotest to the Autotests list. Note After the complete adding of the autotest, inspect the Autotest Overview part.","title":"The Version Control System Info Menu"},{"location":"user-guide/add-autotest/#related-articles","text":"Autotest Overview Delivery Dashboard Diagram Add CD Pipelines Adjust Integration With Jira Server Adjust VCS Integration With Jira Server","title":"Related Articles"},{"location":"user-guide/add-cd-pipeline/","text":"Add CD pipeline \u00b6 Admin Console provides the ability to deploy an environment on your own and specify the essential components as well. Navigate to the Continuous Delivery section on the left-side navigation bar and click the Create button. Once clicked, the four-step menu will appear: The Pipeline Menu The Applications Menu The Stages Menu The creation of the CD pipeline becomes available as soon as an application is created including its provisioning in a branch and the necessary entities for the environment. After the complete adding of the CD pipeline, inspect the Check CD Pipeline Availability part. The Pipeline Menu \u00b6 Type the name of the pipeline in the Pipeline Name field by entering at least two characters and by using the lower-case letters, numbers and inner dashes. Click the Proceed button to be switched to the next menu. The Applications Menu \u00b6 Select the check box of the necessary application in the Applications menu. Specify the necessary codebase Docker stream (the output for the branch and other stages from other CD pipelines) from the drop-down menu. Select the Promote in pipeline check box in order to transfer the application from one to another stage by the specified codebase Docker stream. If the Promote in pipeline check box is not selected, the same codebase Docker stream will be deployed regardless of the stage, i.e. the codebase Docker stream input, which was selected for the pipeline, will be always used. Note The newly created CD pipeline has the following pattern combination: [pipeline name]-[branch name]. If there is another deployed CD pipeline stage with the respective codebase Docker stream (= image stream as an OpenShift term), the pattern combination will be as follows: [pipeline name]-[stage name]-[application name]-[verified]; Click the Proceed button to be switched to the next menu. The Stages Menu \u00b6 Click the plus sign icon in the Stages menu and fill in the necessary fields in the Adding Stage window: a. Type the stage name; b. Enter the description for this stage; c. Select the quality gate type: Manual - means that the promoting process should be confirmed in Jenkins manually; Autotests - means that the promoting process should be confirmed by the successful passing of the autotests. In the additional fields, select the previously created autotest name and specify its branch for the autotest that will be launched on the current stage. d. Type the step name, which will be displayed in Jenkins, for every quality gate type; e. Select the trigger type that allows promoting images to the next environment. The available trigger types are manual and auto . By selecting the auto trigger type, the CD pipeline will be launched automatically. Info Add an unlimited number of quality gates by clicking a corresponding plus sign icon and remove them as well by clicking the recycle bin icon. Note Execution sequence. The image promotion and execution of the pipelines depend on the sequence in which the environments are added. Click the Add button to display it in the Stages menu: Info Perform the same steps as described above if there is a necessity to add one more stage. Edit the stage by clicking its name and applying changes, and remove the added stage by clicking the recycle bin icon next to its name. Click the Create button to start the provisioning of the pipeline. After the CD pipeline is added, the new project with the stage name will be created in OpenShift. Check CD Pipeline Availability \u00b6 As soon as the CD pipeline is provisioned and added to the CD Pipelines list, there is an ability to: Create another application by clicking the Create button and performing the same steps as described in the Add CD Pipeline section. Select a number of existing CD pipelines to be displayed on one page in the Show entries field. The filter allows to show 10, 25, 50 or 100 entries per page. Sort the existing CD pipelines in a list by clicking the Name title. The CD pipelines will be displayed in alphabetical order. Search the necessary CD pipeline by entering the corresponding name, language or the build tool into the Search field. Navigate between pages if the number of CD pipelines exceeds the capacity of a single page. Edit CD Pipeline \u00b6 Edit the CD pipeline by clicking the pen icon next to its name in the CD Pipelines list: apply the necessary changes and click the Proceed button to confirm the editions: add new extra stages steps by clicking the plus sign icon and filling in the necessary fields in the Adding Stage window. Note The added stage will appear in the Stages menu allowing to review its details or delete. Check the CD pipeline data and details by clicking the CD pipeline name in the CD Pipelines list: the main link on the top of the details page refers to Jenkins; the pen icon refers to the same Edit CD Pipeline page as mentioned above and allows to apply the necessary changes; the Applications menu has the main information about the applications with the respective codebase Docker streams and links to Jenkins and Gerrit as well as the signification of the promotion in CD pipeline; the Stages menu includes the stages data that was previously mentioned, the direct links to the respective to every stage OpenShift page, and the link to the Autotest details page in case there are added autotests. Note The deletion of stages is performed sequentially, starting from the latest created stage. In order to remove a stage , click the corresponding delete icon, type the CD pipeline name and confirm the deletion by clicking the Delete button. If you remove the last stage, the whole CD pipeline will be removed as the CD pipeline does not exist without stages. the Deployed Version menu indicates the applications and stages with the appropriate status. The status will be changed after stage deployment. the Status Info menu displays all the actions that were performed during the deployment process: Remove the added CD pipeline: Info If there is a necessity to create another CD pipeline, navigate to the Continuous Delivery section, click the Create button and perform the same steps as described above. Related Articles \u00b6 EDP Admin Console Delivery Dashboard Diagram","title":"Add CD pipeline"},{"location":"user-guide/add-cd-pipeline/#add-cd-pipeline","text":"Admin Console provides the ability to deploy an environment on your own and specify the essential components as well. Navigate to the Continuous Delivery section on the left-side navigation bar and click the Create button. Once clicked, the four-step menu will appear: The Pipeline Menu The Applications Menu The Stages Menu The creation of the CD pipeline becomes available as soon as an application is created including its provisioning in a branch and the necessary entities for the environment. After the complete adding of the CD pipeline, inspect the Check CD Pipeline Availability part.","title":"Add CD pipeline"},{"location":"user-guide/add-cd-pipeline/#the-pipeline-menu","text":"Type the name of the pipeline in the Pipeline Name field by entering at least two characters and by using the lower-case letters, numbers and inner dashes. Click the Proceed button to be switched to the next menu.","title":"The Pipeline Menu"},{"location":"user-guide/add-cd-pipeline/#the-applications-menu","text":"Select the check box of the necessary application in the Applications menu. Specify the necessary codebase Docker stream (the output for the branch and other stages from other CD pipelines) from the drop-down menu. Select the Promote in pipeline check box in order to transfer the application from one to another stage by the specified codebase Docker stream. If the Promote in pipeline check box is not selected, the same codebase Docker stream will be deployed regardless of the stage, i.e. the codebase Docker stream input, which was selected for the pipeline, will be always used. Note The newly created CD pipeline has the following pattern combination: [pipeline name]-[branch name]. If there is another deployed CD pipeline stage with the respective codebase Docker stream (= image stream as an OpenShift term), the pattern combination will be as follows: [pipeline name]-[stage name]-[application name]-[verified]; Click the Proceed button to be switched to the next menu.","title":"The Applications Menu"},{"location":"user-guide/add-cd-pipeline/#the-stages-menu","text":"Click the plus sign icon in the Stages menu and fill in the necessary fields in the Adding Stage window: a. Type the stage name; b. Enter the description for this stage; c. Select the quality gate type: Manual - means that the promoting process should be confirmed in Jenkins manually; Autotests - means that the promoting process should be confirmed by the successful passing of the autotests. In the additional fields, select the previously created autotest name and specify its branch for the autotest that will be launched on the current stage. d. Type the step name, which will be displayed in Jenkins, for every quality gate type; e. Select the trigger type that allows promoting images to the next environment. The available trigger types are manual and auto . By selecting the auto trigger type, the CD pipeline will be launched automatically. Info Add an unlimited number of quality gates by clicking a corresponding plus sign icon and remove them as well by clicking the recycle bin icon. Note Execution sequence. The image promotion and execution of the pipelines depend on the sequence in which the environments are added. Click the Add button to display it in the Stages menu: Info Perform the same steps as described above if there is a necessity to add one more stage. Edit the stage by clicking its name and applying changes, and remove the added stage by clicking the recycle bin icon next to its name. Click the Create button to start the provisioning of the pipeline. After the CD pipeline is added, the new project with the stage name will be created in OpenShift.","title":"The Stages Menu"},{"location":"user-guide/add-cd-pipeline/#check-cd-pipeline-availability","text":"As soon as the CD pipeline is provisioned and added to the CD Pipelines list, there is an ability to: Create another application by clicking the Create button and performing the same steps as described in the Add CD Pipeline section. Select a number of existing CD pipelines to be displayed on one page in the Show entries field. The filter allows to show 10, 25, 50 or 100 entries per page. Sort the existing CD pipelines in a list by clicking the Name title. The CD pipelines will be displayed in alphabetical order. Search the necessary CD pipeline by entering the corresponding name, language or the build tool into the Search field. Navigate between pages if the number of CD pipelines exceeds the capacity of a single page.","title":"Check CD Pipeline Availability"},{"location":"user-guide/add-cd-pipeline/#edit-cd-pipeline","text":"Edit the CD pipeline by clicking the pen icon next to its name in the CD Pipelines list: apply the necessary changes and click the Proceed button to confirm the editions: add new extra stages steps by clicking the plus sign icon and filling in the necessary fields in the Adding Stage window. Note The added stage will appear in the Stages menu allowing to review its details or delete. Check the CD pipeline data and details by clicking the CD pipeline name in the CD Pipelines list: the main link on the top of the details page refers to Jenkins; the pen icon refers to the same Edit CD Pipeline page as mentioned above and allows to apply the necessary changes; the Applications menu has the main information about the applications with the respective codebase Docker streams and links to Jenkins and Gerrit as well as the signification of the promotion in CD pipeline; the Stages menu includes the stages data that was previously mentioned, the direct links to the respective to every stage OpenShift page, and the link to the Autotest details page in case there are added autotests. Note The deletion of stages is performed sequentially, starting from the latest created stage. In order to remove a stage , click the corresponding delete icon, type the CD pipeline name and confirm the deletion by clicking the Delete button. If you remove the last stage, the whole CD pipeline will be removed as the CD pipeline does not exist without stages. the Deployed Version menu indicates the applications and stages with the appropriate status. The status will be changed after stage deployment. the Status Info menu displays all the actions that were performed during the deployment process: Remove the added CD pipeline: Info If there is a necessity to create another CD pipeline, navigate to the Continuous Delivery section, click the Create button and perform the same steps as described above.","title":"Edit CD Pipeline"},{"location":"user-guide/add-cd-pipeline/#related-articles","text":"EDP Admin Console Delivery Dashboard Diagram","title":"Related Articles"},{"location":"user-guide/add-library/","text":"Add Library \u00b6 Admin Console helps to create, clone or import a library and add it to the environment with its subsequent deployment in Gerrit and building of the Code Review and Build pipelines in Jenkins. Navigate to the Libraries section on the left-side navigation bar and click the Create button. Once clicked, the four-step menu will appear: The Codebase Info Menu The Library Info Menu The Advanced Settings Menu The Version Control System Info Menu Note The Version Control System Info menu is available in case this option is predefined. The Codebase Info Menu \u00b6 In the Codebase Integration Strategy field, select the necessary option that is the configuration strategy for the replication with Gerrit: Create \u2013 creates a project on the pattern in accordance with a code language, a build tool, and a framework. Clone \u2013 clones the indicated repository into EPAM Delivery Platform. Note While cloning the existing repository, you have to fill in the additional fields as well. Import - allows configuring a replication from the Git server. While importing the existing repository, you have to select the Git server and define the respective path to the repository. Note In order to use the import strategy, make sure to adjust it by following the Adjust Import Strategy page. In the Git Repository URL field, specify the link to the repository that is to be cloned. Select the Codebase Authentication check box and fill in the requested fields: Repository Login \u2013 enter your login data. Repository password (or API Token) \u2013 enter your password or indicate the API Token. Click the Proceed button to be switched to the next menu. The Library Info Menu \u00b6 Type the name of the library in the Library Name field by entering at least two characters and by using the lower-case letters, numbers and inner dashes. Info If the Import strategy is used, the Library Name field will not be displayed. Specify the name of the default branch where you want the development to be performed. Note The default branch cannot be deleted. Select any of the supported code languages in the Library Code Language block: Java \u2013 selecting Java allows specify Java 8 or Java 11, and further usage of the Gradle or Maven tool. JavaScript - selecting JavaScript allows using the NPM tool. DotNet - selecting DotNet allows using the DotNet v.2.1 and DotNet v.3.1. Groovy-pipeline - selecting Groovy-pipeline allows having the ability to customize a stages logic. For details, please refer to the Customize CD Pipeline page. Python - selecting Python allows using the Python v.3.8. Terraform - selecting Terraform allows using the Terraform different versions via the Terraform version manager ( tfenv ). EDP supports all actions available in Terraform, thus providing the ability to modify the virtual infrastructure and launch some checks with the help of linters. For details, please refer to the Use Terraform Library in EDP page. Other - selecting Other allows extending the default code languages when creating a codebase with the clone/import strategy. To add another code language, inspect the Add Other Code Language page. Note The Create strategy does not allow to customize the default code language set. The Select Build Tool field disposes of the default tools and can be changed in accordance with the selected code language. Click the Proceed button to be switched to the next menu. The Advanced Settings Menu \u00b6 Select the CI pipeline provisioner that will be used to handle a codebase. For details, refer to the Add Job Provision instruction and become familiar with the main steps to add an additional job provisioner. Select Jenkins slave that will be used to handle a codebase. For details, refer to the Add Jenkins Slave instruction and inspect the steps that should be done to add a new Jenkins slave. Select the necessary codebase versioning type: default - the previous versioning logic that is realized in EDP Admin Console 2.2.0 and lower versions. Using the default versioning type, in order to specify the version of the current artifacts, images, and tags in the Version Control System, a developer should navigate to the corresponding file and change the version manually . edp - the new versioning logic that is available in EDP Admin Console 2.3.0 and subsequent versions. Using the edp versioning type, a developer indicates the version number from which all the artifacts will be versioned and, as a result, automatically registered in the corresponding file (e.g. pom.xml). When selecting the edp versioning type, the extra field will appear: a. Type the version number from which you want the artifacts to be versioned. Note The Start Version From field should be filled out in compliance with the semantic versioning rules, e.g. 1.2.3 or 10.10.10. In the Select CI Tool field, choose the necessary tool: Jenkins or GitLab CI, where Jenkins is the default tool and the GitLab CI tool can be additionally adjusted. For details, please refer to the Adjust GitLab CI Tool page. Note The GitLab CI tool is available only with the Import strategy and makes the Jira integration feature unavailable. Select the Integrate with Jira Server checkbox in case it is required to connect Jira tickets with the commits and have a respective label in the Fix Version field. Note To adjust the Jira integration functionality, first apply the necessary changes described on the Adjust Integration With Jira Server page, and setup the VCS Integration With Jira Server . Pay attention that the Jira integration feature is not available when using the GitLab CI tool. As soon as the Jira server is set, select it in the Select Jira Server field. Indicate the pattern using any character, which is followed on the project, to validate a commit message. Indicate the pattern using any character, which is followed on the project, to find a Jira ticket number in a commit message. In the Advanced Mapping section, specify the names of the Jira fields that should be filled in with attributes from EDP. Upon clicking the question mark icon, observe the tips on how to indicate and combine variables necessary for identifying the format of values to be displayed. a. Select the name of the field in a Jira ticket. The available fields are the following: Fix Version/s , Component/s and Labels . b. Select the pattern of predefined variables, based on which the value from EDP will be displayed in Jira. Combine several variables to obtain the desired value. For the Fix Version/s field, select the EDP_VERSION variable that represents an EDP upgrade version, as in 2.7.0-SNAPSHOT . Combine variables to make the value more informative. For example, the pattern EDP_VERSION-EDP_COMPONENT will be displayed as 2.7.0-SNAPSHOT-nexus-operator in Jira; For the Component/s field select the EDP_COMPONENT variable that defines the name of the existing repository. For example, nexus-operator ; For the Labels field select the EDP_GITTAG variable that defines a tag assigned to the commit in Git Hub. For example, build/2.7.0-SNAPSHOT.59 . c. Click the plus icon to add more Jira field names. d. Click the delete icon to remove the Jira field name. Select the Integrate with Perf Server checkbox in case it is required to connect to the PERF Board ( Project Performance Board ). Such functionality allows monitoring the overall team performance and setting up necessary metrics. Note To adjust the Perf Server integration functionality, first deploy Perf Operator. To get more information about the Perf Operator installation and architecture, please refer to the PERF Operator page. In the Select Perf Server field, select the name of the Perf server with which the integration should be performed. Click the Proceed button to be switched to the next menu. Select the necessary DataSource ( Jenkins/GitLab, Sonar ) from which the data should be transferred to the Project Performance Board. Click the Create button to create a library or click the Proceed button to be switched to the next VCS menu that can be predefined. The Version Control System Info Menu \u00b6 Enter the login credentials into the VCS Login field. Enter the password into the VCS Password (or API Token) field OR add the API Token. Click the Create button, check the CONFIRMATION summary, click Continue to add the library to the Libraries list. Note After the complete adding of the library, inspect the Library Overview part. Related Articles \u00b6 Library Overview Delivery Dashboard Diagram Add CD Pipeline Adjust Integration With Jira Server Adjust VCS Integration With Jira Server Use Terraform Library in EDP Use Open Policy Agent Library in EDP","title":"Add Library"},{"location":"user-guide/add-library/#add-library","text":"Admin Console helps to create, clone or import a library and add it to the environment with its subsequent deployment in Gerrit and building of the Code Review and Build pipelines in Jenkins. Navigate to the Libraries section on the left-side navigation bar and click the Create button. Once clicked, the four-step menu will appear: The Codebase Info Menu The Library Info Menu The Advanced Settings Menu The Version Control System Info Menu Note The Version Control System Info menu is available in case this option is predefined.","title":"Add Library"},{"location":"user-guide/add-library/#the-codebase-info-menu","text":"In the Codebase Integration Strategy field, select the necessary option that is the configuration strategy for the replication with Gerrit: Create \u2013 creates a project on the pattern in accordance with a code language, a build tool, and a framework. Clone \u2013 clones the indicated repository into EPAM Delivery Platform. Note While cloning the existing repository, you have to fill in the additional fields as well. Import - allows configuring a replication from the Git server. While importing the existing repository, you have to select the Git server and define the respective path to the repository. Note In order to use the import strategy, make sure to adjust it by following the Adjust Import Strategy page. In the Git Repository URL field, specify the link to the repository that is to be cloned. Select the Codebase Authentication check box and fill in the requested fields: Repository Login \u2013 enter your login data. Repository password (or API Token) \u2013 enter your password or indicate the API Token. Click the Proceed button to be switched to the next menu.","title":"The Codebase Info Menu"},{"location":"user-guide/add-library/#the-library-info-menu","text":"Type the name of the library in the Library Name field by entering at least two characters and by using the lower-case letters, numbers and inner dashes. Info If the Import strategy is used, the Library Name field will not be displayed. Specify the name of the default branch where you want the development to be performed. Note The default branch cannot be deleted. Select any of the supported code languages in the Library Code Language block: Java \u2013 selecting Java allows specify Java 8 or Java 11, and further usage of the Gradle or Maven tool. JavaScript - selecting JavaScript allows using the NPM tool. DotNet - selecting DotNet allows using the DotNet v.2.1 and DotNet v.3.1. Groovy-pipeline - selecting Groovy-pipeline allows having the ability to customize a stages logic. For details, please refer to the Customize CD Pipeline page. Python - selecting Python allows using the Python v.3.8. Terraform - selecting Terraform allows using the Terraform different versions via the Terraform version manager ( tfenv ). EDP supports all actions available in Terraform, thus providing the ability to modify the virtual infrastructure and launch some checks with the help of linters. For details, please refer to the Use Terraform Library in EDP page. Other - selecting Other allows extending the default code languages when creating a codebase with the clone/import strategy. To add another code language, inspect the Add Other Code Language page. Note The Create strategy does not allow to customize the default code language set. The Select Build Tool field disposes of the default tools and can be changed in accordance with the selected code language. Click the Proceed button to be switched to the next menu.","title":"The Library Info Menu"},{"location":"user-guide/add-library/#the-advanced-settings-menu","text":"Select the CI pipeline provisioner that will be used to handle a codebase. For details, refer to the Add Job Provision instruction and become familiar with the main steps to add an additional job provisioner. Select Jenkins slave that will be used to handle a codebase. For details, refer to the Add Jenkins Slave instruction and inspect the steps that should be done to add a new Jenkins slave. Select the necessary codebase versioning type: default - the previous versioning logic that is realized in EDP Admin Console 2.2.0 and lower versions. Using the default versioning type, in order to specify the version of the current artifacts, images, and tags in the Version Control System, a developer should navigate to the corresponding file and change the version manually . edp - the new versioning logic that is available in EDP Admin Console 2.3.0 and subsequent versions. Using the edp versioning type, a developer indicates the version number from which all the artifacts will be versioned and, as a result, automatically registered in the corresponding file (e.g. pom.xml). When selecting the edp versioning type, the extra field will appear: a. Type the version number from which you want the artifacts to be versioned. Note The Start Version From field should be filled out in compliance with the semantic versioning rules, e.g. 1.2.3 or 10.10.10. In the Select CI Tool field, choose the necessary tool: Jenkins or GitLab CI, where Jenkins is the default tool and the GitLab CI tool can be additionally adjusted. For details, please refer to the Adjust GitLab CI Tool page. Note The GitLab CI tool is available only with the Import strategy and makes the Jira integration feature unavailable. Select the Integrate with Jira Server checkbox in case it is required to connect Jira tickets with the commits and have a respective label in the Fix Version field. Note To adjust the Jira integration functionality, first apply the necessary changes described on the Adjust Integration With Jira Server page, and setup the VCS Integration With Jira Server . Pay attention that the Jira integration feature is not available when using the GitLab CI tool. As soon as the Jira server is set, select it in the Select Jira Server field. Indicate the pattern using any character, which is followed on the project, to validate a commit message. Indicate the pattern using any character, which is followed on the project, to find a Jira ticket number in a commit message. In the Advanced Mapping section, specify the names of the Jira fields that should be filled in with attributes from EDP. Upon clicking the question mark icon, observe the tips on how to indicate and combine variables necessary for identifying the format of values to be displayed. a. Select the name of the field in a Jira ticket. The available fields are the following: Fix Version/s , Component/s and Labels . b. Select the pattern of predefined variables, based on which the value from EDP will be displayed in Jira. Combine several variables to obtain the desired value. For the Fix Version/s field, select the EDP_VERSION variable that represents an EDP upgrade version, as in 2.7.0-SNAPSHOT . Combine variables to make the value more informative. For example, the pattern EDP_VERSION-EDP_COMPONENT will be displayed as 2.7.0-SNAPSHOT-nexus-operator in Jira; For the Component/s field select the EDP_COMPONENT variable that defines the name of the existing repository. For example, nexus-operator ; For the Labels field select the EDP_GITTAG variable that defines a tag assigned to the commit in Git Hub. For example, build/2.7.0-SNAPSHOT.59 . c. Click the plus icon to add more Jira field names. d. Click the delete icon to remove the Jira field name. Select the Integrate with Perf Server checkbox in case it is required to connect to the PERF Board ( Project Performance Board ). Such functionality allows monitoring the overall team performance and setting up necessary metrics. Note To adjust the Perf Server integration functionality, first deploy Perf Operator. To get more information about the Perf Operator installation and architecture, please refer to the PERF Operator page. In the Select Perf Server field, select the name of the Perf server with which the integration should be performed. Click the Proceed button to be switched to the next menu. Select the necessary DataSource ( Jenkins/GitLab, Sonar ) from which the data should be transferred to the Project Performance Board. Click the Create button to create a library or click the Proceed button to be switched to the next VCS menu that can be predefined.","title":"The Advanced Settings Menu"},{"location":"user-guide/add-library/#the-version-control-system-info-menu","text":"Enter the login credentials into the VCS Login field. Enter the password into the VCS Password (or API Token) field OR add the API Token. Click the Create button, check the CONFIRMATION summary, click Continue to add the library to the Libraries list. Note After the complete adding of the library, inspect the Library Overview part.","title":"The Version Control System Info Menu"},{"location":"user-guide/add-library/#related-articles","text":"Library Overview Delivery Dashboard Diagram Add CD Pipeline Adjust Integration With Jira Server Adjust VCS Integration With Jira Server Use Terraform Library in EDP Use Open Policy Agent Library in EDP","title":"Related Articles"},{"location":"user-guide/application/","text":"Application \u00b6 This section describes the subsequent possible actions that can be performed with the newly added or existing applications. Check and Remove Application \u00b6 As soon as the application is successfully provisioned, the following will be created: Code Review and Build pipelines in Jenkins for this application. The Build pipeline will be triggered automatically if at least one environment is already added. A new project in Gerrit or another VCS. SonarQube integration will be available after the Build pipeline in Jenkins is passed. Nexus Repository Manager will be available after the Build pipeline in Jenkins is passed as well. Info To navigate quickly to OpenShift, Jenkins, Gerrit, SonarQube, Nexus, and other resources, click the Overview section on the navigation bar and hit the necessary link. The added application will be listed in the Applications list allowing you to do the following: Create another application by clicking the Create button and performing the same steps as described in Add Applications section. Open application data by clicking its link name. Once clicked, the following blocks will be displayed: General Info - displays common information about the created/cloned/imported application. Advanced Settings - displays the specified job provisioner, Jenkins slave, deployment script, and the versioning type with the start versioning from number (the latter two fields appear in case of edp versioning type). Branches - displays the status and name of the deployment branch, keeps the additional links to Jenkins and Gerrit. In case of edp versioning type, there are two additional fields: Build Number - indicates the current build number; Last Successful Build - indicates the last successful build number. Status Info - displays all the actions that were performed during the creation/cloning/importing process. Edit the application codebase by clicking the pencil icon. For details see the Edit Existing Codebase section. Remove application with the corresponding database and Jenkins pipelines: Click the delete icon next to the application name; Type the required application name; Confirm the deletion by clicking the Delete button. Note The application that is used in a CD pipeline cannot be removed._ Select a number of existing applications to be displayed on one page in the Show entries field. The filter allows to show 10, 25, 50 or 100 entries per page. Sort the existing applications in a list by clicking the Name title. The applications will be displayed in alphabetical order. Search the necessary application by entering the corresponding name, language or the build tool into the Search field. The search can be performed by the application name, language or a build tool. Navigate between pages if the number of applications exceeds the capacity of a single page. Add a New Branch \u00b6 When adding an application, the default branch is a master branch. In order to add a new branch, follow the steps below: Navigate to the Branches block and click the Create button: Fill in the required fields: a. Release Branch - select the Release Branch check box if you need to create a release branch; b. Branch Name - type the branch name. Pay attention that this field remain static if you create a release branch. c. From Commit Hash - paste the commit hash from which the new branch will be created. Note that if the From Commit Hash field is empty, the latest commit from the branch name will be used. d. Branch Version - enter the necessary branch version for the artifact. The Release Candidate (RC) postfix is concatenated to the branch version number. e. Master Branch Version - type the branch version that will be used in a master branch after the release creation. The Snapshot postfix is concatenated to the master branch version number; f. Click the Proceed button and wait until the new branch will be added to the list. Info Adding of a new branch is indicated in the context of the edp versioning type. To get more detailed information on how to add a branch using the default versioning type, please refer here . The default application repository is cloned and changed to the new indicated version before the build, i.e. the new indicated version will not be committed to the repository; thus, the existing repository will keep the default version. Edit Existing Codebase \u00b6 The EDP Admin Console provides the ability to enable, disable or edit the Jira Integration functionality for applications via the Edit Codebase page. Perform the editing from one of the following sections on the Admin Console interface: Navigate to the codebase overview page and click the pencil icon, or Navigate to the codebase list page and click the pencil icon. To enable Jira integration, on the Edit Codebase page do the following: mark the Integrate with Jira server checkbox and fill in the necessary fields; click the Proceed button to apply the changes; navigate to Jenkins and add the create-jira-issue-metadata stage in the Build pipeline. Also add the commit-validate stage in the Code-Review pipeline. To disable Jira integration, on the Edit Codebase page do the following: unmark the Integrate with Jira server checkbox; click the Proceed button to apply the changes; navigate to Jenkins and remove the create-jira-issue-metadata stage in the Build pipeline. Also remove the commit-validate stage in the Code-Review pipeline. As a result, the necessary changes will be applied. Remove Branch \u00b6 In order to remove the added branch with the corresponding record in the Admin Console database, do the following: Navigate to the Branches block by clicking the application name link in the Applications list; Click the delete icon related to the necessary branch: Enter the branch name and click the Delete button; Note The default master branch cannot be removed._ Related Articles \u00b6 Add Application","title":"Overview"},{"location":"user-guide/application/#application","text":"This section describes the subsequent possible actions that can be performed with the newly added or existing applications.","title":"Application"},{"location":"user-guide/application/#check-and-remove-application","text":"As soon as the application is successfully provisioned, the following will be created: Code Review and Build pipelines in Jenkins for this application. The Build pipeline will be triggered automatically if at least one environment is already added. A new project in Gerrit or another VCS. SonarQube integration will be available after the Build pipeline in Jenkins is passed. Nexus Repository Manager will be available after the Build pipeline in Jenkins is passed as well. Info To navigate quickly to OpenShift, Jenkins, Gerrit, SonarQube, Nexus, and other resources, click the Overview section on the navigation bar and hit the necessary link. The added application will be listed in the Applications list allowing you to do the following: Create another application by clicking the Create button and performing the same steps as described in Add Applications section. Open application data by clicking its link name. Once clicked, the following blocks will be displayed: General Info - displays common information about the created/cloned/imported application. Advanced Settings - displays the specified job provisioner, Jenkins slave, deployment script, and the versioning type with the start versioning from number (the latter two fields appear in case of edp versioning type). Branches - displays the status and name of the deployment branch, keeps the additional links to Jenkins and Gerrit. In case of edp versioning type, there are two additional fields: Build Number - indicates the current build number; Last Successful Build - indicates the last successful build number. Status Info - displays all the actions that were performed during the creation/cloning/importing process. Edit the application codebase by clicking the pencil icon. For details see the Edit Existing Codebase section. Remove application with the corresponding database and Jenkins pipelines: Click the delete icon next to the application name; Type the required application name; Confirm the deletion by clicking the Delete button. Note The application that is used in a CD pipeline cannot be removed._ Select a number of existing applications to be displayed on one page in the Show entries field. The filter allows to show 10, 25, 50 or 100 entries per page. Sort the existing applications in a list by clicking the Name title. The applications will be displayed in alphabetical order. Search the necessary application by entering the corresponding name, language or the build tool into the Search field. The search can be performed by the application name, language or a build tool. Navigate between pages if the number of applications exceeds the capacity of a single page.","title":"Check and Remove Application"},{"location":"user-guide/application/#add-a-new-branch","text":"When adding an application, the default branch is a master branch. In order to add a new branch, follow the steps below: Navigate to the Branches block and click the Create button: Fill in the required fields: a. Release Branch - select the Release Branch check box if you need to create a release branch; b. Branch Name - type the branch name. Pay attention that this field remain static if you create a release branch. c. From Commit Hash - paste the commit hash from which the new branch will be created. Note that if the From Commit Hash field is empty, the latest commit from the branch name will be used. d. Branch Version - enter the necessary branch version for the artifact. The Release Candidate (RC) postfix is concatenated to the branch version number. e. Master Branch Version - type the branch version that will be used in a master branch after the release creation. The Snapshot postfix is concatenated to the master branch version number; f. Click the Proceed button and wait until the new branch will be added to the list. Info Adding of a new branch is indicated in the context of the edp versioning type. To get more detailed information on how to add a branch using the default versioning type, please refer here . The default application repository is cloned and changed to the new indicated version before the build, i.e. the new indicated version will not be committed to the repository; thus, the existing repository will keep the default version.","title":"Add a New Branch"},{"location":"user-guide/application/#edit-existing-codebase","text":"The EDP Admin Console provides the ability to enable, disable or edit the Jira Integration functionality for applications via the Edit Codebase page. Perform the editing from one of the following sections on the Admin Console interface: Navigate to the codebase overview page and click the pencil icon, or Navigate to the codebase list page and click the pencil icon. To enable Jira integration, on the Edit Codebase page do the following: mark the Integrate with Jira server checkbox and fill in the necessary fields; click the Proceed button to apply the changes; navigate to Jenkins and add the create-jira-issue-metadata stage in the Build pipeline. Also add the commit-validate stage in the Code-Review pipeline. To disable Jira integration, on the Edit Codebase page do the following: unmark the Integrate with Jira server checkbox; click the Proceed button to apply the changes; navigate to Jenkins and remove the create-jira-issue-metadata stage in the Build pipeline. Also remove the commit-validate stage in the Code-Review pipeline. As a result, the necessary changes will be applied.","title":"Edit Existing Codebase"},{"location":"user-guide/application/#remove-branch","text":"In order to remove the added branch with the corresponding record in the Admin Console database, do the following: Navigate to the Branches block by clicking the application name link in the Applications list; Click the delete icon related to the necessary branch: Enter the branch name and click the Delete button; Note The default master branch cannot be removed._","title":"Remove Branch"},{"location":"user-guide/application/#related-articles","text":"Add Application","title":"Related Articles"},{"location":"user-guide/autotest/","text":"Autotest \u00b6 This section describes the subsequent possible actions that can be performed with the newly added or existing autotests. Check and Remove Autotest \u00b6 As soon as the autotest is successfully provisioned, the following will be created: Code Review and Build pipelines in Jenkins for this autotest. The Build pipeline will be triggered automatically if at least one environment is already added. A new project in Gerrit or another VCS. SonarQube integration will be available after the Build pipeline in Jenkins is passed. Nexus Repository Manager will be available after the Build pipeline in Jenkins is passed as well. Info To navigate quickly to OpenShift, Jenkins, Gerrit, SonarQube, Nexus, and other resources, click the Overview section on the navigation bar and hit the necessary link. The added autotest will be listed in the Autotests list allowing you to do the following: Add another autotest by clicking the Create button and performing the same steps as described here . Open autotest data by clicking its link name. Once clicked, the following blocks will be displayed: General Info - displays common information about the cloned/imported autotest. Advanced Settings - displays the specified job provisioner, Jenkins slave, deployment script, and the versioning type with the start versioning from number (the latter two fields appear in case of edp versioning type). Branches - displays the status and name of the deployment branch, keeps the additional links to Jenkins and Gerrit. In case of edp versioning type, there are two additional fields: Build Number - indicates the current build number; Last Successful Build - indicates the last successful build number. Status Info - displays all the actions that were performed during the cloning/importing process. Edit the autotest codebase by clicking the pencil icon. For details see the Edit Existing Codebase section. Remove autotest with the corresponding database and Jenkins pipelines: Click the delete icon next to the autotest name; Type the required autotest name; Confirm the deletion by clicking the Delete button. Note The autotest that is used in a CD pipeline cannot be removed._ Select a number of existing autotests to be displayed on one page in the Show entries field. The filter allows to show 10, 25, 50 or 100 entries per page. Sort the existing autotests in a list by clicking the Name title. The autotests will be displayed in alphabetical order. Search the necessary autotest by entering the corresponding name, language or the build tool into the Search field. The search can be performed by the autotest name, language or a build tool. Navigate between pages, if the number of autotests exceeds the capacity of a single page. Edit Existing Codebase \u00b6 The EDP Admin Console provides the ability to enable, disable or edit the Jira Integration functionality for autotests via the Edit Codebase page. Perform the editing from one of the following sections on the Admin Console interface: Navigate to the codebase overview page and click the pencil icon, or Navigate to the codebase list page and click the pencil icon. To enable Jira integration, on the Edit Codebase page do the following: mark the Integrate with Jira server checkbox and fill in the necessary fields; click the Proceed button to apply the changes; navigate to Jenkins and add the create-jira-issue-metadata stage in the Build pipeline. Also add the commit-validate stage in the Code-Review pipeline. To disable Jira integration, on the Edit Codebase page do the following: unmark the Integrate with Jira server checkbox; click the Proceed button to apply the changes; navigate to Jenkins and remove the create-jira-issue-metadata stage in the Build pipeline. Also remove the commit-validate stage in the Code-Review pipeline. As a result, the necessary changes will be applied. Add a New Branch \u00b6 When adding an autotest, the default branch is a master branch. In order to add a new branch, follow the steps below: Navigate to the Branches block and click the Create button: Fill in the required fields: a. Release Branch - select the Release Branch check box if you need to create a release branch; b. Branch Name - type the branch name. Pay attention that this field remain static if you create a release branch. c. From Commit Hash - paste the commit hash from which the new branch will be created. Note that if the From Commit Hash field is empty, the latest commit from the branch name will be used. d. Branch Version - enter the necessary branch version for the artifact. The Release Candidate (RC) postfix is concatenated to the branch version number. e. Master Branch Version - type the branch version that will be used in a master branch after the release creation. The Snapshot postfix is concatenated to the master branch version number; f. Click the Proceed button and wait until the new branch will be added to the list. Info Adding of a new branch is indicated in the context of the edp versioning type. To get more detailed information on how to add a branch using the default versioning type, please refer here . The default autotest repository is cloned and changed to the new indicated version before the build, i.e. the new indicated version will not be committed to the repository; thus, the existing repository will keep the default version. Remove Branch \u00b6 In order to remove the added branch with the corresponding record in the Admin Console database, do the following: Navigate to the Branches block by clicking the autotest name link in the Autotests list; Click the delete icon related to the necessary branch: Enter the branch name and click the Delete button; Note The default master branch cannot be removed. Related Articles \u00b6 Add Autotests","title":"Overview"},{"location":"user-guide/autotest/#autotest","text":"This section describes the subsequent possible actions that can be performed with the newly added or existing autotests.","title":"Autotest"},{"location":"user-guide/autotest/#check-and-remove-autotest","text":"As soon as the autotest is successfully provisioned, the following will be created: Code Review and Build pipelines in Jenkins for this autotest. The Build pipeline will be triggered automatically if at least one environment is already added. A new project in Gerrit or another VCS. SonarQube integration will be available after the Build pipeline in Jenkins is passed. Nexus Repository Manager will be available after the Build pipeline in Jenkins is passed as well. Info To navigate quickly to OpenShift, Jenkins, Gerrit, SonarQube, Nexus, and other resources, click the Overview section on the navigation bar and hit the necessary link. The added autotest will be listed in the Autotests list allowing you to do the following: Add another autotest by clicking the Create button and performing the same steps as described here . Open autotest data by clicking its link name. Once clicked, the following blocks will be displayed: General Info - displays common information about the cloned/imported autotest. Advanced Settings - displays the specified job provisioner, Jenkins slave, deployment script, and the versioning type with the start versioning from number (the latter two fields appear in case of edp versioning type). Branches - displays the status and name of the deployment branch, keeps the additional links to Jenkins and Gerrit. In case of edp versioning type, there are two additional fields: Build Number - indicates the current build number; Last Successful Build - indicates the last successful build number. Status Info - displays all the actions that were performed during the cloning/importing process. Edit the autotest codebase by clicking the pencil icon. For details see the Edit Existing Codebase section. Remove autotest with the corresponding database and Jenkins pipelines: Click the delete icon next to the autotest name; Type the required autotest name; Confirm the deletion by clicking the Delete button. Note The autotest that is used in a CD pipeline cannot be removed._ Select a number of existing autotests to be displayed on one page in the Show entries field. The filter allows to show 10, 25, 50 or 100 entries per page. Sort the existing autotests in a list by clicking the Name title. The autotests will be displayed in alphabetical order. Search the necessary autotest by entering the corresponding name, language or the build tool into the Search field. The search can be performed by the autotest name, language or a build tool. Navigate between pages, if the number of autotests exceeds the capacity of a single page.","title":"Check and Remove Autotest"},{"location":"user-guide/autotest/#edit-existing-codebase","text":"The EDP Admin Console provides the ability to enable, disable or edit the Jira Integration functionality for autotests via the Edit Codebase page. Perform the editing from one of the following sections on the Admin Console interface: Navigate to the codebase overview page and click the pencil icon, or Navigate to the codebase list page and click the pencil icon. To enable Jira integration, on the Edit Codebase page do the following: mark the Integrate with Jira server checkbox and fill in the necessary fields; click the Proceed button to apply the changes; navigate to Jenkins and add the create-jira-issue-metadata stage in the Build pipeline. Also add the commit-validate stage in the Code-Review pipeline. To disable Jira integration, on the Edit Codebase page do the following: unmark the Integrate with Jira server checkbox; click the Proceed button to apply the changes; navigate to Jenkins and remove the create-jira-issue-metadata stage in the Build pipeline. Also remove the commit-validate stage in the Code-Review pipeline. As a result, the necessary changes will be applied.","title":"Edit Existing Codebase"},{"location":"user-guide/autotest/#add-a-new-branch","text":"When adding an autotest, the default branch is a master branch. In order to add a new branch, follow the steps below: Navigate to the Branches block and click the Create button: Fill in the required fields: a. Release Branch - select the Release Branch check box if you need to create a release branch; b. Branch Name - type the branch name. Pay attention that this field remain static if you create a release branch. c. From Commit Hash - paste the commit hash from which the new branch will be created. Note that if the From Commit Hash field is empty, the latest commit from the branch name will be used. d. Branch Version - enter the necessary branch version for the artifact. The Release Candidate (RC) postfix is concatenated to the branch version number. e. Master Branch Version - type the branch version that will be used in a master branch after the release creation. The Snapshot postfix is concatenated to the master branch version number; f. Click the Proceed button and wait until the new branch will be added to the list. Info Adding of a new branch is indicated in the context of the edp versioning type. To get more detailed information on how to add a branch using the default versioning type, please refer here . The default autotest repository is cloned and changed to the new indicated version before the build, i.e. the new indicated version will not be committed to the repository; thus, the existing repository will keep the default version.","title":"Add a New Branch"},{"location":"user-guide/autotest/#remove-branch","text":"In order to remove the added branch with the corresponding record in the Admin Console database, do the following: Navigate to the Branches block by clicking the autotest name link in the Autotests list; Click the delete icon related to the necessary branch: Enter the branch name and click the Delete button; Note The default master branch cannot be removed.","title":"Remove Branch"},{"location":"user-guide/autotest/#related-articles","text":"Add Autotests","title":"Related Articles"},{"location":"user-guide/d-d-diagram/","text":"Delivery Dashboard Diagram \u00b6 Admin Console allows getting the general visualization of all the relations between CD pipeline, stages, codebases, branches, and image streams that are elements with the specific icon. To open the current project diagram, navigate to the Delivery Dashboard Diagram section on the navigation bar: Info All the requested changes (deletion, creation, adding) are displayed immediately on the Delivery Dashboard Diagram. Possible actions when using dashboard: To zoom in or zoom out the diagram scale, scroll up / down. To move the diagram, click and drag. To move an element, click it and drag to the necessary place. To see the relations for one element, click this element. To see the whole diagram, click the empty space. Related Articles \u00b6 EDP Admin Console","title":"Delivery Dashboard Diagram"},{"location":"user-guide/d-d-diagram/#delivery-dashboard-diagram","text":"Admin Console allows getting the general visualization of all the relations between CD pipeline, stages, codebases, branches, and image streams that are elements with the specific icon. To open the current project diagram, navigate to the Delivery Dashboard Diagram section on the navigation bar: Info All the requested changes (deletion, creation, adding) are displayed immediately on the Delivery Dashboard Diagram. Possible actions when using dashboard: To zoom in or zoom out the diagram scale, scroll up / down. To move the diagram, click and drag. To move an element, click it and drag to the necessary place. To see the relations for one element, click this element. To see the whole diagram, click the empty space.","title":"Delivery Dashboard Diagram"},{"location":"user-guide/d-d-diagram/#related-articles","text":"EDP Admin Console","title":"Related Articles"},{"location":"user-guide/library/","text":"Library \u00b6 This section describes the subsequent possible actions that can be performed with the newly added or existing libraries. Check and Remove Library \u00b6 As soon as the library is successfully provisioned, the following will be created: Code Review and Build pipelines in Jenkins for this library. The Build pipeline will be triggered automatically if at least one environment is already added. A new project in Gerrit or another VCS. SonarQube integration will be available after the Build pipeline in Jenkins is passed. Nexus Repository Manager will be available after the Build pipeline in Jenkins is passed as well. Info To navigate quickly to OpenShift, Jenkins, Gerrit, SonarQube, Nexus, and other resources, click the Overview section on the navigation bar and hit the necessary link. The added library will be listed in the Libraries list allowing you to do the following: Create another library by clicking the Create button and performing the same steps as described here ; Open library data by clicking its link name. Once clicked, the following blocks will be displayed: General Info - displays common information about the created/cloned/imported library. Advanced Settings - displays the specified job provisioner, Jenkins slave, deployment script, and the versioning type with the start versioning from number (the latter two fields appear in case of edp versioning type). Branches - displays the status and name of the deployment branch, keeps the additional links to Jenkins and Gerrit. In case of edp versioning type, there are two additional fields: Build Number - indicates the current build number; Last Successful Build - indicates the last successful build number. Status Info - displays all the actions that were performed during the creation/cloning/importing process. Edit the library codebase by clicking the pencil icon. For details see the Edit Existing Codebase section. Remove library with the corresponding database and Jenkins pipelines: Click the delete icon next to the library name; Type the required library name; Confirm the deletion by clicking the Delete button. Note The library that is used in a CD pipeline cannot be removed. Select a number of existing libraries to be displayed on one page in the Show entries field. The filter allows to show 10, 25, 50 or 100 entries per page. Sort the existing libraries in a list by clicking the Name title. The libraries will be displayed in an alphabetical order. Search the necessary application by entering the corresponding name, language or the build tool into the Search field. The search can be performed by the library name, language or a build tool. Navigate between pages, if the number of libraries exceeds the capacity of a single page. Edit Existing Codebase \u00b6 The EDP Admin Console provides the ability to enable, disable or edit the Jira Integration functionality for applications via the Edit Codebase page. Perform the editing from one of the following sections on the Admin Console interface: Navigate to the codebase overview page and click the pencil icon, or Navigate to the codebase list page and click the pencil icon. To enable Jira integration, on the Edit Codebase page do the following: mark the Integrate with Jira server checkbox and fill in the necessary fields; click the Proceed button to apply the changes; navigate to Jenkins and add the create-jira-issue-metadata stage in the Build pipeline. Also add the commit-validate stage in the Code-Review pipeline. To disable Jira integration, on the Edit Codebase page do the following: unmark the Integrate with Jira server checkbox; click the Proceed button to apply the changes; navigate to Jenkins and remove the create-jira-issue-metadata stage in the Build pipeline. Also remove the commit-validate stage in the Code-Review pipeline. As a result, the necessary changes will be applied. Add a New Branch \u00b6 When adding a library, the default branch is a master branch. In order to add a new branch, follow the steps below: Navigate to the Branches block and click the Create button: Fill in the required fields: a. Release Branch - select the Release Branch check box if you need to create a release branch; b. Branch Name - type the branch name. Pay attention that this field remain static if you create a release branch. c. From Commit Hash - paste the commit hash from which the new branch will be created. Note that if the From Commit Hash field is empty, the latest commit from the branch name will be used. d. Branch Version - enter the necessary branch version for the artifact. The Release Candidate (RC) postfix is concatenated to the branch version number. e. Master Branch Version - type the branch version that will be used in a master branch after the release creation. The Snapshot postfix is concatenated to the master branch version number; f. Click the Proceed button and wait until the new branch will be added to the list. Info Adding of a new branch is indicated in the context of the edp versioning type. To get more detailed information on how to add a branch using the default versioning type, please refer here . The default library repository is cloned and changed to the new indicated version before the build, i.e. the new indicated version will not be committed to the repository; thus, the existing repository will keep the default version. Remove Branch \u00b6 In order to remove the added branch with the corresponding record in the Admin Console database, do the following: Navigate to the Branches block by clicking the library name link in the Libraries list; Click the delete icon related to the necessary branch: Enter the branch name and click the Delete button; Note The default master branch cannot be removed._ Related Articles \u00b6 Add Library","title":"Overview"},{"location":"user-guide/library/#library","text":"This section describes the subsequent possible actions that can be performed with the newly added or existing libraries.","title":"Library"},{"location":"user-guide/library/#check-and-remove-library","text":"As soon as the library is successfully provisioned, the following will be created: Code Review and Build pipelines in Jenkins for this library. The Build pipeline will be triggered automatically if at least one environment is already added. A new project in Gerrit or another VCS. SonarQube integration will be available after the Build pipeline in Jenkins is passed. Nexus Repository Manager will be available after the Build pipeline in Jenkins is passed as well. Info To navigate quickly to OpenShift, Jenkins, Gerrit, SonarQube, Nexus, and other resources, click the Overview section on the navigation bar and hit the necessary link. The added library will be listed in the Libraries list allowing you to do the following: Create another library by clicking the Create button and performing the same steps as described here ; Open library data by clicking its link name. Once clicked, the following blocks will be displayed: General Info - displays common information about the created/cloned/imported library. Advanced Settings - displays the specified job provisioner, Jenkins slave, deployment script, and the versioning type with the start versioning from number (the latter two fields appear in case of edp versioning type). Branches - displays the status and name of the deployment branch, keeps the additional links to Jenkins and Gerrit. In case of edp versioning type, there are two additional fields: Build Number - indicates the current build number; Last Successful Build - indicates the last successful build number. Status Info - displays all the actions that were performed during the creation/cloning/importing process. Edit the library codebase by clicking the pencil icon. For details see the Edit Existing Codebase section. Remove library with the corresponding database and Jenkins pipelines: Click the delete icon next to the library name; Type the required library name; Confirm the deletion by clicking the Delete button. Note The library that is used in a CD pipeline cannot be removed. Select a number of existing libraries to be displayed on one page in the Show entries field. The filter allows to show 10, 25, 50 or 100 entries per page. Sort the existing libraries in a list by clicking the Name title. The libraries will be displayed in an alphabetical order. Search the necessary application by entering the corresponding name, language or the build tool into the Search field. The search can be performed by the library name, language or a build tool. Navigate between pages, if the number of libraries exceeds the capacity of a single page.","title":"Check and Remove Library"},{"location":"user-guide/library/#edit-existing-codebase","text":"The EDP Admin Console provides the ability to enable, disable or edit the Jira Integration functionality for applications via the Edit Codebase page. Perform the editing from one of the following sections on the Admin Console interface: Navigate to the codebase overview page and click the pencil icon, or Navigate to the codebase list page and click the pencil icon. To enable Jira integration, on the Edit Codebase page do the following: mark the Integrate with Jira server checkbox and fill in the necessary fields; click the Proceed button to apply the changes; navigate to Jenkins and add the create-jira-issue-metadata stage in the Build pipeline. Also add the commit-validate stage in the Code-Review pipeline. To disable Jira integration, on the Edit Codebase page do the following: unmark the Integrate with Jira server checkbox; click the Proceed button to apply the changes; navigate to Jenkins and remove the create-jira-issue-metadata stage in the Build pipeline. Also remove the commit-validate stage in the Code-Review pipeline. As a result, the necessary changes will be applied.","title":"Edit Existing Codebase"},{"location":"user-guide/library/#add-a-new-branch","text":"When adding a library, the default branch is a master branch. In order to add a new branch, follow the steps below: Navigate to the Branches block and click the Create button: Fill in the required fields: a. Release Branch - select the Release Branch check box if you need to create a release branch; b. Branch Name - type the branch name. Pay attention that this field remain static if you create a release branch. c. From Commit Hash - paste the commit hash from which the new branch will be created. Note that if the From Commit Hash field is empty, the latest commit from the branch name will be used. d. Branch Version - enter the necessary branch version for the artifact. The Release Candidate (RC) postfix is concatenated to the branch version number. e. Master Branch Version - type the branch version that will be used in a master branch after the release creation. The Snapshot postfix is concatenated to the master branch version number; f. Click the Proceed button and wait until the new branch will be added to the list. Info Adding of a new branch is indicated in the context of the edp versioning type. To get more detailed information on how to add a branch using the default versioning type, please refer here . The default library repository is cloned and changed to the new indicated version before the build, i.e. the new indicated version will not be committed to the repository; thus, the existing repository will keep the default version.","title":"Add a New Branch"},{"location":"user-guide/library/#remove-branch","text":"In order to remove the added branch with the corresponding record in the Admin Console database, do the following: Navigate to the Branches block by clicking the library name link in the Libraries list; Click the delete icon related to the necessary branch: Enter the branch name and click the Delete button; Note The default master branch cannot be removed._","title":"Remove Branch"},{"location":"user-guide/library/#related-articles","text":"Add Library","title":"Related Articles"},{"location":"user-guide/pipeline-stages/","text":"Pipeline Stages \u00b6 Get acquainted with EDP CI/CD workflow and stages description. EDP CI/CD Workflow \u00b6 Within EDP, the pipeline framework comprises the following pipelines: Code Review; Build; Deploy. Note Please refer to the EDP Pipeline Framework page for details. The diagram below shows the commit path through these pipelines and the respective stages. Stages Description \u00b6 The table below provides the details on all the stages in the EDP pipeline framework: Name Dependency Description Pipeline Application Library Autotest Source code Documentation init Initiates information gathering Create Release, Code Review, Build + + Build.groovy checkout Performs for all files the checkout from a selected branch of the Git repository. For the main branch - from HEAD, for code review - from the commit Create Release, Build + + Checkout.groovy compile Compiles the code, includes individual groovy files for each type of app or lib (NPM, DotNet, Python, Maven, Gradle) Code Review, Build + + Compile tests Launches testing procedure, includes individual groovy files for each type of app or lib Code Review, Build + + + Tests sonar Launches testing via SonarQube scanner and includes individual groovy files for each type of app or lib Code Review, Build + + Sonar build Builds the application, includes individual groovy files for each type of app or lib (Go, Maven, Gradle, NPM) Code Review, Build + Build create-branch EDP create-release process Creates default branch in Gerrit during create and clone strategies Create Release + + + CreateBranch.groovy trigger-job EDP create-release process Triggers \"build\" job Create Release + + + TriggerJob.groovy gerrit-checkout Performs checkout to the current project branch in Gerrit Code Review + + + GerritCheckout.groovy commit-validate Optional in EDP Admin Console Takes Jira parameters, when \"Jira Integration\" is enabled for the project in the Admin Console. Code Review + + CommitValidate.groovy dockerfile-lint Launches linting tests for Dockerfile Code Review + LintDockerApplicationLibrary.groovy Use lint stages for code review dockerbuild-verify \"Build\" stage (if there are no \"COPY\" layers in Dockerfile) Launches build procedure for Dockerfile without pushing an image to the repository Code Review + BuildDockerfileApplicationLibrary.groovy Use lint stages for code review helm-lint Launches linting tests for deployment charts Code Review + LintHelmApplicationLibrary.groovy Use lint stages for code review get-version Defines the versioning of the project depending on the versioning schema selected in Admin Console Build + + GetVersion terraform-plan AWS credentials added to Jenkins Checks Terraform version, and installs default version if necessary, and launches terraform init, returns AWS username which used for action, and terraform plan command is called with an output of results to .tfplan file Build + TerraformPlan.groovy Use Terraform library in EDP terraform-apply AWS credentials added to Jenkins, the \"Terraform-plan\" stage Checks Terraform version, and installs default version if necessary, and launches terraform init, launches terraform plan from saves before .tfplan file, asks to approve, and run terraform apply from .tfplan file Build + TerraformApply.groovy Use Terraform library in EDP build-image-from-dockerfile Platform: OpenShift Builds Dockerfile Build + + .groovy files for building Dockerfile image build-image-kaniko Platform: k8s Builds Dockerfile using the Kaniko tool Build + BuildImageKaniko.groovy push Pushes an artifact to the Nexus repository Build + + Push create-Jira-issue-metadata \"get-version\" stage Creates a temporary CR in the namespace and after that pushes Jira Integration data to Jira ticket, and delete CR Build + + JiraIssueMetadata.groovy ecr-to-docker DockerHub credentials added to Jenkins Copies the docker image from the ECR project registry to DockerHub via the Crane tool after it is built Build + EcrToDocker.groovy Promote Docker images from ECR to Docker hub git-tag \"Get-version\" stage Creates a tag in SCM for the current build Build + + GitTagApplicationLibrary.groovy deploy Deploys the application Deploy + Deploy.groovy manual Works with the manual approve to proceed Deploy + ManualApprove.groovy promote-images Promotes docker images to the registry Deploy + PromoteImage.groovy promote-images-ecr Promotes docker images to ECR Deploy + PromoteImagesECR.groovy Note The Create Release pipeline is an internal EDP mechanism for adding, importing or cloning a codebase. It is not a part of the pipeline framework._ Related Articles \u00b6 Add Job Provisioner GitLab Integration GitHub Integration Job Provisions for GCP Issues","title":"Pipeline Stages"},{"location":"user-guide/pipeline-stages/#pipeline-stages","text":"Get acquainted with EDP CI/CD workflow and stages description.","title":"Pipeline Stages"},{"location":"user-guide/pipeline-stages/#edp-cicd-workflow","text":"Within EDP, the pipeline framework comprises the following pipelines: Code Review; Build; Deploy. Note Please refer to the EDP Pipeline Framework page for details. The diagram below shows the commit path through these pipelines and the respective stages.","title":"EDP CI/CD Workflow"},{"location":"user-guide/pipeline-stages/#stages-description","text":"The table below provides the details on all the stages in the EDP pipeline framework: Name Dependency Description Pipeline Application Library Autotest Source code Documentation init Initiates information gathering Create Release, Code Review, Build + + Build.groovy checkout Performs for all files the checkout from a selected branch of the Git repository. For the main branch - from HEAD, for code review - from the commit Create Release, Build + + Checkout.groovy compile Compiles the code, includes individual groovy files for each type of app or lib (NPM, DotNet, Python, Maven, Gradle) Code Review, Build + + Compile tests Launches testing procedure, includes individual groovy files for each type of app or lib Code Review, Build + + + Tests sonar Launches testing via SonarQube scanner and includes individual groovy files for each type of app or lib Code Review, Build + + Sonar build Builds the application, includes individual groovy files for each type of app or lib (Go, Maven, Gradle, NPM) Code Review, Build + Build create-branch EDP create-release process Creates default branch in Gerrit during create and clone strategies Create Release + + + CreateBranch.groovy trigger-job EDP create-release process Triggers \"build\" job Create Release + + + TriggerJob.groovy gerrit-checkout Performs checkout to the current project branch in Gerrit Code Review + + + GerritCheckout.groovy commit-validate Optional in EDP Admin Console Takes Jira parameters, when \"Jira Integration\" is enabled for the project in the Admin Console. Code Review + + CommitValidate.groovy dockerfile-lint Launches linting tests for Dockerfile Code Review + LintDockerApplicationLibrary.groovy Use lint stages for code review dockerbuild-verify \"Build\" stage (if there are no \"COPY\" layers in Dockerfile) Launches build procedure for Dockerfile without pushing an image to the repository Code Review + BuildDockerfileApplicationLibrary.groovy Use lint stages for code review helm-lint Launches linting tests for deployment charts Code Review + LintHelmApplicationLibrary.groovy Use lint stages for code review get-version Defines the versioning of the project depending on the versioning schema selected in Admin Console Build + + GetVersion terraform-plan AWS credentials added to Jenkins Checks Terraform version, and installs default version if necessary, and launches terraform init, returns AWS username which used for action, and terraform plan command is called with an output of results to .tfplan file Build + TerraformPlan.groovy Use Terraform library in EDP terraform-apply AWS credentials added to Jenkins, the \"Terraform-plan\" stage Checks Terraform version, and installs default version if necessary, and launches terraform init, launches terraform plan from saves before .tfplan file, asks to approve, and run terraform apply from .tfplan file Build + TerraformApply.groovy Use Terraform library in EDP build-image-from-dockerfile Platform: OpenShift Builds Dockerfile Build + + .groovy files for building Dockerfile image build-image-kaniko Platform: k8s Builds Dockerfile using the Kaniko tool Build + BuildImageKaniko.groovy push Pushes an artifact to the Nexus repository Build + + Push create-Jira-issue-metadata \"get-version\" stage Creates a temporary CR in the namespace and after that pushes Jira Integration data to Jira ticket, and delete CR Build + + JiraIssueMetadata.groovy ecr-to-docker DockerHub credentials added to Jenkins Copies the docker image from the ECR project registry to DockerHub via the Crane tool after it is built Build + EcrToDocker.groovy Promote Docker images from ECR to Docker hub git-tag \"Get-version\" stage Creates a tag in SCM for the current build Build + + GitTagApplicationLibrary.groovy deploy Deploys the application Deploy + Deploy.groovy manual Works with the manual approve to proceed Deploy + ManualApprove.groovy promote-images Promotes docker images to the registry Deploy + PromoteImage.groovy promote-images-ecr Promotes docker images to ECR Deploy + PromoteImagesECR.groovy Note The Create Release pipeline is an internal EDP mechanism for adding, importing or cloning a codebase. It is not a part of the pipeline framework._","title":"Stages Description"},{"location":"user-guide/pipeline-stages/#related-articles","text":"Add Job Provisioner GitLab Integration GitHub Integration Job Provisions for GCP Issues","title":"Related Articles"}]}